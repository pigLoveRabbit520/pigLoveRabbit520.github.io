[{"categories":["Machine Learning"],"content":"最小二乘法 早在19世纪,勒让德就认为让\"误差的平方和最小\"估计出来的模型是最接近真实情形的。 按照勒让德的最佳原则,于是就是求: $$ \\text{L} = \\sum_{i=1}^{n} \\left( y_i - f(x_i) \\right)^2 $$ 这个目标函数取得最小值时的函数参数,这就是最小二乘法的思想想,所谓\"二乘\"就是平方的意思。从这里我们可以看到,最小二乘法其实 就是用来做函数拟合的一种思想。 至于怎么求出具体的参数那就是另外一个问题了,理论上可以用导数法、几何法,工程上可以用梯度下降法。下面以最常用的线性回归为 例进行推导和理解。 在机器学习中用于回归问题的损失函数(Loss Function)是均方误差(MSE)： $$ \\text{L} = \\frac{1}{2n} \\sum_{i=1}^{n} \\left( y_i - f(x_i) \\right)^2 $$ 其实就是多了个1/2n。 ","date":"2024-10-08","objectID":"/least_square/:1:0","tags":[],"title":"最小二乘法和线性回归","uri":"/least_square/"},{"categories":["Machine Learning"],"content":"线性回归 线性回归因为比较简单,可以直接推导出解析解,而且许多非线性的问题也可以转化为线性问题来解决,所以得到了广泛的应用。甚至许多人认为最小二乘法指的就是线性回归,其实并不是,最小二乘法就是一种思想,它可以拟合任意函数,线性回归只是其中一个比较简单而且也很常用的函数,所以讲最小二乘法基本都会以它为例。 下面我会先用矩阵法进行推导,然后再用几何法来帮助你理解最小二乘法的几何意义。 设计矩阵 X （维度为$ n \\times \\left(p + 1\\right) $）：包含所有样本的特征信息，第一列是全为 1 的常数列，代表截距项$ \\beta_{0} $ ，其余列为各个特征的值。 $$ \\boldsymbol{X}=\\left[\\begin{array}{ccccc} 1 \u0026 x_{11} \u0026 x_{12} \u0026 \\ldots \u0026 x_{1 p} \\newline 1 \u0026 x_{21} \u0026 x_{22} \u0026 \\ldots \u0026 x_{2 p} \\newline \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\newline 1 \u0026 x_{n 1} \u0026 x_{n 2} \u0026 \\ldots \u0026 x_{n p} \\end{array}\\right] $$ 回归系数向量 $ \\beta $ （维度为$ \\left(p + 1\\right) \\times 1 $）：包含所有的回归系数（包括截距项）。 $$ \\boldsymbol{\\beta} = \\begin{bmatrix} \\beta_0 \\newline \\beta_1 \\newline \\beta_2 \\newline \\vdots \\newline \\beta_p \\end{bmatrix} $$ 观测值向量$ y $（维度为$ n \\times 1 $）：包含所有样本的目标值。 $$ \\boldsymbol{y} = \\begin{bmatrix} y_0 \\newline y_1 \\newline y_2 \\newline \\vdots \\newline y_p \\end{bmatrix} $$ 线性回归的模型可以简化为： $$ \\boldsymbol{y} = \\boldsymbol{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon} $$ 其中$\\boldsymbol{\\epsilon}$是误差向量。 为了估计$\\beta$，我们通常使用 最小二乘法 来最小化残差平方和，即： $$ \\min_{\\beta} || \\boldsymbol{y} - \\boldsymbol{X}\\boldsymbol{\\beta} ||^2 $$ 这里的$|\\cdot|$表示Frobenius 范数或F-范数，是一种矩阵范数。 矩阵A的Frobenius范数定义为矩阵A各项元素的绝对值平方的总和，即 ： $$ ||A||F = \\sqrt{\\sum{i,j} |a_{ij}|^2} $$ 这里$ a_{ij} $是矩阵 中第i行，第j列的元素。下标2可以省略，所以可以直接写成$ ||A|| $。 因为$ \\boldsymbol{y} - \\boldsymbol{X}\\boldsymbol{\\beta} $其实是一个列向量，所以它的F-范数行向量乘以列向量，我们可以得到： $$ ||A||^2 = A^TA $$ 所以误差函数可以表示为: $$ || y - X\\beta ||^2 = (y - X\\beta)^T (y - X\\beta) $$ 展开后得到： $$ (y - X\\beta)^T (y - X\\beta) = y^T y - y^T X\\beta - (X\\beta)^T y + (X\\beta)^T X\\beta $$ 然后得到： $$ (y - X\\beta)^T (y - X\\beta) = y^T y - y^T X\\beta - \\beta^TX^T y + \\beta^T X^T X \\beta $$ 这里$y^T X\\beta $和$ \\beta^TX^T y$ 都是$1 \\times 1$的标量，对于标量，有$a^T = a$，因此$\\beta^TX^T y = (\\beta^TX^T y)^T = y^TX\\beta $ 合并同类项： $$ (y - X\\beta)^T (y - X\\beta) = y^T y - 2\\beta^T X^Ty + \\beta^T X^T X \\beta $$ 参考： 矩阵范数 最小二乘法线性回归：矩阵视角 ","date":"2024-10-08","objectID":"/least_square/:2:0","tags":[],"title":"最小二乘法和线性回归","uri":"/least_square/"},{"categories":["Nodejs"],"content":"JavaScript会将异步任务划分为微任务和宏任务，微任务会在宏任务之前执行（因为每次从主线程切换到任务队列时，都会优先遍历微任务队列，后遍历宏任务队列）。 ","date":"2024-09-18","objectID":"/javascript_%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97_promise/:0:0","tags":["Promise","Nodejs"],"title":"JavaScript中的微任务、宏任务和Promise","uri":"/javascript_%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97_promise/"},{"categories":["Nodejs"],"content":"一个小例子 // 1 setTimeout(() =\u003e { // 宏任务 console.log(4) }, 0) // 2 new Promise(resolve =\u003e { resolve() console.log(1) // 3 }).then(data =\u003e { // 微任务 console.log(3) }) // 4 console.log(2) // 同步任务 // 执行结果： 1 2 3 4 ","date":"2024-09-18","objectID":"/javascript_%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97_promise/:1:0","tags":["Promise","Nodejs"],"title":"JavaScript中的微任务、宏任务和Promise","uri":"/javascript_%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97_promise/"},{"categories":["Nodejs"],"content":"Promise实现原理 // 判断变量否为function const isFunction = variable =\u003e typeof variable === 'function' // 定义Promise的三种状态常量 const PENDING = 'PENDING' const FULFILLED = 'FULFILLED' const REJECTED = 'REJECTED' class MyPromise { constructor (handle) { if (!isFunction(handle)) { throw new Error('MyPromise must accept a function as a parameter') } // 添加状态 this._status = PENDING // 添加状态 this._value = undefined // 添加成功回调函数队列 this._fulfilledQueues = [] // 添加失败回调函数队列 this._rejectedQueues = [] // 执行handle try { handle(this._resolve.bind(this), this._reject.bind(this)) } catch (err) { this._reject(err) } } // 添加resovle时执行的函数 _resolve (val) { const run = () =\u003e { if (this._status !== PENDING) return // 依次执行成功队列中的函数，并清空队列 const runFulfilled = (value) =\u003e { let cb; while (cb = this._fulfilledQueues.shift()) { cb(value) } } // 依次执行失败队列中的函数，并清空队列 const runRejected = (error) =\u003e { let cb; while (cb = this._rejectedQueues.shift()) { cb(error) } } /* 如果resolve的参数为Promise对象，则必须等待该Promise对象状态改变后, 当前Promsie的状态才会改变，且状态取决于参数Promsie对象的状态 */ if (val instanceof MyPromise) { val.then(value =\u003e { this._value = value this._status = FULFILLED runFulfilled(value) }, err =\u003e { this._value = err this._status = REJECTED runRejected(err) }) } else { this._value = val this._status = FULFILLED runFulfilled(val) } } // 为了支持同步的Promise，这里采用异步调用 setTimeout(run, 0) } // 添加reject时执行的函数 _reject (err) { if (this._status !== PENDING) return // 依次执行失败队列中的函数，并清空队列 const run = () =\u003e { this._status = REJECTED this._value = err let cb; while (cb = this._rejectedQueues.shift()) { cb(err) } } // 为了支持同步的Promise，这里采用异步调用 setTimeout(run, 0) } // 添加then方法 then (onFulfilled, onRejected) { const { _value, _status } = this // 返回一个新的Promise对象 return new MyPromise((onFulfilledNext, onRejectedNext) =\u003e { // 封装一个成功时执行的函数 let fulfilled = value =\u003e { try { if (!isFunction(onFulfilled)) { onFulfilledNext(value) } else { let res = onFulfilled(value); if (res instanceof MyPromise) { // 如果当前回调函数返回MyPromise对象，必须等待其状态改变后在执行下一个回调 res.then(onFulfilledNext, onRejectedNext) } else { //否则会将返回结果直接作为参数，传入下一个then的回调函数，并立即执行下一个then的回调函数 onFulfilledNext(res) } } } catch (err) { // 如果函数执行出错，新的Promise对象的状态为失败 onRejectedNext(err) } } // 封装一个失败时执行的函数 let rejected = error =\u003e { try { if (!isFunction(onRejected)) { onRejectedNext(error) } else { let res = onRejected(error); if (res instanceof MyPromise) { // 如果当前回调函数返回MyPromise对象，必须等待其状态改变后在执行下一个回调 res.then(onFulfilledNext, onRejectedNext) } else { //否则会将返回结果直接作为参数，传入下一个then的回调函数，并立即执行下一个then的回调函数 onFulfilledNext(res) } } } catch (err) { // 如果函数执行出错，新的Promise对象的状态为失败 onRejectedNext(err) } } switch (_status) { // 当状态为pending时，将then方法回调函数加入执行队列等待执行 case PENDING: this._fulfilledQueues.push(fulfilled) this._rejectedQueues.push(rejected) break // 当状态已经改变时，立即执行对应的回调函数 case FULFILLED: fulfilled(_value) break case REJECTED: rejected(_value) break } }) } // 添加catch方法 catch (onRejected) { return this.then(undefined, onRejected) } // 添加静态resolve方法 static resolve (value) { // 如果参数是MyPromise实例，直接返回这个实例 if (value instanceof MyPromise) return value return new MyPromise(resolve =\u003e resolve(value)) } // 添加静态reject方法 static reject (value) { return new MyPromise((resolve ,reject) =\u003e reject(value)) } // 添加静态all方法 static all (list) { return new MyPromise((resolve, reject) =\u003e { /** * 返回值的集合 */ let values = [] let count = 0 for (let [i, p] of list.entries()) { // 数组参数如果不是MyPromise实例，先调用MyPromise.resolve this.resolve(p).then(res =\u003e { values[i] = res count++ // 所有状态都变成fulfilled时返回的MyPromise状态就变成fulfilled if (count === list.length) resolve(values) }, err =\u003e { // 有一个被rejected时返回的MyPromise状态就变成rejected reject(err) }) } }) } // 添加静态race方法 static race (list) { return new MyPromise((resolve, reject) =\u003e { for (let p of list) { // 只要有一个实例率先改变状态，新的MyPromise的状态就跟着改变 this.resolve(p).then(res =\u003e { resolve(res) }, err =\u003e { reject(err) }) } }) } finally (cb) { return this.then( value =\u003e MyPromise.resolve(cb()).then(() =\u003e value), reason =\u003e MyPromise.resolve(cb()).then(() =\u003e { throw reason }) ); } } let promise1 = new MyProm","date":"2024-09-18","objectID":"/javascript_%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97_promise/:2:0","tags":["Promise","Nodejs"],"title":"JavaScript中的微任务、宏任务和Promise","uri":"/javascript_%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97_promise/"},{"categories":["cuda"],"content":"CUDA 的安装参考之前的文章 需要安装 OptiX 8 这是Reference.pdf 新建一个 CMake 项目，目录结构是这样的 optix_example/ ├── CMakeLists.txt ├── src └── main.cpp └── cmake └── FindOptiX80.cmake CMakeLists.txt文件： cmake_minimum_required(VERSION 3.10) project(OptiXExample) set(CMAKE_CXX_STANDARD 17) # Find OptiX package list(APPEND CMAKE_MODULE_PATH \"${CMAKE_SOURCE_DIR}/cmake\") find_package(OptiX80) # Add CUDA find_package(CUDAToolkit 12.0 REQUIRED) # Include directories include_directories(${OPTIX80_INCLUDE_DIR} ${CUDAToolkit_INCLUDE_DIRS}) # Source files set(SOURCES src/main.cpp) # Executable add_executable(OptiXExample ${SOURCES}) # Link libraries target_link_libraries(OptiXExample CUDA::cudart) FindOptix80.cmake文件： # Looks for the environment variable: # OPTIX80_PATH # Sets the variables : # OPTIX80_INCLUDE_DIR # OptiX80_FOUND set(OPTIX80_PATH $ENV{OPTIX80_PATH}) if(\"${OPTIX80_PATH}\" STREQUAL \"\") if(WIN32) # Try finding it inside the default installation directory under Windows first. set(OPTIX80_PATH \"C:/ProgramData/NVIDIA Corporation/OptiX SDK 8.0.0\") else() # Adjust this if the OptiX SDK 8.0.0 installation is in a different location. set(OPTIX80_PATH \"~/NVIDIA-OptiX-SDK-8.0.0-linux64\") endif() endif() find_path(OPTIX80_INCLUDE_DIR optix_host.h ${OPTIX80_PATH}/include) # message(\"OPTIX80_INCLUDE_DIR = \" \"${OPTIX80_INCLUDE_DIR}\") include(FindPackageHandleStandardArgs) find_package_handle_standard_args(OptiX80 DEFAULT_MSG OPTIX80_INCLUDE_DIR) mark_as_advanced(OPTIX80_INCLUDE_DIR) # message(\"OptiX80_FOUND = \" \"${OptiX80_FOUND}\") 上面的内容是参考 Github 上OptiX_Apps，它读取了OPTIX80_PATH 环境变量，代表 Optix 在你机器上的位置，例如我的是/home/rabbit/NVIDIA-OptiX-SDK-8.0.0-linux64-x86_64。 main.cpp 文件： #include \u003coptix.h\u003e #include \u003coptix_stubs.h\u003e #include \u003coptix_function_table_definition.h\u003e #include \u003ciostream\u003e #include \u003cstring.h\u003e #include \u003cvector\u003e #include \u003cstdexcept\u003e #include \u003ccuda.h\u003e #include \u003ccuda_runtime_api.h\u003e #define OPTIX_CHECK(call) \\ { \\ OptixResult res = call; \\ if (res != OPTIX_SUCCESS) \\ { \\ fprintf(stderr, \"Optix call (%s) failed with code %d (line %d)\\n\", #call, res, __LINE__); \\ exit(2); \\ } \\ } void initOptix() { // ------------------------------------------------------- // check for available optix7 capable devices // ------------------------------------------------------- cudaFree(0); int numDevices; cudaGetDeviceCount(\u0026numDevices); if (numDevices == 0) throw std::runtime_error(\"#osc: no CUDA capable devices found!\"); std::cout \u003c\u003c \"#osc: found \" \u003c\u003c numDevices \u003c\u003c \" CUDA devices\" \u003c\u003c std::endl; // ------------------------------------------------------- // initialize optix // ------------------------------------------------------- OPTIX_CHECK(optixInit()); } int main() { // Initialize CUDA cudaFree(0); try { std::cout \u003c\u003c \"#osc: initializing optix...\" \u003c\u003c std::endl; initOptix(); std::cout \u003c\u003c \"#osc: successfully initialized optix... yay!\" \u003c\u003c std::endl; // for this simple hello-world example, don't do anything else // ... std::cout \u003c\u003c \"#osc: done. clean exit.\" \u003c\u003c std::endl; } catch (std::runtime_error \u0026e) { std::cout \u003c\u003c \"FATAL ERROR: \" \u003c\u003c e.what() \u003c\u003c std::endl; exit(1); } return 0; } 最后编译，运行输出 $ ./OptiXExample #osc: initializing optix... #osc: found 1 CUDA devices #osc: successfully initialized optix... yay! #osc: done. clean exit. ","date":"2024-07-05","objectID":"/ubuntu-optix-8%E7%AE%80%E5%8D%95%E5%B0%9D%E8%AF%95/:0:0","tags":["OptiX","Ubuntu","cuda"],"title":"Ubuntu上OptiX8 简单尝试","uri":"/ubuntu-optix-8%E7%AE%80%E5%8D%95%E5%B0%9D%E8%AF%95/"},{"categories":["wsl2"],"content":"算法简介 排样问题（Nesting Problem）又称为下料问题(Cutting and stock problems)或填充问题(Packing Problem)，其目标是在材料切割过程中寻找一个较高的材料利用率。排样问题属于经典的NP-Hard问题，其时间复杂度随着问题规模的增加迅速上升，难以在合理时间内精确求解大规模实例。相较于矩形排样问题，异形件排样问题的突出特点是裁片的边界轮廓复杂，计算过程中需要复杂的几何运算，其算法复杂度将进一步上升，是学术界和工业界公认的难以求解的问题。因此在大多数情况下，不规则形状排样算法主要是以启发式算法和智能搜索算法为主。 ","date":"2024-02-15","objectID":"/irregular_packing_nesting_problem/:0:1","tags":["cuda","wsl2"],"title":"二维异形件排版算法（摘抄）","uri":"/irregular_packing_nesting_problem/"},{"categories":["wsl2"],"content":"NFP求解算法 二维异形件排样算法的一个相当重要的方面是计算几何算法，其主要内容在于计算异形件之间的靠接位置、确定裁片与面料之间的包含关系、判断是否重叠以及实现二维区域之间的交、并、差等布尔运算。 为寻找一种更简便高效的靠接和重叠判断计算方法，研究人员提供了临界多边形（No-Fit Polygon，NFP）的概念[1]。临界多边形NFP的简要定义如下：给定两个多边形，其中一个固定，另一个多边形围绕固定的多边形作不旋转的刚体运动，并围绕固定多边形滑动，直到回到起点位置，在此过程中在运动多边形上选取一点作为参考点，则参考点在环绕过程中形成的轨迹就称为临界多边形，如图所示： NFP求解还会遇到特殊场景，如图所示，图a由于多边形A存在凹槽，多边形B可以在凹槽内部移动，此时将形成空腔NFP；图b由于多边形B恰好可以沿着多边形A凹槽移动，此时NFP将退化成线；图c多边形B恰好可以放在多边形B凹槽内，此时NFP将退化成点。NFP求解算法同时要考虑这些特殊情景。 由于临界多边形的重要性质，NFP目前已成为二维不规则形状排样算法的基础性几何工具。如何快速准确的计算出NFP是异形件排样问题的关键技术。学界目前的求解算法主要有4种，分别是凸化分割法、移动碰撞法[4]、明科夫斯基矢量和法[5]以及轨迹线法[2]。 摘抄文章: 二维异形件排版算法介绍（一） ","date":"2024-02-15","objectID":"/irregular_packing_nesting_problem/:0:2","tags":["cuda","wsl2"],"title":"二维异形件排版算法（摘抄）","uri":"/irregular_packing_nesting_problem/"},{"categories":["wsl2"],"content":"驱动 网上有许多资料写道需要安装针对WSL特别驱动，但是现在已经不需要这么做了，只需要到NVIDIA官网将驱动升级到最新版本即可。根据参考资料描述，驱动类型最好选择Game Ready版本而不是studio版本。 注意，该是安装Windows驱动，而不是安装Linux驱动，在Windows下安装驱动后，会自动将驱动以_libcuda.so_的形式集成至WSL2中，因此切勿在WSL Linux中重复安装驱动。 CUDA 这一步要小心，WSL2中安装CUDA和在普通Linux中安装CUDA会有所不同，要选择WSL-Ubuntu类型 然后按命令安装CUDA wget https://developer.download.nvidia.com/compute/cuda/12.3.1/local_installers/cuda_12.3.1_545.23.08_linux.run sudo sh cuda_12.3.1_545.23.08_linux.run 最后nvcc命令还是没找到，得vim ~/.bashrc，把cuda-toolkit的东西加到环境变量里（官方脚本没写好吧^=^） export PATH=${PATH}:/usr/local/cuda/bin export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda/lib64 最后，看一下nvcc命令 $ nvcc --version nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2023 NVIDIA Corporation Built on Fri_Nov__3_17:16:49_PDT_2023 Cuda compilation tools, release 12.3, V12.3.103 Build cuda_12.3.r12.3/compiler.33492891_0 ","date":"2023-12-10","objectID":"/wsl2-install-cuda/:0:0","tags":["cuda","wsl2"],"title":"wsl2 install CUDA","uri":"/wsl2-install-cuda/"},{"categories":["Hyper-V"],"content":"创建 NAT 虚拟网络 要用到一些PowerShell命令 New-VMSwitch -SwitchName \"new\" -SwitchType Internal New-NetIPAddress -IPAddress 192.168.0.1 -PrefixLength 24 -InterfaceAlias \"vEthernet (new)\" New-NetNat -Name MyNATnetwork -InternalIPInterfaceAddressPrefix 192.168.0.0/24 New-VMSwitch 新建了一个内部的交换机 New-NetIPAddress 设置了网卡的ip New-NetNat 设定了子网 ","date":"2023-09-08","objectID":"/hyper-v%E5%81%9Aport-forwarding/:1:0","tags":["windows","Hyper-V"],"title":"Hyper-V做port forwarding","uri":"/hyper-v%E5%81%9Aport-forwarding/"},{"categories":["Hyper-V"],"content":"端口映射 最后利用Add-NetNatStaticMapping命令，映射到宿主机端口： Add-NetNatStaticMapping -NatName MyNATnetwork -Protocol TCP -ExternalIPAddress 0.0.0.0/24 -ExternalPort 5400 -InternalIPAddress 192.168.0.3 -InternalPort 5400 参考： https://learn.microsoft.com/zh-cn/virtualization/hyper-v-on-windows/user-guide/setup-nat-network ","date":"2023-09-08","objectID":"/hyper-v%E5%81%9Aport-forwarding/:2:0","tags":["windows","Hyper-V"],"title":"Hyper-V做port forwarding","uri":"/hyper-v%E5%81%9Aport-forwarding/"},{"categories":["Blender"],"content":" 查看顶点/面法向量 左上角下拉框选择编辑模式，在右边3个Tab中选择面模式 然后点overlays下拉箭头，就能看到normal的选项了 第一个Tab就是顶点法向，第三个Tab就是面法向。 ","date":"2023-07-20","objectID":"/blender%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:0:0","tags":["Blender"],"title":"Blender常用操作","uri":"/blender%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["OpenGL"],"content":"顶点着色器 vertex.glsl varying vec3 vPosition; void main() { vPosition = position; // MVP vec4 modelViewPosition = modelViewMatrix * vec4( position, 1.0 ); vec4 projectedPosition = projectionMatrix * modelViewPosition; gl_Position = projectedPosition; } 片段着色器 fragment.glsl varying vec3 vPosition; void main() { gl_FragColor = vec4(vPosition, 1); } 效果 用了PlaneGeometry // meshes const geometry = new THREE.PlaneGeometry(2, 2) const material = new THREE.ShaderMaterial({ vertexShader: vertexShader, fragmentShader: fragmentShader, }) ","date":"2023-07-02","objectID":"/webgl-shader/:0:0","tags":["WebGL"],"title":"WebGL Shader","uri":"/webgl-shader/"},{"categories":["矩阵"],"content":"旋转矩阵 首先要说明的是，左右手旋转矩阵是不一样的，DirectX中是左手坐标系，而OpenGL用的是右手坐标系，这里给出的旋转矩阵也是基于右手坐标系的 绕x轴旋转的矩阵： $$ \\begin{bmatrix} \\color{red}1 \u0026 \\color{red}0 \u0026 \\color{red}0 \\newline \\color{green}0 \u0026 \\color{green}{\\cos \\theta} \u0026 - \\color{green}{\\sin \\theta} \\newline \\color{blue}0 \u0026 \\color{blue}{\\sin \\theta} \u0026 \\color{blue}{\\cos \\theta} \\end{bmatrix} $$ 沿y轴旋转矩阵： $$ \\begin{bmatrix} \\color{red}{\\cos \\theta} \u0026 \\color{red}0 \u0026 \\color{red}{\\sin \\theta} \\newline \\color{green}0 \u0026 \\color{green}1 \u0026 \\color{green}0 \\newline -\\color{blue}{\\sin \\theta} \u0026 \\color{blue}0 \u0026 \\color{blue}{\\cos \\theta} \\end{bmatrix} $$ 沿z轴旋转矩阵： $$ \\begin{bmatrix} \\color{red}{\\cos \\theta} \u0026 - \\color{red}{\\sin \\theta} \u0026 \\color{red}0 \\newline \\color{green}{\\sin \\theta} \u0026 \\color{green}{\\cos \\theta} \u0026 \\color{green}0 \\newline \\color{blue}0 \u0026 \\color{blue}0 \u0026 \\color{blue}1 \\newline \\end{bmatrix} $$ 参考： 变换 ","date":"2023-03-21","objectID":"/opengl_matrix/:1:0","tags":["矩阵"],"title":"OpenGL中旋转矩阵","uri":"/opengl_matrix/"},{"categories":["C++","wxWidgets"],"content":"源码编译安装 前往wxWidgets官网，下载wxWidgets 打开Developer Command Prompt for VS 2022工具，进入 build\\msw 目录，编译 nmake /f makefile.vc BUILD=debug SHARED=0 TARGET_CPU=X64 这里我编译了64位debug版的静态库，这里x64和debug两个关键字很重要，你在VS中开发时，也要选择相应的配置 tip 在属性管理器窗口添加wxWidgets目录下的wxwidgets.props文件 tip 这里我们还需要额外注意一下，因为我们跑的是GUI程序，所以需要在项目的属性中，把项目设置成窗口 跑个简单的程序，hello.cpp // wxWidgets \"Hello world\" Program // For compilers that support precompilation, includes \"wx/wx.h\". #include \u003cwx/wxprec.h\u003e #ifndef WX_PRECOMP #include \u003cwx/wx.h\u003e #endif class MyApp : public wxApp { public: virtual bool OnInit(); }; class MyFrame : public wxFrame { public: MyFrame(const wxString\u0026 title, const wxPoint\u0026 pos, const wxSize\u0026 size); private: void OnHello(wxCommandEvent\u0026 event); void OnExit(wxCommandEvent\u0026 event); void OnAbout(wxCommandEvent\u0026 event); wxDECLARE_EVENT_TABLE(); }; enum { ID_Hello = 1 }; wxBEGIN_EVENT_TABLE(MyFrame, wxFrame) EVT_MENU(ID_Hello, MyFrame::OnHello) EVT_MENU(wxID_EXIT, MyFrame::OnExit) EVT_MENU(wxID_ABOUT, MyFrame::OnAbout) wxEND_EVENT_TABLE() wxIMPLEMENT_APP(MyApp); bool MyApp::OnInit() { MyFrame* frame = new MyFrame(\"Hello World\", wxPoint(50, 50), wxSize(450, 340)); frame-\u003eShow(true); return true; } MyFrame::MyFrame(const wxString\u0026 title, const wxPoint\u0026 pos, const wxSize\u0026 size) : wxFrame(NULL, wxID_ANY, title, pos, size) { wxMenu* menuFile = new wxMenu; menuFile-\u003eAppend(ID_Hello, \"\u0026Hello...\\tCtrl-H\", \"Help string shown in status bar for this menu item\"); menuFile-\u003eAppendSeparator(); menuFile-\u003eAppend(wxID_EXIT); wxMenu* menuHelp = new wxMenu; menuHelp-\u003eAppend(wxID_ABOUT); wxMenuBar* menuBar = new wxMenuBar; menuBar-\u003eAppend(menuFile, \"\u0026File\"); menuBar-\u003eAppend(menuHelp, \"\u0026Help\"); SetMenuBar(menuBar); CreateStatusBar(); SetStatusText(\"Welcome to wxWidgets!\"); } void MyFrame::OnExit(wxCommandEvent\u0026 event) { Close(true); } void MyFrame::OnAbout(wxCommandEvent\u0026 event) { wxMessageBox(\"This is a wxWidgets' Hello world sample\", \"About Hello World\", wxOK | wxICON_INFORMATION); } void MyFrame::OnHello(wxCommandEvent\u0026 event) { wxLogMessage(\"Hello world from wxWidgets!\"); } ","date":"2022-08-15","objectID":"/wxwidgets%E4%BD%BF%E7%94%A8/:1:0","tags":["C++"],"title":"wxWidgets使用","uri":"/wxwidgets%E4%BD%BF%E7%94%A8/"},{"categories":["Matrix","css"],"content":"css中应用 对元素的transform属性，我们可以应用矩阵 matrix(a,b,c,d,e,f) 这6参数，对应的矩阵就是： 注意书写方向是竖着的。 e, f参数其实就是x，y方向上偏移。 我们知道平面中旋转的矩阵是 那我们可以写个demo了 \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e \u003cstyle\u003e .square { height: 100px; width: 100px; background-color: red; transform: matrix(1, 0, 0, 1, 30, 30); } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ch2\u003eSquare CSS\u003c/h2\u003e \u003cdiv class=\"square\" id=\"square\"\u003e\u003c/div\u003e \u003c/body\u003e \u003cscript\u003e let angle = 0; // 弧度 let squareElement = document.getElementById(\"square\"); function getMatrix(angle) { return [Math.cos(angle), Math.sin(angle), -Math.sin(angle), Math.cos(angle), 0, 0]; } setInterval(() =\u003e { angle++; let items = getMatrix(angle).join(\",\"); squareElement.style.transform = `matrix(${items})`; }, 80); \u003c/script\u003e \u003c/html\u003e 上面展示了一个自动利用矩阵旋转的方块。 参考： 理解CSS3 transform中的Matrix(矩阵) 如何通俗地讲解「仿射变换」这个概念？ ","date":"2022-07-10","objectID":"/matrix/:1:0","tags":[],"title":"几何中矩阵","uri":"/matrix/"},{"categories":["Docker"],"content":"平常我们用的都是Linux Container，这些容器用的都是Linux的内核，而今天我们要记录的是Windows Container，就是讲这些容器用的是Windows的内核，Windows内核是啥？那就是Windows NT。 查看你的Windows内核版本，可以用 Get-ComputerInfo | Select WindowsProductName, WindowsVersion, WindowsInstallationType, OsServerLevel, OsVersion, OsHardwareAbstractionLayer 类似输出 WindowsProductName : Windows 10 Pro for Workstations WindowsVersion : 2009 WindowsInstallationType : Client OsServerLevel : OsVersion : 10.0.19044 OsHardwareAbstractionLayer : 10.0.19041.1566 上面NT的版本是10.0.19044。 环境 安装 .NET 6 SDK Windows Server 2022 Docker（针对Windows Server的docker，没有UI的） 安装一个喜欢的代码编辑器，例如 Visual Studio(Code)。 ","date":"2022-05-11","objectID":"/asp-net-in-windows-container/:0:0","tags":["Docker","WIndows"],"title":"ASP.NET in Windows Container","uri":"/asp-net-in-windows-container/"},{"categories":["Docker"],"content":"Docker 若要在 Windows Server 上安装 Docker，可以使用由 Microsoft 发布的 OneGet 提供程序 PowerShell 模块（称为 DockerMicrosoftProvider）。 此提供程序启用 Windows 中的容器功能，并安装 Docker 引擎和客户端。 以下是操作方法： 打开提升的 PowerShell 会话，从 PowerShell 库安装 Docker-Microsoft PackageManagement 提供程序。 Install-Module -Name DockerMsftProvider -Repository PSGallery -Force 如果系统提示安装 NuGet 提供程序，还请键入 Y 进行安装。 如果在打开 PowerShell 库时遇到错误，则可能需要将 PowerShell 客户端使用的 TLS 版本设置为 TLS 1.2。 为此，请运行以下命令： # Set the TLS version used by the PowerShell client to TLS 1.2. [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.SecurityProtocolType]::Tls12; 使用 PackageManagement PowerShell 模块安装最新版本的 Docker。 Install-Package -Name docker -ProviderName DockerMsftProvider PowerShell 询问是否信任包源“DockerDefault”时，键入 A 以继续进行安装。 在安装完成后，请重启计算机。 Restart-Computer -Force ","date":"2022-05-11","objectID":"/asp-net-in-windows-container/:1:0","tags":["Docker","WIndows"],"title":"ASP.NET in Windows Container","uri":"/asp-net-in-windows-container/"},{"categories":["Docker"],"content":"Windows Container 我们知道Linux容器的Base Image是alpine或者scratch， 那Windows容器的Base Image是什么呢？其实微软官方也有介绍了。 好了，我们进入正题。 要确保当前Docker是使用Windows Container的，我们可以拉个镜像 docker pull mcr.microsoft.com/windows/nanoserver:ltsc2022-amd64 如果看到错误消息“no matching manifest for linux/amd64 in the manifest list entries”，那说明 Docker 用的是Linux 容器。 注意：mcr.microsoft.com上的镜像在国内访问挺慢的，你可以先把镜像pull到阿里云，然后再在你电脑上拉取。 我们跑一个简单容器（执行cmd） docker run -it mcr.microsoft.com/windows/nanoserver:ltsc2022-amd64 cmd.exe 在容器中执行一些命令： C:\\\u003edir Volume in drive C has no label. Volume Serial Number is F63B-D098 Directory of C:\\ 05/05/2022 10:35 AM 5,510 License.txt 05/05/2022 10:37 AM \u003cDIR\u003e Users 05/11/2022 03:37 PM \u003cDIR\u003e Windows 1 File(s) 5,510 bytes 2 Dir(s) 21,302,714,368 bytes free C:\\\u003ehostname fbb1d7595c03 C:\\\u003eipconfig/all Windows IP Configuration Host Name . . . . . . . . . . . . : fbb1d7595c03 Primary Dns Suffix . . . . . . . : Node Type . . . . . . . . . . . . : Hybrid IP Routing Enabled. . . . . . . . : No WINS Proxy Enabled. . . . . . . . : No DNS Suffix Search List. . . . . . : lan Ethernet adapter vEthernet (Ethernet): Connection-specific DNS Suffix . : lan Description . . . . . . . . . . . : Hyper-V Virtual Ethernet Container Adapter Physical Address. . . . . . . . . : 00-15-5D-E5-CC-89 DHCP Enabled. . . . . . . . . . . : No Autoconfiguration Enabled . . . . : Yes Link-local IPv6 Address . . . . . : fe80::a0c8:ad95:72dd:fe6f%17(Preferred) IPv4 Address. . . . . . . . . . . : 172.30.150.168(Preferred) Subnet Mask . . . . . . . . . . . : 255.255.240.0 Default Gateway . . . . . . . . . : 172.30.144.1 DNS Servers . . . . . . . . . . . : 172.30.144.1 10.0.2.3 NetBIOS over Tcpip. . . . . . . . : Disabled Connection-specific DNS Suffix Search List : lan 可以看到，容器中目录还有hostname，网络都是隔离的。 ","date":"2022-05-11","objectID":"/asp-net-in-windows-container/:2:0","tags":["Docker","WIndows"],"title":"ASP.NET in Windows Container","uri":"/asp-net-in-windows-container/"},{"categories":["Docker"],"content":"运行一个ASP.NET程序 dotnet 6已经可以很方便的创建asp程序的骨架了，创建新目录myweb, 终端输入dotnet new web，然后sdk就帮你创建了一个hello world程序。 看一下Program.cs的内容： var builder = WebApplication.CreateBuilder(args); var app = builder.Build(); app.MapGet(\"/\", () =\u003e \"Hello World!\"); app.Run(); 恩，蛮简单的，我们在宿主机上运行dotnet run，输出 info: Microsoft.Hosting.Lifetime[14] Now listening on: https://localhost:7174 info: Microsoft.Hosting.Lifetime[14] Now listening on: http://localhost:5017 info: Microsoft.Hosting.Lifetime[0] Application started. Press Ctrl+C to shut down. info: Microsoft.Hosting.Lifetime[0] Hosting environment: Development info: Microsoft.Hosting.Lifetime[0] Content root path: /your_path/myweb/ curl http://localhost:5017返回了Hello World!，速度阔以的。 为了在Docker中运行程序，我们需要创建一个Dockerfile FROM mcr.microsoft.com/dotnet/sdk:6.0 AS build-env WORKDIR /app # Copy everything COPY . ./ # Restore as distinct layers RUN dotnet restore # Build and publish a release RUN dotnet publish -c Release -o out # Build runtime image FROM mcr.microsoft.com/dotnet/aspnet:6.0 WORKDIR /app COPY --from=build-env /app/out . ENTRYPOINT [\"dotnet\", \"myweb.dll\"] 当然，为了docker build能快点，我们应该添加一个.dockerignore文件 # Build results [Dd]ebug/ [Rr]elease/ x64/ [Bb]in/ [Oo]bj/ # build folder is nowadays used for build scripts and should not be ignored #build/ # NuGet Packages *.nupkg # The packages folder can be ignored because of Package Restore **/packages/* # except build/, which is used as an MSBuild target. !**/packages/build/ # Uncomment if necessary however generally it will be regenerated when needed #!**/packages/repositories.config # MSTest test Results [Tt]est[Rr]esult*/ [Bb]uild[Ll]og.* 好了，现在执行docker build -t fuck_image .，构建镜像成功后，可以看到 PS C:\\Users\\Administrator\u003e docker images REPOSITORY TAG IMAGE ID CREATED SIZE fuck_image latest a8b482b53388 5 hours ago 392MB 我们跑个容器docker run -d --name fuck_asp fuck_image，查看容器日志docker logs fuck_asp，发现它的http端口是80 info: Microsoft.Hosting.Lifetime[14] Now listening on: http://[::]:80 info: Microsoft.Hosting.Lifetime[0] Application started. Press Ctrl+C to shut down. info: Microsoft.Hosting.Lifetime[0] Hosting environment: Production info: Microsoft.Hosting.Lifetime[0] Content root path: C:\\app\\ 进入容器执行curl docker exec -it fuck_asp cmd.exe C:\\app\u003ecurl http://localhost Hello World! OK了。 注：你的Windows Server如果是跑在虚拟机中的，获取虚拟机的ip有个命令：VBoxManage guestproperty get \"Win Server2022\" \"/VirtualBox/GuestInfo/Net/0/V4/IP\" 参考： 入门：准备适用于容器的 Windows Tutorial: Containerize a .NET app ","date":"2022-05-11","objectID":"/asp-net-in-windows-container/:3:0","tags":["Docker","WIndows"],"title":"ASP.NET in Windows Container","uri":"/asp-net-in-windows-container/"},{"categories":["OS"],"content":"Bochs Bochs是一个x86硬件平台的开源模拟器。你可以当它是一台虚拟的x86的计算机。 本文环境： OS: Ubuntu 20.04.4 LTS Bochs： 2.6.9 ","date":"2022-04-17","objectID":"/bochs%E4%B8%8B%E5%90%AF%E5%8A%A8/:0:0","tags":["OS"],"title":"bochs下启动自己的MBR","uri":"/bochs%E4%B8%8B%E5%90%AF%E5%8A%A8/"},{"categories":["OS"],"content":"安装Bochs 这个网上教程很多了，先去下载，然后configure： ./configure \\ --prefix=/your_path/bochs \\ --enable-debugger\\ --enable-disasm \\ --enable-iodebug \\ --enable-x86-debugger \\ --with-x \\ --with-x11 这里会出点问题，一般是缺少库了： sudo apt-get install libx11-dev ................. for X11/Xlib.h sudo apt-get install mesa-common-dev........ for GL/glx.h sudo apt-get install libglu1-mesa-dev ..... for GL/glu.h sudo apt-get install libxrandr-dev ........... for X11/extensions/Xrandr.h sudo apt-get install libxi-dev ................... for X11/extensions/XInput.h configure通过就可以编译安装了： make sudo make install ","date":"2022-04-17","objectID":"/bochs%E4%B8%8B%E5%90%AF%E5%8A%A8/:1:0","tags":["OS"],"title":"bochs下启动自己的MBR","uri":"/bochs%E4%B8%8B%E5%90%AF%E5%8A%A8/"},{"categories":["OS"],"content":"配置 当我们在终端输入bochs后， Bochs会自己在当前目录顺序寻找以下文件作为默认配置文件： .bochsrc bochsrc bochsrc.txt bochsrc.bxrc(仅对Windows有效) 我们可以自己创建一个名为.bochsrc的文件，来指定Bochs配置我们想要的虚拟机。 [~/bochs_fun]$ cat bochsrc ################################################################# # Bochs的配置文件 # Configuration file for Bochs ################################################################# # how much memory the emulated machine will have megs: 32 # filenameof ROM images romimage:file=/usr/local/share/bochs/BIOS-bochs-latest vgaromimage:file=/usr/local/share/bochs/VGABIOS-lgpl-latest # which disk image will be used 这个是启动软盘 floppya:1_44=a.img, status=inserted # choose the boot disk 确定启动方式 #boot: floppy boot: disk # where do we send log messages? log: bochsout.txt # disable the mouse mouse: enabled=0 # enable key mapping ,using US layout as default keyboard:keymap=/usr/local/share/bochs/keymaps/x11-pc-us.map # 硬盘设置 ata0: enabled=1, ioaddr1=0x1f0, ioaddr2=0x3f0, irq=14 ","date":"2022-04-17","objectID":"/bochs%E4%B8%8B%E5%90%AF%E5%8A%A8/:2:0","tags":["OS"],"title":"bochs下启动自己的MBR","uri":"/bochs%E4%B8%8B%E5%90%AF%E5%8A%A8/"},{"categories":["OS"],"content":"测试开机 按c继续运行，弹出新的窗口。 ","date":"2022-04-17","objectID":"/bochs%E4%B8%8B%E5%90%AF%E5%8A%A8/:3:0","tags":["OS"],"title":"bochs下启动自己的MBR","uri":"/bochs%E4%B8%8B%E5%90%AF%E5%8A%A8/"},{"categories":["OS"],"content":"MBR MBR：Master Boot Record，主分区引导记录，它是整个硬盘最开始的扇区，即0柱面0磁头1扇区（CHS表示方法，如果是LBA的话，那就是0扇区）。 扇区是什么？那就涉及到硬盘基本知识了，对于机械硬盘，有以下概念： 盘片（platter） 磁头（head） 磁道（track） 扇区（sector） 柱面（cylinder） 盘片 片面 和 磁头（Head） 硬盘中一般会有多个盘片组成，每个盘片包含两个面，每个盘面都对应地有一个读/写磁头。受到硬盘整体体积和生产成本的限制，盘片数量都受到限制，一般都在5片以内。盘片的编号自下向上从0开始，如最下边的盘片有0面和1面，再上一个盘片就编号为2面和3面。 扇区（Sector）和 磁道（Track） 下图显示的是一个盘面，盘面中一圈圈灰色同心圆为一条条磁道，从圆心向外画直线，可以将磁道划分为若干个弧段，每个磁道上一个弧段被称之为一个扇区（图践绿色部分）。扇区是磁盘的最小组成单元，通常是512字节。（由于不断提高磁盘的大小，部分厂商设定每个扇区的大小是4096字节） 磁头（Head）和 柱面（Cylinder） 硬盘通常由重叠的一组盘片构成，每个盘面都被划分为数目相等的磁道，并从外缘的“0”开始编号，具有相同编号的磁道形成一个圆柱，称之为磁盘的柱面。磁盘的柱面数与一个盘面上的磁道数是相等的。由于每个盘面都有自己的磁头，因此，盘面数等于总的磁头数。 如下图 图3 所谓CHS即柱面（cylinder），磁头（header），扇区（sector），通过这三个变量描述磁盘地址（先定位柱面，然后选定磁头，然后确定扇区），需要明白的是，这里表示的已不是物理地址而是逻辑地址了。这种方法也称作是LARGE寻址方式。该方法下： 硬盘容量=磁头数×柱面数×扇区数×扇区大小（一般为512byte）。 后来，人们通过为每个扇区分配逻辑地址，以扇区为单位进行寻址，也就有了LBA寻址方式。但是为了保持与CHS模式的兼容，通过逻辑变换算法，可以转换为磁头/柱面/扇区三种参数来表示，和 LARGE寻址模式一样，这里的地址也是逻辑地址了。（固态硬盘的存储原理虽然与机械硬盘不同，采用的是flash存储，但仍然使用LBA进行管理，此处不再详述。） 好了，再回来说MBR，MBR(Master Boot Record)是传统的分区机制，应用于绝大多数使用BIOS引导的PC设备（苹果使用EFI的方式），很多Server服务器即支持BIOS也支持EFI的引导方式。它的结构如下： MBR结构：占用硬盘最开头的512字节 * 前446字节为：引导代码（Bootstrap Code Area）（引导不同的操作系统；不同操作系统，引导代码是不一样的） 接下来的为4个16字节：分别对应4个主分区表信息(Primary Partition Table) 最后2个字节：为启动标示（Boot Signature），永远都是55和AA；55和ＡＡ是个永久性的标示，代表这个硬盘是可启动的。 ","date":"2022-04-17","objectID":"/bochs%E4%B8%8B%E5%90%AF%E5%8A%A8/:4:0","tags":["OS"],"title":"bochs下启动自己的MBR","uri":"/bochs%E4%B8%8B%E5%90%AF%E5%8A%A8/"},{"categories":["OS"],"content":"主引导代码 BIOS在完成一些简单的检测工作或初始化工作后，会把处理器使用权交出去，下一棒就是MBR程序。BIOS会把MBR加载到0x7c00的位置，然后执行里头代码（jmp 0:0x7c00）。 mbr.S文件： ;主引导程序 ;------------------------------------------------------------ SECTION MBR vstart=0x7c00 mov ax,cs mov ds,ax mov es,ax mov ss,ax mov fs,ax mov sp,0x7c00 ; 清屏 利用0x06号功能，上卷全部行，则可清屏。 ; ----------------------------------------------------------- ;INT 0x10 功能号:0x06 功能描述:上卷窗口 ;------------------------------------------------------ ;输入： ;AH 功能号= 0x06 ;AL = 上卷的行数(如果为0,表示全部) ;BH = 上卷行属性 ;(CL,CH) = 窗口左上角的(X,Y)位置 ;(DL,DH) = 窗口右下角的(X,Y)位置 ;无返回值： mov ax, 0x600 mov bx, 0x700 mov cx, 0 ; 左上角: (0, 0) mov dx, 0x184f ; 右下角: (80,25), ; VGA文本模式中,一行只能容纳80个字符,共25行。 ; 下标从0开始,所以0x18=24,0x4f=79 int 0x10 ; int 0x10 ;;;;;;;;; 下面这三行代码是获取光标位置 ;;;;;;;;; ;.get_cursor获取当前光标位置,在光标位置处打印字符. mov ah, 3 ; 输入: 3号子功能是获取光标位置,需要存入ah寄存器 mov bh, 0 ; bh寄存器存储的是待获取光标的页号 int 0x10 ; 输出: ch=光标开始行,cl=光标结束行 ; dh=光标所在行号,dl=光标所在列号 ;;;;;;;;; 获取光标位置结束 ;;;;;;;;;;;;;;;; ;;;;;;;;; 打印字符串 ;;;;;;;;;;; ;还是用10h中断,不过这次是调用13号子功能打印字符串 mov ax, message mov bp, ax ; es:bp 为串首地址, es此时同cs一致， ; 开头时已经为sreg初始化 ; 光标位置要用到dx寄存器中内容,cx中的光标位置可忽略 mov cx, 0xb ; cx 为串长度,不包括结束符0的字符个数 mov ax, 0x1301 ; 子功能号13是显示字符及属性,要存入ah寄存器, ; al设置写字符方式 ah=01: 显示字符串,光标跟随移动 mov bx, 0x2 ; bh存储要显示的页号,此处是第0页, ; bl中是字符属性, 属性黑底绿字(bl = 02h) int 0x10 ; 执行BIOS 0x10 号中断 ;;;;;;;;; 打字字符串结束 ;;;;;;;;;;;;;;; jmp $ ; 使程序悬停在此 message db \"love rabbit\" times 510-($-$$) db 0 db 0x55,0xaa 用nasm编译成纯二进制文件nasm -o mbr.bin mbr.S，可以查看mbr.bin文件大小，正好512个字节。 然后利用dd命令把bin文件写进磁盘的0柱面0磁头1扇区： dd if=/your_path/bochs_fun/mbr.bin of=/your_path/bochs_fun/hd60M.img bs=512 count=1 conv=notrunc ","date":"2022-04-17","objectID":"/bochs%E4%B8%8B%E5%90%AF%E5%8A%A8/:5:0","tags":["OS"],"title":"bochs下启动自己的MBR","uri":"/bochs%E4%B8%8B%E5%90%AF%E5%8A%A8/"},{"categories":["OS"],"content":"增加磁盘读写 mbr.S ;主引导程序 ;------------------------------------------------------------ %include \"boot.inc\" SECTION MBR vstart=0x7c00 mov ax,cs mov ds,ax mov es,ax mov ss,ax mov fs,ax mov sp,0x7c00 mov ax,0xb800 mov gs,ax ; 清屏 ;利用0x06号功能，上卷全部行，则可清屏。 ; ----------------------------------------------------------- ;INT 0x10 功能号:0x06 功能描述:上卷窗口 ;------------------------------------------------------ ;输入： ;AH 功能号= 0x06 ;AL = 上卷的行数(如果为0,表示全部) ;BH = 上卷行属性 ;(CL,CH) = 窗口左上角的(X,Y)位置 ;(DL,DH) = 窗口右下角的(X,Y)位置 ;无返回值： mov ax, 0600h mov bx, 0700h mov cx, 0 ; 左上角: (0, 0) mov dx, 184fh ; 右下角: (80,25), ; 因为VGA文本模式中，一行只能容纳80个字符,共25行。 ; 下标从0开始，所以0x18=24,0x4f=79 int 10h ; int 10h ; 输出字符串:MBR mov byte [gs:0x00],'1' mov byte [gs:0x01],0xA4 mov byte [gs:0x02],' ' mov byte [gs:0x03],0xA4 mov byte [gs:0x04],'M' mov byte [gs:0x05],0xA4 ;A表示绿色背景闪烁，4表示前景色为红色 mov byte [gs:0x06],'B' mov byte [gs:0x07],0xA4 mov byte [gs:0x08],'R' mov byte [gs:0x09],0xA4 mov eax,LOADER_START_SECTOR ; 起始扇区lba地址 mov bx,LOADER_BASE_ADDR ; 写入的地址 mov cx,1 ; 待读入的扇区数 call rd_disk_m_16 ; 以下读取程序的起始部分（一个扇区） jmp LOADER_BASE_ADDR ;------------------------------------------------------------------------------- ;功能:读取硬盘n个扇区 rd_disk_m_16: ;------------------------------------------------------------------------------- ; eax=LBA扇区号 ; ebx=将数据写入的内存地址 ; ecx=读入的扇区数 mov esi,eax ;备份eax mov di,cx ;备份cx ;读写硬盘: ;第1步：设置要读取的扇区数 mov dx,0x1f2 mov al,cl out dx,al ;读取的扇区数 mov eax,esi ;恢复ax ;第2步：将LBA地址存入0x1f3 ~ 0x1f6 ;LBA地址7~0位写入端口0x1f3 mov dx,0x1f3 out dx,al ;LBA地址15~8位写入端口0x1f4 mov cl,8 shr eax,cl mov dx,0x1f4 out dx,al ;LBA地址23~16位写入端口0x1f5 shr eax,cl mov dx,0x1f5 out dx,al shr eax,cl and al,0x0f ;lba第24~27位 or al,0xe0 ; 设置7～4位为1110,表示lba模式 mov dx,0x1f6 out dx,al ;第3步：向0x1f7端口写入读命令，0x20 mov dx,0x1f7 mov al,0x20 out dx,al ;第4步：检测硬盘状态 .not_ready: ;同一端口，写时表示写入命令字，读时表示读入硬盘状态 nop in al,dx and al,0x88 ;第4位为1表示硬盘控制器已准备好数据传输，第7位为1表示硬盘忙 cmp al,0x08 jnz .not_ready ;若未准备好，继续等。 ;第5步：从0x1f0端口读数据 mov ax, di mov dx, 256 mul dx mov cx, ax ; di为要读取的扇区数，一个扇区有512字节，每次读入一个字， ; 共需di*512/2次，所以di*256 mov dx, 0x1f0 .go_on_read: in ax,dx mov [bx],ax add bx,2 loop .go_on_read ret times 510-($-$$) db 0 db 0x55,0xaa boot.inc文件 ;------------- loader和kernel ---------- LOADER_BASE_ADDR equ 0x900 LOADER_START_SECTOR equ 0x2 最后CPU会调到0x900的地址，还得有个loader %include \"boot.inc\" section loader vstart=LOADER_BASE_ADDR ; 输出背景色绿色，前景色红色，并且跳动的字符串\"1 MBR\" mov byte [gs:0x20],'2' mov byte [gs:0x21],0xA4 ; A表示绿色背景闪烁，4表示前景色为红色 mov byte [gs:0x22],' ' mov byte [gs:0x23],0xA4 mov byte [gs:0x24],'L' mov byte [gs:0x25],0xA4 mov byte [gs:0x26],'O' mov byte [gs:0x27],0xA4 mov byte [gs:0x28],'A' mov byte [gs:0x29],0xA4 mov byte [gs:0x2a],'D' mov byte [gs:0x2b],0xA4 mov byte [gs:0x2c],'E' mov byte [gs:0x2d],0xA4 mov byte [gs:0x2e],'R' mov byte [gs:0x2f],0xA4 jmp $ ; 通过死循环使程序悬停在此 参考： OS篇-Bochs在Ubuntu下的安装教程 Ubuntu20.04/18.04安装Bochs2.6.9编译运行GeekOS 柱面-磁头-扇区寻址的一些旧事 MBR与GPT ","date":"2022-04-17","objectID":"/bochs%E4%B8%8B%E5%90%AF%E5%8A%A8/:6:0","tags":["OS"],"title":"bochs下启动自己的MBR","uri":"/bochs%E4%B8%8B%E5%90%AF%E5%8A%A8/"},{"categories":null,"content":"x86汇编 8086的指令在32/64位的x86 CPU上都是能用的，所以汇编代码是类似的，80836之后的CPU 保护模式下段寄存器就不重要了，平常用的多的就是那8个通用寄存器（为啥用不到CS, DS, ES等寄存器了，请看这里）： 通用寄存器 含义 低8位 功能 EAX 累加(Accumulator)寄存器 AX(AH、AL) 常用于乘、除法和函数返回值 EBX 基址(Base)寄存器 BX(BH、BL) 常做内存数据的指针, 或者说常以它为基址来访问内存. ECX 计数器(Counter)寄存器 CX(CH、CL) 常做字符串和循环操作中的计数器 EDX 数据(Data)寄存器 DX(DH、DL) 常用于乘、除法和 I/O 指针 ESI 来源索引(Source Index)寄存器 SI 常做内存数据指针和源字符串指针 EDI 目的索引(Destination Index)寄存器 DI 常做内存数据指针和目的字符串指针 ESP 堆栈指针(Stack Point)寄存器 SP 只做堆栈的栈顶指针; 不能用于算术运算与数据传送 EBP 基址指针(Base Point)寄存器 BP 只做堆栈指针, 可以访问堆栈内任意地址, 经常用于中转 ESP 中的数据, 也常以它为基址来访问堆栈; 不能用于算术运算与数据传送 64位CPU兼容32位的程序，所有下面的程序都是32位的，汇编器用的是NASM。 ","date":"2022-04-08","objectID":"/win32_assembly/:1:0","tags":null,"title":"x86汇编","uri":"/win32_assembly/"},{"categories":null,"content":"调用MessageBox ; Message Box, 32 bit. V1.01 NULL EQU 0 ; Constants MB_DEFBUTTON1 EQU 0 MB_DEFBUTTON2 EQU 100h IDNO EQU 7 MB_YESNO EQU 4 extern _MessageBoxA@16 ; Import external symbols，在“@”之后的数字表示了该函数所有参数的尺寸（字节为单位） extern _ExitProcess@4 ; Windows API functions, decorated global Start ; Export symbols. The entry point section .data ; Initialized data segment MessageBoxText db \"Do you want to exit?\", 0 MessageBoxCaption db \"MessageBox 32\", 0 section .text ; Code segment Start: push MB_YESNO | MB_DEFBUTTON2 ; 4th parameter. 2 constants ORed together push MessageBoxCaption ; 3rd parameter push MessageBoxText ; 2nd parameter push NULL ; 1st parameter call _MessageBoxA@16 cmp EAX, IDNO ; Check the return value for \"No\" je Start push NULL call _ExitProcess@4 用nasm编译nasm -f win32 fun.asm -o fun.obj 用golink链接golink /entry:Start kernel32.dll user32.dll fun.obj 参考： nasm-messagebox32 ","date":"2022-04-08","objectID":"/win32_assembly/:2:0","tags":null,"title":"x86汇编","uri":"/win32_assembly/"},{"categories":[],"content":" INT表示interrupt（中断）， INT指令是X86汇编语言中最重要的指令之一，它的作用是引发中断，调用“中断例程”（interrupt routine）。 中断是由于软件或硬件的信号，使CPU暂停执行当前的任务，转而去执行另一段子程序。 硬中断（外中断）：由外部设备，如网卡、硬盘随机引发的，比如网卡收到数据包的时候，就会发出一个中断。 软中断（内中断）：由执行中的指令产生的，可以通过程序控制触发。 可以通过 “ INT 中断码 ” 实现中断，内存中有一张中断向量表，用来存放中断码处理中断程序的入口地址。CPU在接受到中断信号后，暂停当前正在执行的程序，跳转到中断码对应的向量表地址处去执行中断。 我们理解上可以当INT就是调用系统内置的一些功能。 常用的中断： INT 21H：DOS系统功能调用 INT 10H：BIOS终端调用 INT 3H：断点中断，用于调试程序 这篇文章重点记录下DOS的系统功能调用，也就是INT 21H。 本文环境： 操作系统：虚拟机中的Windows 10 Visual Studio Code VSCode 插件：MASM/TASM 这个插件还蛮方便的，省去了自己配环境的麻烦，右键单击文件选择Run ASM code就可以执行代码： DOS系统功能调用格式都是一致的，步骤如下： 在AH寄存器中设置系统功能调用号。 在指定的寄存器中设置入口参数。 用INT 21H指令执行功能调用。 根据出口参数分析功能调用执行情况。 ","date":"2022-03-05","objectID":"/assembly_int21h/:0:0","tags":["Assembly"],"title":"DOS 系统功能调用（INT 21H）","uri":"/assembly_int21h/"},{"categories":[],"content":"常见功能 DOS 系统功能调用 INT 21H，有数百种功能供用户使用。下面介绍几个常用的 DOS 系统功能调用，简要描述如表所示。 4C肯定天天用，毕竟用来返回DOS的，这里写点其他功能的例子。 ","date":"2022-03-05","objectID":"/assembly_int21h/:1:0","tags":["Assembly"],"title":"DOS 系统功能调用（INT 21H）","uri":"/assembly_int21h/"},{"categories":[],"content":"一些例子 汇编代码中，指令和寄存器名大写和小写没关系，所以这里ah和AH，dx和DX也没问题。但是4H和4还是有点不一样的，4H是16进制，不带h表示10进制。 显示一个字符 assume cs:code, ds:data ; 数据段 data segment message db 'hello' data ends ; 代码段 code segment start: mov ax, data mov ds, ax mov dl, ds:[1h] ;调用DOS系统功能，2表示输出DL寄存器的字符到显示器 mov ah, 2h int 21h ;返回DOS mov ah, 4ch int 21h code ends end start 这个程序会输出一个e的字符。 打印hello world 代码是用别人的，他的注释写的蛮好的： ; 注：这里的关联并没有任何实际操作，相当于给我们自己的注释而已 ; 相当于即使不写这一行也没有关系 assume cs:code, ds:data ; 数据段 data segment ; 创建字符串 ; 汇编打印字符串要在尾部用 $ 标记字符串的结束位置 ; 将字符串用hello做一个标记，方便后面使用它 hello db 'Hello World!$' data ends ; 代码段 code segment ; 指令执行的起始，类似于C语言的main函数入口 start: ; 汇编语言不会自动把数据段寄存器指向我们程序的数据段 ; 将数据段寄存器指向我们自己程序的数据段 mov ax, data mov ds, ax ; 打印字符串的参数 ; DS:DX=串地址，将字符串的偏移地址传入dx寄存器 ; 字符串是在数据段起始创建的，它的偏移地址是0H ; offset hello 即找到标记为hello的数据段字符串的编译地址 ; 还可以写成 mov dx, 0H mov dx, offset hello ; 打印字符串，ah=9H代表打印 mov ah, 9h int 21h ; 正常退出程序，相当于高级语言的 return 0 mov ah, 4ch int 21h code ends end start 读取键盘输入两个数求和 这个例子复杂了点 assume cs:code, ds:data, ss:stack stack segment dw 30h dup(0) stack ends ; 数据段 data segment buf db 20h, 0, 20h dup (0) message db 'input a number:$' num dw ? data ends code segment start: mov ax, data mov ds, ax call printMsg call readInput call atoi push num ; again call printMsg call readInput call atoi push num ; cal summ call sum call printAx mov ah, 4ch int 21h printMsg: mov dx, offset message mov ah, 9h int 21h ret readInput: ; first byte to tell dos maximum characters buffer can hold mov dx, 0h mov ah, 0Ah int 21h ; print \\n mov dl, 0Ah mov ah, 02h int 21h ret atoi proc mov dx,0 mov bx,10 mov si,2 mov num,0 mov ax,0 lop: mov al,buf[si] cmp al,0Dh je final sub al,30h cmp num,0 je do_delta push ax mov ax,num mul bx mov num,ax pop ax do_delta: add num,ax mov ax,0 inc si jmp lop final: ret atoi endp ; 内平衡 sum: mov bp, sp mov ax, ss:[bp+2] add ax, ss:[bp+4] ret 4 printAx proc ;initialize count mov cx,0 mov dx,0 label1: ; if ax is zero cmp ax,0 je print1 mov bx,10 div bx ;push it in the stack push dx ;increment the count inc cx ;set dx to 0 xor dx,dx jmp label1 print1: ;check if count ;is greater than zero cmp cx,0 je exit ;pop the top of stack pop dx ;add 48 so that it ;represents the ASCII ;value of digits add dx,48 ; print character mov ah,02h int 21h ;decrease the count dec cx jmp print1 exit: ret printAx endp code ends end start ","date":"2022-03-05","objectID":"/assembly_int21h/:2:0","tags":["Assembly"],"title":"DOS 系统功能调用（INT 21H）","uri":"/assembly_int21h/"},{"categories":[],"content":"调试工具DEBUG常用命令 R ——查看和修改寄存器 D ——查看内存单元 内存每16个字节单元为一小段，逻辑段必须从小段的首址开始。用D命令可以查看存储单元的地址和内容。 D命令格式为： D 段地址:起始偏移地址 [结尾偏移地址] [L范围] 例如： D DS:0 查看数据段，从0号单元开始 D ES:0 查看附加段，从0号单元开始 D DS:100 查看数据段，从100H号单元开始 D 0200:5 15 查看0200H段的5号单元到15H号单元（在虚拟机上该命令不能执行） D 0200:5 L 11 用L选择范围。查看0200H段的5号单元到15H号单元共10个单元 T /P——单步执行 P可以跳过子程序或系统调用，其他方面T和P是类型的。 参考： 从零入门8086汇编 调试工具DEBUG ","date":"2022-03-05","objectID":"/assembly_int21h/:3:0","tags":["Assembly"],"title":"DOS 系统功能调用（INT 21H）","uri":"/assembly_int21h/"},{"categories":["nodejs"],"content":"在开始之前，我们先了解下什么是 Core 和 Core Dump。 什么是 Core? 在使用半导体作为内存材料前，人类是利用线圈当作内存的材料，线圈就叫作 core ，用线圈做的内存就叫作 core memory。如今 ，半导体工业澎勃发展，已经没有人用 core memory 了，不过在许多情况下， 人们还是把记忆体叫作 core 。 什么是 Core Dump? 当程序运行的过程中异常终止或崩溃，操作系统会将程序当时的内存状态记录下来，保存在一个文件中，这种行为就叫做 Core Dump（中文有的翻译成 “核心转储”)。我们可以认为 Core Dump 是 “内存快照”，但实际上，除了内存信息之外，还有些关键的程序运行状态也会同时 dump 下来，例如寄存器信息（包括程序指针、栈指针等）、内存管理信息、其他处理器和操作系统状态和信息。Core Dump 对于编程人员诊断和调试程序是非常有帮助的，因为对于有些程序错误是很难重现的，例如指针异常，而 Core Dump 文件可以再现程序出错时的情景。 在Node生成core dump文件有两步 先开启core dump ulimit -c unlimited ulimit -c设置允许 Core Dump 生成的文件的大小，如果是 0 则表示关闭了 Core Dump。unlimited表示无限制。 gcore 第二步我们可以用gcore命令（需要装gdb）不重启程序生成core dump文件： gcore [-o filename] pid 但在容器中，gcore命令会报错。 参考： Node.js 调试指南 ","date":"2021-07-27","objectID":"/core_dump_in_docker/:0:0","tags":["nodejs"],"title":"Node.js：容器中Core Dump","uri":"/core_dump_in_docker/"},{"categories":["Javascript"],"content":"安装 安装TypeScript还是很简单的： npm install -g typescript 写个hello.ts function sayHello(person: string) { return 'Hello, ' + person; } let user = 'Tom'; console.log(sayHello(user)); 然后执行 tsc hello.ts 这时候会生成一个编译好的文件 hello.js： function sayHello(person) { return 'Hello, ' + person; } var user = 'Tom'; console.log(sayHello(user)); 可以看到，编译好后的就是平常的js代码，TS的一个优点在于类型的声明，这样在编译期bug就能及早发现（当然还有其他好处，例如泛型，Enum，装饰器）。 注意： TypeScript 只会在编译时对类型进行静态检查，如果发现有错误，编译的时候就会报错。而在运行时，与普通的 JavaScript 文件一样，不会对类型进行检查。 ","date":"2021-06-05","objectID":"/typescript_learn/:1:0","tags":["Typescript"],"title":"Typescript学习","uri":"/typescript_learn/"},{"categories":["Javascript"],"content":"复杂点 构建一个TypeScript的项目就需要tsconfig.json文件了。如果一个目录下存在一个tsconfig.json文件，那么它意味着这个目录是TypeScript项目的根目录。 创建一个简单的项目，目录结构如下： MyProj ├── src │ ├── index.ts │ ├── person.ts │ ├── animal.js ├── package.json ├── tsconfig.json ├── .eslintrc.js tsconfig.json文件 { \"compilerOptions\": { \"target\": \"ES2018\", // 指定ECMAScript目标版本 \"module\": \"commonjs\", \"moduleResolution\": \"node\", \"experimentalDecorators\": true, // 开启装饰器 \"strict\": true, // 启用所有严格类型检查选项 \"noImplicitAny\": false, \"removeComments\": true, // 移除注释 \"sourceMap\": false, \"rootDir\": \"src\", // Default: The longest common path of all non-declaration input files. \"outDir\": \"dist\", // 编译输出目录 \"allowJs\": true // 允许JS文件混合 }, \"include\": [\"src/**/*\"], // 指定要编译文件 \"exclude\": [\"node_modules\"] // 指定要排除的编译文件 } person.ts export class Person { private name: string; private age: number; constructor(name: string, age: number) { this.name = name; this.age = age; } getName() { return this.name; } } export interface Payload { title: string; description: string; } index.ts import { Person, Payload } from './person'; import { Animal } from './animal'; const p = new Person('sala', 12); const data: Payload = { title: 'One', description: 'happy...' }; type StringOrNumber = string | number; function getString(n: StringOrNumber): string { if (typeof n === 'string') { return n; } else { return n.toString(); } } const animal = new Animal('Kitty'); animal.js export class Animal { constructor(name) { this.name = name; } sayHi() { return 'hello!'; } } package.json { \"name\": \"ts_learn_project\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"dependencies\": {}, \"devDependencies\": { \"@typescript-eslint/eslint-plugin\": \"^4.22.0\", \"@typescript-eslint/parser\": \"^4.22.0\", \"eslint\": \"^7.24.0\", \"typescript\": \"^4.2.4\", \"mwts\": \"^1.0.5\" }, \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" \u0026\u0026 exit 1\", \"eslint\": \"eslint src --ext .ts\", \"build\": \"tsc\" }, \"keywords\": [ \"typescript\" ], \"author\": \"salamander\", \"license\": \"ISC\" } .eslintrc.js module.exports = { parser: \"@typescript-eslint/parser\", plugins: [\"@typescript-eslint\"], rules: { // 禁止使用 var \"no-var\": \"error\", // 优先使用 interface 而不是 type \"@typescript-eslint/consistent-type-definitions\": [\"error\", \"interface\"], }, }; 2019 年 1 月，TypeScirpt 官方决定全面采用 ESLint 作为代码检查的工具，并创建了一个新项目 typescript-eslint，提供了 TypeScript 文件的解析器 @typescript-eslint/parser 和相关的配置选项 @typescript-eslint/eslint-plugin 等。 参考： TypeScript 中文手册 tsconfig ","date":"2021-06-05","objectID":"/typescript_learn/:2:0","tags":["Typescript"],"title":"Typescript学习","uri":"/typescript_learn/"},{"categories":["RabbitMQ"],"content":"业务需求 有时候我们需要某些任务定时执行，譬如取消订单，5分钟没支付，这个订单就被取消。简单实现的话，我们可以使用Redis或Linux的crontab来实现，而对于RabbitMQ，我们则可以用它的死信队列来实现定时任务。 ","date":"2021-03-20","objectID":"/rabbitmq_dlx/:1:0","tags":["RabbitMQ"],"title":"RabbitMQ四五事之死信队列","uri":"/rabbitmq_dlx/"},{"categories":["RabbitMQ"],"content":"DLX RabbitMQ 中有一种交换器叫 DLX，全称为 Dead-Letter-Exchange，可以称之为死信交换器。当消息在一个队列中变成死信（dead message）之后，它会被重新发送到另外一个交换器中，这个交换器就是 DLX，绑定在 DLX 上的队列就称之为死信队列。 消息变成死信一般是以下几种情况： 消息被拒绝，并且设置 requeue 参数为 false 消息过期 队列达到最大长度 DLX其实就是一个普通的交换器，要使用它也很简单，就是在声明某个队列的时候设置其 deadLetterExchange 和 deadLetterRoutingKey 参数，deadLetterRoutingKey 参数可选，表示为 DLX 指定的路由键，如果没有特殊指定，则使用原队列的路由键。这样设置后，这个队列的消息一过期，RabbitMQ 就会自动地将这个消息重新发布到设置的 DLX 上去，进而被路由到另一个队列，即死信队列。 ","date":"2021-03-20","objectID":"/rabbitmq_dlx/:2:0","tags":["RabbitMQ"],"title":"RabbitMQ四五事之死信队列","uri":"/rabbitmq_dlx/"},{"categories":["RabbitMQ"],"content":"简单例子 用之前文章RabbitMQ二三事快速启动RabbitMQ的服务，再把RabbitMQ三四事的代码改造下。 producer.js const config = require(\"./config\"); const amqp = require('amqplib'); async function getMQConnection() { return await amqp.connect({ protocol: 'amqp', hostname: config.host, port: config.port, username: config.user, password: config.pass, locale: 'en_US', frameMax: 0, heartbeat: 5, // 心跳 vhost: config.vhost, }) } async function run(rmqConn, msgObj) { const noramlQueue = 'noramlQu'; const noramlExchange = 'noramlEx'; const exchangeDLX = 'testExDLX'; const queueDLX = 'testQueueDLX'; const routingKeyDLX = 'testRoutingKeyDLX'; try { const channel = await rmqConn.createChannel(); // 声明死信交换器和队列，就跟普通的一样 await channel.assertExchange(exchangeDLX, 'direct', { durable: true, autoDelete: false }); await channel.assertQueue(queueDLX, {durable: true, autoDelete: false, }); await channel.bindQueue(queueDLX, exchangeDLX, routingKeyDLX); // 普通交换器和队列 await channel.assertExchange(noramlExchange, 'direct', { durable: true, autoDelete: false }) await channel.assertQueue(noramlQueue, {durable: true, autoDelete: false, deadLetterExchange: exchangeDLX, deadLetterRoutingKey: routingKeyDLX, }); // 队列设置DLX await channel.bindQueue(noramlQueue, noramlExchange, noramlQueue); // 发送消息 await channel.publish(noramlExchange, noramlQueue, Buffer.from(msgObj.content), { expiration: msgObj.expiration, // 过期时间，ms persistent: true, mandatory: true, }); console.log('send message successfully.') await channel.close(); } catch(err) { console.log('send message failed:' + err.message) } } async function testSend() { const conn = await getMQConnection() await run(conn, { content: (new Date()).toLocaleString(), expiration: '3000', }) await conn.close() } testSend(); consumer.js const config = require(\"./config\"); const amqp = require('amqplib'); async function getMQConnection() { return await amqp.connect({ protocol: 'amqp', hostname: config.host, port: config.port, username: config.user, password: config.pass, locale: 'en_US', frameMax: 0, heartbeat: 5, // 心跳 vhost: config.vhost, }) } async function run(rmqConn) { const noramlQueue = 'noramlQu'; const noramlExchange = 'noramlEx'; const exchangeDLX = 'testExDLX'; const queueDLX = 'testQueueDLX'; const routingKeyDLX = 'testRoutingKeyDLX'; try { const channel = await rmqConn.createChannel(); // 声明死信交换器和队列，就跟普通的一样 await channel.assertExchange(exchangeDLX, 'direct', { durable: true, autoDelete: false }); await channel.assertQueue(queueDLX, {durable: true, autoDelete: false, }); await channel.bindQueue(queueDLX, exchangeDLX, routingKeyDLX); // 处理死信队列消息 await channel.consume(queueDLX, msg =\u003e { console.log(`[${(new Date()).toLocaleString()}] consumer msg：`, msg.content.toString()); }, { noAck: true }); } catch(err) { console.log('consume message failed:' + err.message) } } async function testConsume() { const conn = await getMQConnection(); console.log('begin consuming messages...'); await run(conn); process.on('SIGINT', () =\u003e { console.log('stop consumer.') conn.close(); }); } testConsume(); config.js module.exports = { host: '127.0.0.1', port: 5672, user: 'test', pass: '************', vhost: '/' } 上面的代码，我们让消息3s后过期，先启动消费者，再启动生产者，我们可以看到消息3s后过期: $ node consumer.js begin consuming messages... [2021/3/20 下午3:22:29] consumer msg： 2021/3/20 下午3:22:26 ","date":"2021-03-20","objectID":"/rabbitmq_dlx/:3:0","tags":["RabbitMQ"],"title":"RabbitMQ四五事之死信队列","uri":"/rabbitmq_dlx/"},{"categories":["RabbitMQ"],"content":"死信队列问题 RabbitMQ中，每个消息的过期不是独立的，一个队列里的某个消息即使比同队列中的其它消息提前过期，也不会优先进入到死信队列，只有当过期的消息到了队列的顶端，才会被真正的丢弃或者进入死信队列。 我们把生产者的代码调整下，先发一个20s过期的消息，再发一个3s过期的消息 .... async function testSend() { const conn = await getMQConnection() await run(conn, { content: (new Date()).toLocaleString() + ' 20s过期 ', expiration: '20000', }) await run(conn, { content: (new Date()).toLocaleString() + ' 3s过期 ', expiration: '3000', }) await conn.close() } 观察消费者输出： $ node consumer.js begin consuming messages... [2021/3/21 下午6:10:21] consumer msg： 2021/3/21 下午6:10:01 20s过期 [2021/3/21 下午6:10:21] consumer msg： 2021/3/21 下午6:10:01 3s过期 可以发现，3s过期的消息并没有先被消费，而是只能前面的20s过期的消息先过期，它才会被检查是否过期。 究其本质的话，RabbitMQ 的队列是一个 FIFO 的有序队列，投入的消息都顺序的压进 MQ 中。而 RabbitMQ 也只会对队列顶端的消息进行超时判定，所以就出现了上述的情况。 所以对于固定时间的延时任务的话，例如下单后半小时未支付则关闭订单这种场景，RabbitMQ无疑可以很好的承担起这个需求，但对于需要每条消息的死亡相互独立这种场景，RabbitMQ还是无法满足的。 ","date":"2021-03-20","objectID":"/rabbitmq_dlx/:4:0","tags":["RabbitMQ"],"title":"RabbitMQ四五事之死信队列","uri":"/rabbitmq_dlx/"},{"categories":["RabbitMQ"],"content":"解决队列消息非异步 RabbitMQ 本身没有这种功能，但是它有个插件可以解决这个问题：rabbitmq_delayed_message_exchange，地址 。 这个插件的介绍如下： A user can declare an exchange with the type x-delayed-message and then publish messages with the custom header x-delay expressing in milliseconds a delay time for the message. The message will be delivered to the respective queues after x-delay milliseconds. 这个插件增加了一种新类型的exchange：x-delayed-message，然后只要发送消息时指定的是这个交换机，那么只需要在消息 header 中指定参数 x-delay [:毫秒值] 就能够实现每条消息的异步延时。 ","date":"2021-03-20","objectID":"/rabbitmq_dlx/:5:0","tags":["RabbitMQ"],"title":"RabbitMQ四五事之死信队列","uri":"/rabbitmq_dlx/"},{"categories":["RabbitMQ"],"content":"添加插件 用了Docker之后，添加这个插件非常简单，添加Dockerfile： FROM rabbitmq:3.8.12-management COPY ./rabbitmq_delayed_message_exchange-3.8.9-0199d11c.ez /plugins RUN rabbitmq-plugins enable rabbitmq_delayed_message_exchange 插件可以在Release页下载。 docker-compose.yml改下： version: \"2\" services: mq: build: . restart: always mem_limit: 2g hostname: mq1 volumes: - ./mnesia:/var/lib/rabbitmq/mnesia - ./log:/var/log/rabbitmq - ./rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf ports: - \"55672:15672\" - \"5672:5672\" environment: - CONTAINER_NAME=rabbitMQ - RABBITMQ_ERLANG_COOKIE=3t182q3wtj1p9z0kd3tb 这样插件就安装成功了。 ","date":"2021-03-20","objectID":"/rabbitmq_dlx/:5:1","tags":["RabbitMQ"],"title":"RabbitMQ四五事之死信队列","uri":"/rabbitmq_dlx/"},{"categories":["RabbitMQ"],"content":"修改代码 producer.js const config = require(\"./config\"); const amqp = require('amqplib'); async function getMQConnection() { return await amqp.connect({ protocol: 'amqp', hostname: config.host, port: config.port, username: config.user, password: config.pass, locale: 'en_US', frameMax: 0, heartbeat: 5, // 心跳 vhost: config.vhost, }) } async function run(rmqConn, msgObj) { const exchangeDelay = 'testExNewDelay'; const queueDLX = 'testQueueDLX'; const routingKeyDLX = 'testRoutingKeyDLX'; try { const channel = await rmqConn.createChannel(); // x-delayed-message类型的exchange await channel.assertExchange(exchangeDelay, 'x-delayed-message', { durable: true, autoDelete: false, arguments: {'x-delayed-type': \"direct\"} }); await channel.assertQueue(queueDLX, {durable: true, autoDelete: false, }); await channel.bindQueue(queueDLX, exchangeDelay, routingKeyDLX); // 发送消息 await channel.publish(exchangeDelay, routingKeyDLX, Buffer.from(msgObj.content), { headers: {\"x-delay\": msgObj.expiration}, // ms persistent: true, mandatory: true, }); console.log('send message successfully.') await channel.close(); } catch(err) { console.log('send message failed:' + err.message) } } async function testSend() { const conn = await getMQConnection() await run(conn, { content: (new Date()).toLocaleString() + ' 20s过期 ', expiration: '20000', }) await run(conn, { content: (new Date()).toLocaleString() + ' 3s过期 ', expiration: '3000', }) await conn.close() } testSend(); x-delayed-type告诉插件在给定的延迟时间过去之后，exchange应该跟direct，fanout，topic中的exchange路由功能一样。 consumer.js const config = require(\"./config\"); const amqp = require('amqplib'); async function getMQConnection() { return await amqp.connect({ protocol: 'amqp', hostname: config.host, port: config.port, username: config.user, password: config.pass, locale: 'en_US', frameMax: 0, heartbeat: 5, // 心跳 vhost: config.vhost, }) } async function run(rmqConn) { const exchangeDelay = 'testExNewDelay'; const queueDLX = 'testQueueDLX'; const routingKeyDLX = 'testRoutingKeyDLX'; try { const channel = await rmqConn.createChannel(); // x-delayed-message类型的exchange await channel.assertExchange(exchangeDelay, 'x-delayed-message', { durable: true, autoDelete: false, arguments: {'x-delayed-type': \"direct\"} }); await channel.assertQueue(queueDLX, {durable: true, autoDelete: false, }); await channel.bindQueue(queueDLX, exchangeDelay, routingKeyDLX); // 处理死信队列消息 await channel.consume(queueDLX, msg =\u003e { console.log(`[${(new Date()).toLocaleString()}] consumer msg：`, msg.content.toString()); }, { noAck: true }); } catch(err) { console.log('consume message failed:' + err.message) } } async function testConsume() { const conn = await getMQConnection(); console.log('begin consuming messages...'); await run(conn); process.on('SIGINT', () =\u003e { console.log('stop consumer.') conn.close(); }); } testConsume(); ","date":"2021-03-20","objectID":"/rabbitmq_dlx/:5:2","tags":["RabbitMQ"],"title":"RabbitMQ四五事之死信队列","uri":"/rabbitmq_dlx/"},{"categories":["RabbitMQ"],"content":"测试效果 执行生产者代码之后，我们可以看到消费者输出： $ node consumer.js begin consuming messages... [2021/3/22 下午2:16:37] consumer msg： 2021/3/22 下午2:16:34 3s过期 [2021/3/22 下午2:16:54] consumer msg： 2021/3/22 下午2:16:34 20s过期 可以发现，消息已经独立的过期了。 ","date":"2021-03-20","objectID":"/rabbitmq_dlx/:5:3","tags":["RabbitMQ"],"title":"RabbitMQ四五事之死信队列","uri":"/rabbitmq_dlx/"},{"categories":["RabbitMQ"],"content":"局限性 没有什么东西是完美的，这个插件也不例外。看下这个插件的Performance Impact部分： For each message that crosses an \"x-delayed-message\" exchange, the plugin will try to determine if the message has to be expired by making sure the delay is within range, ie: Delay \u003e 0, Delay =\u003c ?ERL_MAX_T (In Erlang a timer can be set up to (2^32)-1 milliseconds in the future). 延迟时间最大为 (2^32)-1 毫秒，大约 49 天。另外这个插件也不适合大量延迟消息（例如数十万或数百万）的场景，Limitations也写了： Current design of this plugin doesn't really fit scenarios with a high number of delayed messages (e.g. 100s of thousands or millions). See #72 for details. 参考： RabbitMQ 死信机制真的可以作为延时任务这个场景的解决方案吗？ RabbitMQ 延迟队列插件 x-delay Bug ","date":"2021-03-20","objectID":"/rabbitmq_dlx/:5:4","tags":["RabbitMQ"],"title":"RabbitMQ四五事之死信队列","uri":"/rabbitmq_dlx/"},{"categories":[],"content":" 这篇文章很简单呢，就是记录一下用Puppeteer的一些snippet。 ","date":"2021-03-05","objectID":"/puppeteer%E4%BD%BF%E7%94%A8%E4%BE%8B%E5%AD%90/:0:0","tags":["puppeteer","Nodejs"],"title":"Puppeteer使用例子","uri":"/puppeteer%E4%BD%BF%E7%94%A8%E4%BE%8B%E5%AD%90/"},{"categories":[],"content":"访问网站后截图 const puppeteer = require('puppeteer'); const url = 'https://segmentfault.com'; (async() =\u003e { const browser = await puppeteer.launch({ headless: true, args: [\"--no-sandbox\", \"--single-process\"], }); const page = await browser.newPage(); await page.setViewport({ width: 1920, height: 1080 }); // ‘networkidle2’ means that there are no more than 2 active requests open. // This is a good setting because for some websites (e.g. websites using websockets) there will always be connections open await page.goto(url, { waitUntil: 'networkidle2', timeout: 1000 * 60 * 5, // 毫秒 超时参数需要加上，有时候网络不好，会导致等着 }); await page.screenshot({path: './data/website.png', type: 'png'}); page.close(); browser.close(); })(); ","date":"2021-03-05","objectID":"/puppeteer%E4%BD%BF%E7%94%A8%E4%BE%8B%E5%AD%90/:1:0","tags":["puppeteer","Nodejs"],"title":"Puppeteer使用例子","uri":"/puppeteer%E4%BD%BF%E7%94%A8%E4%BE%8B%E5%AD%90/"},{"categories":["JavaScript"],"content":"ES6 ECMAScript 2015或ES2015是对JavaScript编程语言的重大更新。这是自2009年对ES5进行标准化以来对语言的首次重大更新，ES6加入很多有用的特性。因此，ES2015通常被称为ES6。 本文环境： NodeJs版本：v12.13.0 OS：Ubuntu 18.04.4 LTS ","date":"2020-08-29","objectID":"/es6_class/:1:0","tags":["JavaScript","class"],"title":"ES6中的class","uri":"/es6_class/"},{"categories":["JavaScript"],"content":"class语法糖 首先我们先来看一下关于 ES6 中的类 class Persion { say() { console.log('hello~') } } 上面这段代码是 ES6 中定义一个类的写法，其实只是一个语法糖，而实际上当我们给一个类添加一个属性的时候，会调用到 Object.defineProperty 这个方法，它会接受三个参数：target 、name 和 descriptor ，所以上面的代码实际上在执行时是这样的： function Persion() {} Object.defineProperty(Persion.prototype, \"say\", { value: function() { console.log(\"hello ~\"); }, enumerable: false, configurable: true, writable: true }); ","date":"2020-08-29","objectID":"/es6_class/:2:0","tags":["JavaScript","class"],"title":"ES6中的class","uri":"/es6_class/"},{"categories":["JavaScript"],"content":"ES6中extends ES6中可以很方便地用extends的实现继承： class Shape { constructor(x, y) { this.x = x; this.y = y; } move(x, y) { this.x += x; this.y += y; console.info('Shape moved.'); } } class Rectangle extends Shape { constructor() { super(); // ES6 要求，子类的构造函数必须执行一次 super 函数，否则会报错。 } } 要用ES5实现继承，就是用利用原型链。 // Shape - 父类(superclass) function Shape() { this.x = 0; this.y = 0; } // 父类的方法 Shape.prototype.move = function(x, y) { this.x += x; this.y += y; console.info('Shape moved.'); }; // Rectangle - 子类(subclass) function Rectangle() { Shape.call(this); // call super constructor. } // 子类续承父类 Rectangle.prototype = Object.create(Shape.prototype); Rectangle.prototype.constructor = Rectangle; var rect = new Rectangle(); console.log('Is rect an instance of Rectangle?', rect instanceof Rectangle); // true console.log('Is rect an instance of Shape?', rect instanceof Shape); // true rect.move(1, 1); // Outputs, 'Shape moved.' 参考： MDN Object create ","date":"2020-08-29","objectID":"/es6_class/:3:0","tags":["JavaScript","class"],"title":"ES6中的class","uri":"/es6_class/"},{"categories":["PHP"],"content":"缘由 有时候，我们想看看一个变量底层对应底层的数据结构或者PHP脚本是如何执行的，gdb就是这样一个好工具，之前有篇文章写过如何简单使用gdb。 本文环境： PHP版本：PHP 7.1.16 (cli) (built: Apr 8 2020 11:56:59) ( ZTS ) OS：Ubuntu 18.04.4 LTS gdb: GNU gdb (Ubuntu 8.1-0ubuntu3.2) 8.1.0.20180409-git ","date":"2020-07-03","objectID":"/debug_php_source_code/:1:0","tags":["PHP","Linux"],"title":"调试PHP源码","uri":"/debug_php_source_code/"},{"categories":["PHP"],"content":"编译 你可以从PHP官网下载PHP源码的压缩包，者是从git.php.net（或者是github的镜像）的git库clone最新的代码库，然后切换到对应的PHP版本的分支，本文使用的是PHP7.1，你可以使用下面的命令完成这些工作： git clone http://git.php.net/repository/php-src.git cd php-src git checkout PHP-7.1 如果你是从git库中clone的代码，那么你先要运行下buildconf命令： ~/php-src\u003e ./buildconf 这个命令会生成configure脚本，从官网下载的源码包中会直接包含这个脚本，如果你执行buildconf出错，那么很可能是因为你的系统中没有autoconf这个工具，你可以使用包安装工具进行安装。 如果你已经成功生成了configure脚本文件（或者是使用已包含这个脚本文件的源码包），那就可以开始编译了。为了调式PHP源码，我们的编译会disable所有的扩展（除了一些必须包含的外，这些PHP的编译脚本会自行处理），我们使用下面的命令来完成编译安装的工作，假设安装的路径为$HOME/myphp： ~/php-src\u003e ./configure --disable-all --enable-debug --prefix=$HOME/myphp ~/php-src\u003e make -jN ~/php-src\u003e make install 注意这里的prefix的参数必须为绝对路径，所以你不能写成~/myphp，另外我们这次编译只是为了调式，所以建议一定要设置prefix参数，要不然PHP会被安装到默认路径中，大多数时候是/usr/local/php中，这可能会造成一些没必要的污染。另外我们使用了两个选项，一个是–disable-all，这个表示禁止安装所有扩展（除了一个必须安装的），另外一个就是–enable-debug，这个选项表示以debug模式编译PHP源码，相当于gcc的-g选项，它会把调试信息编译进最终的二进制程序中。 上面的命令make -jN，N表示你的CPU数量（或者是CPU核心的数量），设置了这个参数后就可以使用多个CPU进行并行编译，这可以提高编译效率。 ","date":"2020-07-03","objectID":"/debug_php_source_code/:2:0","tags":["PHP","Linux"],"title":"调试PHP源码","uri":"/debug_php_source_code/"},{"categories":["PHP"],"content":"调试PHP 我们调试一段简单的PHP代码： \u003c?php $a = 10; $b = 42; echo $b; 我们想看下$a对应的底层变量结构，那我们应该在哪个函数上叫断点呢？通过查阅资料（如《PHP7内核分析》）我们发现，ZendVM的执行器就是一个white循环，在这个循环中依次调用opline指令的handler，然后根据handler的返回决定下一步的动作。执行调度器为zend_execute_ex，这是函数指针，默认为execute_ex，我们看下这个函数的代码： //删除了预处理语句 ZEND_API void execute_ex(zend_execute_data *ex) { DCL_OPLINE const zend_op *orig_opline = opline; zend_execute_data *orig_execute_data = execute_data; /* execute_data是一个全局变量 */ execute_data = ex; LOAD_OPLINE(); while (1) { ((opcode_handler_t)OPLINE-\u003ehandler)(ZEND_OPCODE_HANDLER_ARGS_PASSTHRU); //执行OPCode对应的C函数，OPLINE是一个全局变量 if (UNEXPECTED(!OPLINE)) { //当前OPArray执行完 execute_data = orig_execute_data; opline = orig_opline; return; } } zend_error_noreturn(E_CORE_ERROR, \"Arrived at end of main loop which shouldn't happen\"); } 所以我们可以在给execute_ex函数打断点。 gdb ~/myphp/bin/php (gdb) r index.php Starting program: /home/salamander/myphp/bin/php index.php Breakpoint 1, execute_ex (ex=0x7ffff7014030) at /home/salamander/php-7.1.16/Zend/zend_vm_execute.h:411 411 const zend_op *orig_opline = opline; (gdb) n 414 zend_execute_data *orig_execute_data = execute_data; (gdb) n 415 execute_data = ex; (gdb) n 421 LOAD_OPLINE(); (gdb) n 422 ZEND_VM_LOOP_INTERRUPT_CHECK(); (gdb) n 429 ((opcode_handler_t)OPLINE-\u003ehandler)(ZEND_OPCODE_HANDLER_ARGS_PASSTHRU); 现在就要调用opline指令的handler，我们应该键入s，跳到对应函数内部去： (gdb) s ZEND_ASSIGN_SPEC_CV_CONST_RETVAL_UNUSED_HANDLER () at /home/salamander/php-7.1.16/Zend/zend_vm_execute.h:39506 39506 SAVE_OPLINE(); (gdb) n 39507 value = EX_CONSTANT(opline-\u003eop2); (gdb) n 39508 variable_ptr = _get_zval_ptr_cv_undef_BP_VAR_W(execute_data, opline-\u003eop1.var); (gdb) n 39516 value = zend_assign_to_variable(variable_ptr, value, IS_CONST); (gdb) p value $1 = (zval *) 0x7ffff707b460 (gdb) p *$1 $3 = {value = {lval = 10, dval = 4.9406564584124654e-323, counted = 0xa, str = 0xa, arr = 0xa, obj = 0xa, res = 0xa, ref = 0xa, ast = 0xa, zv = 0xa, ptr = 0xa, ce = 0xa, func = 0xa, ww = {w1 = 10, w2 = 0}}, u1 = {v = {type = 4 '\\004', type_flags = 0 '\\000', const_flags = 0 '\\000', reserved = 0 '\\000'}, type_info = 4}, u2 = {next = 4294967295, cache_slot = 4294967295, lineno = 4294967295, num_args = 4294967295, fe_pos = 4294967295, fe_iter_idx = 4294967295, access_flags = 4294967295, property_guard = 4294967295, extra = 4294967295}} 我们第一行PHP代码是$a = 10;，这是一条赋值语句,ZEND_ASSIGN_SPEC_CV_CONST_RETVAL_UNUSED_HANDLER是把一个常量赋值给一个变量，EX_CONSTANT(opline-\u003eop2)是获取常量的值，$a为CV变量，分配在zend_execute_data动态变量区，通过_get_zval_ptr_cv_undef_BP_VAR_W取到这个变量的地址，剩下的好理解了，就是把变量值赋值给CV变量。 value就是我们的变量值，$a对应的底层变量就是它。 回忆一下PHP7变量的数据结构，是一个叫zval的结构体，zend_value保存具体的变量值： typedef union _zend_value { zend_long lval; /* long value */ double dval; /* double value */ zend_refcounted *counted; zend_string *str; zend_array *arr; zend_object *obj; zend_resource *res; zend_reference *ref; zend_ast_ref *ast; zval *zv; void *ptr; zend_class_entry *ce; zend_function *func; struct { uint32_t w1; uint32_t w2; } ww; } zend_value; struct _zval_struct { zend_value value; /* value */ union { struct { ZEND_ENDIAN_LOHI_4( zend_uchar type, /* 变量类型 */ zend_uchar type_flags, zend_uchar const_flags, zend_uchar reserved) /* call info for EX(This) */ } v; uint32_t type_info; } u1; union { uint32_t next; /* hash collision chain */ uint32_t cache_slot; /* literal cache slot */ uint32_t lineno; /* line number (for ast nodes) */ uint32_t num_args; /* arguments number for EX(This) */ uint32_t fe_pos; /* foreach position */ uint32_t fe_iter_idx; /* foreach iterator index */ uint32_t access_flags; /* class constant access flags */ uint32_t property_guard; /* single property guard */ uint32_t extra; /* not further specified */ } u2; }; #define IS_UNDEF 0 #define IS_NULL 1 #define IS_FALSE 2 #define IS_TRUE 3 #define IS_LONG 4 #define IS_DOUBLE 5 #define IS_STRING 6 #define IS_ARRAY 7 #define IS_OBJECT 8 #define IS_RESOURCE 9 #define IS_REFERENCE 10 /* constant expressions */ #define IS_CONSTANT 11 #define IS_CONSTANT_AST 12 我们打印出来的底层变量，lval是10，u1里的type是4，也正好是IS_LONG，别的字段的值大家也可以分析看看。 参考： PH","date":"2020-07-03","objectID":"/debug_php_source_code/:3:0","tags":["PHP","Linux"],"title":"调试PHP源码","uri":"/debug_php_source_code/"},{"categories":["Linux"],"content":"gdb gdb 是 UNIX 及 UNIX-like 下的调试工具，在 Linux 下一般都直接在命令行中用 gdb 来调试程序，相比 Windows 上的集成开发环境 IDE 提供的图形界面调试，一开始使用 gdb 调试可能会让你感觉很难适应，但是只要熟悉了 gdb 调试的常用命令，调试出程序会很有成就感，一方面因为这些命令就类似图形界面调试按钮背后的逻辑，另一方面用命令行来调试程序，逼格瞬间就上了一个档次，这次就跟大家分享 gdb 调试的基本技术和 15 个常用调试命令。 ","date":"2020-07-02","objectID":"/gdb_use/:1:0","tags":["gdb","Linux"],"title":"gdb调试简单使用","uri":"/gdb_use/"},{"categories":["Linux"],"content":"使用 ","date":"2020-07-02","objectID":"/gdb_use/:2:0","tags":["gdb","Linux"],"title":"gdb调试简单使用","uri":"/gdb_use/"},{"categories":["Linux"],"content":"gdb快捷键说明 一些快捷命令 l – list p – print print {variable} //打印变量 c – continue //继续执行 s – step b - break break line_number/break [file_name]:line_number/break [file_name]:func_name //设置断点 r - run //执行文件 ","date":"2020-07-02","objectID":"/gdb_use/:2:1","tags":["gdb","Linux"],"title":"gdb调试简单使用","uri":"/gdb_use/"},{"categories":["Linux"],"content":"使用 编译可以调试的程序 这是本次要调试的 hello.c 程序，非常简单： #include \u003cstdio.h\u003e int add(int x, int y) { return x + y; } int main() { int a = 1; int b = 2; printf(\"a = %d\\n\", a); printf(\"b = %d\\n\", b); int c = add(a, b); printf(\"%d + %d = %d\\n\", a, b, c); return 0; } 我们平常使用 gcc 编译的程序如果不加 [-g] 选项： gcc hello.c -o hello gdb 会提示该可执行文件没有调试符号，不能调试： gdb hello ... Reading symbols from hello...(no debugging symbols found)...done. ... 如果需要让程序可以调试，就**必须在编译的时候加上 ** [-g] 参数 载入要调试的程序 使用如下的命令来载入可执行文件 hello 到 gdb 中： gdb hello 载入成功，gdb 会打印一段提示信息，并且命令行前缀变为 (gdb)，下面是我的 Ubuntu 输出的信息： GNU gdb (Ubuntu 8.1-0ubuntu3.2) 8.1.0.20180409-git Copyright (C) 2018 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u003chttp://gnu.org/licenses/gpl.html\u003e This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-linux-gnu\". Type \"show configuration\" for configuration details. For bug reporting instructions, please see: \u003chttp://www.gnu.org/software/gdb/bugs/\u003e. Find the GDB manual and other documentation resources online at: \u003chttp://www.gnu.org/software/gdb/documentation/\u003e. For help, type \"help\". Type \"apropos word\" to search for commands related to \"word\"... Reading symbols from hello...done. (gdb) 注，按 q 退出 gdb 方法二 - 使用 gdb 提供的 file 命令 第二种方法是在 gdb 环境中使用 file 命令，我们需要先进入 gdb 环境下： gdb 使用 file hello 载入待调试程序： ... (gdb) file hello Reading symbols from hello...done. (gdb) q 查看调试程序 在 gdb 下查看调试程序使用命令 list 或简写 l，「回车」列出后面程序： (gdb) list 1 #include \u003cstdio.h\u003e 2 3 int add(int x, int y) { 4 return x + y; 5 } 6 7 int main() { 8 int a = 1; 9 int b = 2; 10 printf(\"a = %d\\n\", a); (gdb) 添加断点 在 gdb 下添加断点使用命令 break 或简写 b，有下面几个常见用法（这里统一用 b）： b function_name b row_num b file_name:row_num b row_num if condition 比如我们以第一个为例，在 main 函数上添加断点： (gdb) b main Breakpoint 1 at 0x666: file hello.c, line 8. 打印的信息告诉我们在 hello.c 文件的第 8 行，地址 0x666 处添加了一个断点，那如何查看断点呢？ 查看断点 在 gdb 下查看断点使用命令 info break 或简写 i b，比如查看刚才打的断点： (gdb) i b Num Type Disp Enb Address What 1 breakpoint keep y 0x0000000000000666 in main at hello.c:8 删除断点 在 gdb 下删除断点使用命令 delete 断点 Num 或简写 d Num，比如删除刚才的 Num = 1 的断点： (gdb) d 1 (gdb) i b No breakpoints or watchpoints. 删除后再次查看断点，提示当前没有断点，说明删除成功啦，下面来运行程序试试。 运行程序 在 gdb 下使用命令 run 或简写 r 来运行当前载入的程序： (gdb) r Starting program: /home/salamander/文档/test/hello a = 1 b = 2 1 + 2 = 3 [Inferior 1 (process 16249) exited normally] 我这次没有添加断点，程序全速运行，然后正常退出了。 单步执行下一步 在 gdb 下使用命令 next 或简写 n 来单步执行下一步，假设我们在 main 打了断点： (gdb) b main Breakpoint 1 at 0x555555554666: file hello.c, line 8. (gdb) r Starting program: /home/salamander/文档/test/hello Breakpoint 1, main () at hello.c:8 8 int a = 1; (gdb) n 9 int b = 2; 可以看到当前停在 int a = 1; 这一行，按 n 执行了下一句代码 int b = 2; 打印变量 在 gdb 中使用命令 print var 或简写 p var 来打印一个变量或者函数的返回值，在上述gdb中打印 a 的值： (gdb) b main Breakpoint 1 at 0x555555554666: file hello.c, line 8. (gdb) r Starting program: /home/salamander/文档/test/hello Breakpoint 1, main () at hello.c:8 8 int a = 1; (gdb) n 9 int b = 2; (gdb) n 10 printf(\"a = %d\\n\", a); (gdb) p a $1 = 1 参考： Linux 高级编程 - 15 个 gdb 调试基础命令 ","date":"2020-07-02","objectID":"/gdb_use/:2:2","tags":["gdb","Linux"],"title":"gdb调试简单使用","uri":"/gdb_use/"},{"categories":["Go"],"content":"需求 有时候我们会开启很多线程（go中是协程）去做一件事件，然后希望主线程等待这些线程都完成后才结束，一个简单的想法是，我在主线程sleep一段时间，譬如3s钟，但是明显这样的做法不科学，因为这些任务很有可能在200ms内就都完成了。如果你用过Java的话，那你很快就会想到CountDownLatch类，在Go中，也有类似的结构，就是本文要讨论的WaitGroup。 ","date":"2020-06-15","objectID":"/go_sync_waitgroup/:1:0","tags":["Go"],"title":"go并发之WaitGroup使用","uri":"/go_sync_waitgroup/"},{"categories":["Go"],"content":"使用 示例代码 package main import ( \"fmt\" \"sync\" \"time\" ) func main() { learnWaitGroup() } func learnWaitGroup() { num := 10 wg := sync.WaitGroup{} wg.Add(num) for i := 0; i \u003c num; i++ { go func(idx int) { fmt.Printf(\"%d Doing something...\\n\", idx) time.Sleep(time.Second) wg.Done() }(i) } wg.Wait() fmt.Println(\"All is done...\") } WaitGroup 对象内部有一个计数器，最初从0开始，它有三个方法：Add(), Done(), Wait() 用来控制计数器的数量。Add(n) 把计数器设置为n ，Done() 每次把计数器-1 ，Wait() 会阻塞代码的运行，直到计数器地值减为0。 ","date":"2020-06-15","objectID":"/go_sync_waitgroup/:2:0","tags":["Go"],"title":"go并发之WaitGroup使用","uri":"/go_sync_waitgroup/"},{"categories":["Go"],"content":"注意问题 WaitGroup对象不是一个引用类型，所以在作为参数的时候，你应该要使用指针。在上面的示例提取一个任务函数 package main import ( \"fmt\" \"sync\" \"time\" ) func main() { learnWaitGroup() } func learnWaitGroup() { num := 10 wg := sync.WaitGroup{} wg.Add(num) for i := 0; i \u003c num; i++ { go runTask(i, \u0026wg) } wg.Wait() fmt.Println(\"All is done...\") } func runTask(idx int, wg *sync.WaitGroup) { fmt.Printf(\"%d Doing something...\\n\", idx) time.Sleep(time.Second) wg.Done() } ","date":"2020-06-15","objectID":"/go_sync_waitgroup/:3:0","tags":["Go"],"title":"go并发之WaitGroup使用","uri":"/go_sync_waitgroup/"},{"categories":["Go"],"content":"Java类比 Java中可以使用CountDownLatch类实现这个功能，它暴露出三个方法： // 调用此方法的线程会被阻塞，直到 CountDownLatch 的 count 为 0 public void await() throws InterruptedException // 会将 count 减 1，直至为 0 public void countDown() countDown() 跟WaitGroup的Done()函数类似，我们还是很容易实现的 public class Main { public static void main(String[] args) { try { testCountDownLatch(); } catch (Exception ex) { ex.printStackTrace(); } } static class TaskThread extends Thread { CountDownLatch latch; public TaskThread(CountDownLatch latch) { this.latch = latch; } @Override public void run() { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } finally { System.out.println(getName() + \" Task is Done\"); latch.countDown(); } } } public static void testCountDownLatch() throws InterruptedException { final int threadNum = 10; CountDownLatch latch = new CountDownLatch(threadNum); for(int i = 0; i \u003c threadNum; i++) { TaskThread task = new TaskThread(latch); task.start(); } System.out.println(\"Task Start!\"); latch.await(); System.out.println(\"All Task is Done!\"); } } ","date":"2020-06-15","objectID":"/go_sync_waitgroup/:4:0","tags":["Go"],"title":"go并发之WaitGroup使用","uri":"/go_sync_waitgroup/"},{"categories":["Go","gRPC"],"content":"gRPC是什么 官网如此写到 A high-performance, open source universal RPC framework 其实，gRPC是一个高性能的，通用的，面向服务端和移动端，基于 HTTP/2 设计的RPC框架。 ","date":"2020-06-02","objectID":"/grpc_learn/:1:0","tags":["rpc","go"],"title":"gRPC入门使用","uri":"/grpc_learn/"},{"categories":["Go","gRPC"],"content":"RPC框架是什么？ RPC 框架说白了就是让你可以像调用本地方法一样调用远程服务提供的方法，而不需要关心底层的通信细节。简单地说就让远程服务调用更加简单、透明。 RPC框架包含了客户端（Client）和服务端（Server） 常见的RPC框架有 gRPC。谷歌出品 Thrift。Apache出品 Dubbo。阿里出品，也是一个微服务框架 ","date":"2020-06-02","objectID":"/grpc_learn/:2:0","tags":["rpc","go"],"title":"gRPC入门使用","uri":"/grpc_learn/"},{"categories":["Go","gRPC"],"content":"gRPC的特性 看官方文档的介绍，有以下4点特性： 使用Protocal Buffers这个强大的结构数据序列化工具 gRPC可以跨语言使用 安装简单，扩展方便（用该框架每秒可达到百万个RPC） 基于HTTP2协议 ","date":"2020-06-02","objectID":"/grpc_learn/:3:0","tags":["rpc","go"],"title":"gRPC入门使用","uri":"/grpc_learn/"},{"categories":["Go","gRPC"],"content":"gRPC使用流程 定义标准的proto文件 生成标准代码（用protoc工具） 服务端使用生成的代码提供服务 客户端使用生成的代码调用服务 ","date":"2020-06-02","objectID":"/grpc_learn/:4:0","tags":["rpc","go"],"title":"gRPC入门使用","uri":"/grpc_learn/"},{"categories":["Go","gRPC"],"content":"Golang实践 ","date":"2020-06-02","objectID":"/grpc_learn/:5:0","tags":["rpc","go"],"title":"gRPC入门使用","uri":"/grpc_learn/"},{"categories":["Go","gRPC"],"content":"安装protoc 首先，我们需要安装protoc，这个工具是Protocol Buffer的编译器，把proto文件翻译成不同语言（Java，Go等）。 地址：protobuf/releases 解压把bin目录下protoc文件放到/usr/local/bin目录下即可。 ","date":"2020-06-02","objectID":"/grpc_learn/:5:1","tags":["rpc","go"],"title":"gRPC入门使用","uri":"/grpc_learn/"},{"categories":["Go","gRPC"],"content":"安装 protoc-gen-go protoc-gen-go是Go的protoc编译插件，protobuf内置了许多高级语言的编译器，但没有Go的。 $ protoc -h ... --cpp_out=OUT_DIR Generate C++ header and source. --csharp_out=OUT_DIR Generate C# source file. --java_out=OUT_DIR Generate Java source file. --js_out=OUT_DIR Generate JavaScript source. --objc_out=OUT_DIR Generate Objective C header and source. --php_out=OUT_DIR Generate PHP source file. --python_out=OUT_DIR Generate Python source file. --ruby_out=OUT_DIR Generate Ruby source file. ... 我们借助Go Modules来安装，新建一个目录grpc-test，在目录下执行go mod init grpc-test创建一个Module 因为墙的原因，我们在go get之前要设置proxy（或者把GOPROXY设置到.bashrc文件中） $ export GOPROXY=https://goproxy.cn 然后执行 go get -u github.com/golang/protobuf/protoc-gen-go 执行完就可以在$GOPATH的bin目录下看到protoc-gen-go文件。 ","date":"2020-06-02","objectID":"/grpc_learn/:5:2","tags":["rpc","go"],"title":"gRPC入门使用","uri":"/grpc_learn/"},{"categories":["Go","gRPC"],"content":"定义服务 在grpc-test目录下新建一个protos的目录，写入hello.proto文件 syntax = \"proto3\"; package hello; option go_package = \"hellopb\"; message helloRequest { string name = 1; int64 age = 2; } message helloResponse { string greeting = 1; } service helloService { rpc Hello(helloRequest) returns (helloResponse) {}; } helloService就是给外部调用的服务 然后我们利用protoc工具把 .proto 文件翻译成需要语言的代码（这里是go） gen.sh文件： #!/bin/bash protoDir=\"./protos\" outDir=\"./grpc\" protoc -I ${protoDir}/ ${protoDir}/*proto --go_out=plugins=grpc:${outDir} -I： 指定import路径，可以指定多个-I参数，编译时按顺序查找，不指定默认当前目录 –go_out：指定go语言的访问类 plugins：指定依赖的插件 这个bash会把生成的go代码写到hellopb目录下。 ","date":"2020-06-02","objectID":"/grpc_learn/:5:3","tags":["rpc","go"],"title":"gRPC入门使用","uri":"/grpc_learn/"},{"categories":["Go","gRPC"],"content":"定义服务端 我们需要去实现hello.proto中的helloService package main import ( \"context\" \"fmt\" \"google.golang.org/grpc\" \"grpc-test/hellopb\" \"log\" \"net\" ) type server struct { } func (*server) Hello(ctx context.Context, request *hellopb.HelloRequest) (*hellopb.HelloResponse, error) { name := request.Name response := \u0026hellopb.HelloResponse{ Greeting: \"Hello \" + name, } return response, nil } func main() { address := \"0.0.0.0:50051\" lis, err := net.Listen(\"tcp\", address) if err != nil { log.Fatalf(\"Error %v\", err) } fmt.Printf(\"Server is listening on %v ...\", address) s := grpc.NewServer() hellopb.RegisterHelloServiceServer(s, \u0026server{}) s.Serve(lis) } ","date":"2020-06-02","objectID":"/grpc_learn/:5:4","tags":["rpc","go"],"title":"gRPC入门使用","uri":"/grpc_learn/"},{"categories":["Go","gRPC"],"content":"定义客户端 package main import ( \"context\" \"fmt\" \"grpc-test/hellopb\" \"google.golang.org/grpc\" \"log\" ) func main() { fmt.Println(\"Hello client ...\") opts := grpc.WithInsecure() cc, err := grpc.Dial(\"localhost:50051\", opts) if err != nil { log.Fatal(err) } defer cc.Close() client := hellopb.NewHelloServiceClient(cc) request := \u0026hellopb.HelloRequest{Name: \"Jeremy\", Age: 18} resp, _ := client.Hello(context.Background(), request) fmt.Printf(\"Receive response =\u003e [%v]\", resp.Greeting) } 参考： gRPC详细入门教程，Golang/Python/PHP多语言讲解 ","date":"2020-06-02","objectID":"/grpc_learn/:5:5","tags":["rpc","go"],"title":"gRPC入门使用","uri":"/grpc_learn/"},{"categories":["c"],"content":"FTP协议 相比其他协议，如 HTTP 协议，FTP 协议要复杂一些。与一般的 C/S 应用不同点在于一般的C/S 应用程序一般只会建立一个 Socket 连接，这个连接同时处理服务器端和客户端的连接命令和数据传输。而FTP协议中将命令与数据分开传送的方法提高了效率。 本文环境： OS：Ubuntu 18.04.4 LTS 还有 Windows 10专业版 ftplib：V4.0-1 gcc： 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04) ","date":"2020-05-13","objectID":"/ftplib_source/:1:0","tags":["c"],"title":"ftplib源码分析","uri":"/ftplib_source/"},{"categories":["c"],"content":"命令结构 FTP 每个命令都有 3 到 4 个大写字母组成，命令后面跟参数，用空格分开。每个命令都以 “\\r\\n\"结束（应答也是用”\\r\\n\"结束），例如发送一个CWD命令，那要要发送数据就是：CWD dirname\\r\\n。 常见的FTP命令有： ","date":"2020-05-13","objectID":"/ftplib_source/:1:1","tags":["c"],"title":"ftplib源码分析","uri":"/ftplib_source/"},{"categories":["c"],"content":"响应结构 FTP响应跟命令结构是类似的。 FTP响应通常是单行的，格式为\"响应码+空格+提示信息+\\r\\n\"。如果需要产生一条多行应答，第1行在第3位数字应答码之后包含一个连字符\"-\"，而不是空格，最后一行包含相同的3位数字应答码，后跟一个空格字符。 ","date":"2020-05-13","objectID":"/ftplib_source/:1:2","tags":["c"],"title":"ftplib源码分析","uri":"/ftplib_source/"},{"categories":["c"],"content":"FTP响应码 客户端发送 FTP 命令后，服务器返回响应码。 响应码用三位数字编码表示： 第一个数字给出了命令状态的一般性指示，比如响应成功、失败或不完整。 第二个数字是响应类型的分类，如 2 代表跟连接有关的响应，3 代表用户认证。 第三个数字提供了更加详细的信息。 第一个数字的含义如下： 1 表示服务器正确接收信息，还未处理。 2 表示服务器已经正确处理信息。 3 表示服务器正确接收信息，正在处理。 4 表示信息暂时错误。 5 表示信息永久错误。 第二个数字的含义如下： 0 表示语法。 1 表示系统状态和信息。 2 表示连接状态。 3 表示与用户认证有关的信息。 4 表示未定义。 5 表示与文件系统有关的信息。 ","date":"2020-05-13","objectID":"/ftplib_source/:1:3","tags":["c"],"title":"ftplib源码分析","uri":"/ftplib_source/"},{"categories":["c"],"content":"例子 用客户端登录 FTP 服务器为例子 大致调用函数过称为： /* 命令 ”USER username\\r\\n” */ sprintf(send_buf,\"USER %s\\r\\n\",username); /*客户端发送用户名到服务器端 */ write(control_sock, send_buf, strlen(send_buf)); /* 客户端接收服务器的响应码和信息，正常为 ”331 User name okay, need password.” */ read(control_sock, read_buf, read_len); /* 命令 ”PASS password\\r\\n” */ sprintf(send_buf,\"PASS %s\\r\\n\",password); /* 客户端发送密码到服务器端 */ write(control_sock, send_buf, strlen(send_buf)); /* 客户端接收服务器的响应码和信息，正常为 ”230 User logged in, proceed.” */ read(control_sock, read_buf, read_len); ","date":"2020-05-13","objectID":"/ftplib_source/:1:4","tags":["c"],"title":"ftplib源码分析","uri":"/ftplib_source/"},{"categories":["c"],"content":"源码分析 ftplib在这里下载。 登录了FTP服务器后，肯定需要一个句柄的量，在这个ftplib中是netbuf： typedef struct NetBuf netbuf; struct NetBuf { char *cput,*cget; int handle; int cavail,cleft; char *buf; int dir; netbuf *ctrl; netbuf *data; int cmode; struct timeval idletime; FtpCallback idlecb; void *idlearg; unsigned long int xfered; unsigned long int cbbytes; unsigned long int xfered1; char response[RESPONSE_BUFSIZ]; }; handle字段其实就存了tcp握手成功后的socket。 ","date":"2020-05-13","objectID":"/ftplib_source/:2:0","tags":["c"],"title":"ftplib源码分析","uri":"/ftplib_source/"},{"categories":["c"],"content":"FtpSendCmd函数 首先来看FtpSendCmd函数，这个函数顾名思义，就是用来发送FTP命令，你在FtpPwd、FtpNlst、FtpDir、FtpGet等函数中都可以看到它： static int FtpSendCmd(const char *cmd, char expresp, netbuf *nControl) { char buf[TMP_BUFSIZ]; if (nControl-\u003edir != FTPLIB_CONTROL) return 0; if (ftplib_debug \u003e 2) fprintf(stderr,\"%s\\n\",cmd); if ((strlen(cmd) + 3) \u003e sizeof(buf)) return 0; sprintf(buf,\"%s\\r\\n\",cmd); if (net_write(nControl-\u003ehandle, buf, strlen(buf)) \u003c= 0) { if (ftplib_debug) perror(\"write\"); return 0; } return readresp(expresp, nControl); } 这个函数的过程： 用net_write函数操作socket发送数据 readresp函数读取服务器响应 net_write函数 我们查看一下net_write，其实它就是封装了一下write函数，因为TCP通信对于应用程序来说是完全异步，你调用write写入5个字节，返回不一定是5个字节，可能是3个，4个，所以net_write多次调用了write（在《UNIX网络编程 卷1》中，作者也有类似的封装）。另外，write返回成功了也只代表buf中的数据被复制到了kernel中的TCP发送缓冲区，至于数据什么时候被发往网络，什么时候被对方主机接收，什么时候被对方进程读取，系统调用层面不会给予任何保证和通知。 int net_write(int fd, const char *buf, size_t len) { int done = 0; while ( len \u003e 0 ) { int c = write( fd, buf, len ); if ( c == -1 ) { if ( errno != EINTR \u0026\u0026 errno != EAGAIN ) return -1; } else if ( c == 0 ) { return done; } else { buf += c; done += c; len -= c; } } return done; } readresp函数 发送了FTP的命令数据后，就需要用socket接受响应数据了，切记TCP是流式传输的，所以你需要自己做应用层的解析。 FTP的消息块的分割符是\\r\\n，看readline函数名应该是读取一行数据 static int readresp(char c, netbuf *nControl) { char match[5]; if (readline(nControl-\u003eresponse, RESPONSE_BUFSIZ, nControl) == -1) { if (ftplib_debug) perror(\"Control socket read failed\"); return 0; } if (ftplib_debug \u003e 1) fprintf(stderr,\"%s\",nControl-\u003eresponse); if (nControl-\u003eresponse[3] == '-') { strncpy(match,nControl-\u003eresponse,3); match[3] = ' '; match[4] = '\\0'; do { if (readline(nControl-\u003eresponse, RESPONSE_BUFSIZ, nControl) == -1) { if (ftplib_debug) perror(\"Control socket read failed\"); return 0; } if (ftplib_debug \u003e 1) fprintf(stderr,\"%s\",nControl-\u003eresponse); } while (strncmp(nControl-\u003eresponse, match, 4)); } if (nControl-\u003eresponse[0] == c) return 1; return 0; } readline函数 static int readline(char *buf, int max, netbuf *ctl) { int x, retval = 0; char *end,*bp=buf; int eof = 0; if ((ctl-\u003edir != FTPLIB_CONTROL) \u0026\u0026 (ctl-\u003edir != FTPLIB_READ)) return -1; if (max == 0) return 0; do { if (ctl-\u003ecavail \u003e 0) { x = (max \u003e= ctl-\u003ecavail) ? ctl-\u003ecavail : max-1; end = memccpy(bp, ctl-\u003ecget, '\\n',x); if (end != NULL) x = end - bp; retval += x; bp += x; *bp = '\\0'; max -= x; ctl-\u003ecget += x; ctl-\u003ecavail -= x; if (end != NULL) { bp -= 2; if (strcmp(bp,\"\\r\\n\") == 0) { *bp++ = '\\n'; *bp++ = '\\0'; --retval; } break; } } if (max == 1) { *buf = '\\0'; break; } if (ctl-\u003ecput == ctl-\u003ecget) { ctl-\u003ecput = ctl-\u003ecget = ctl-\u003ebuf; ctl-\u003ecavail = 0; ctl-\u003ecleft = FTPLIB_BUFSIZ; } if (eof) { if (retval == 0) retval = -1; break; } if (!socket_wait(ctl)) return retval; if ((x = net_read(ctl-\u003ehandle, ctl-\u003ecput, ctl-\u003ecleft)) == -1) { if (ftplib_debug) perror(\"read\"); retval = -1; break; } if (x == 0) eof = 1; ctl-\u003ecleft -= x; ctl-\u003ecavail += x; ctl-\u003ecput += x; } while (1); return retval; } socket_wait()函数 这个函数用了select系统函数，用来检测ctl-\u003ehandle是否可读（这里可读的时候就是服务端发过来响应数据了）。select函数的返回值：返回-1表示调用select函数时有错误发生，具体的错误在Linux可通过errno输出来查看；返回0，表示select函数超时；返回正数即调用select函数成功，表示集合中文件描述符的数量，集合也会被修改以显示哪一个文件描述符已准备就绪。 不过在用来发送命令的socket上（也就是调用FtpConnect函数得到的那个socket），因为ctl-\u003edir是FTPLIB_CONTROL（ctl-\u003eidlecb也是NULL），所以直接返回了1。 /* * socket_wait - wait for socket to receive or flush data * * return 1 if no user callback, otherwise, return value returned by * user callback */ static int socket_wait(netbuf *ctl) { fd_set fd,*rfd = NULL,*wfd = NULL; struct timeval tv; int rv = 0; if ((ctl-\u003edir == FTPLIB_CONTROL) || (ctl-\u003eidlecb == NULL)) return 1; if (ctl-\u003edir == FTPLIB_WRITE) wfd = \u0026fd; else rfd = \u0026fd; FD_ZERO(\u0026fd); do { FD_SET(ctl-\u003ehandle,\u0026fd); tv = ctl-\u003eidletime; rv = select(ctl-\u003ehandle+1, rfd, wfd, NULL, \u0026tv); if (rv == -1) { rv = 0; strncpy(ctl-\u003ectrl-\u003eresponse, strerror(errno), sizeof(ctl-\u003ectrl-\u003eresponse)); break; } else if (rv \u003e 0) { rv = 1; break; } } while ((rv = ctl-\u003eidlecb(ctl, ctl-\u003exfered, ctl-\u003eidlearg))); return rv; } net_read函数 这个函数简单，用了read函数读到了数据，就立马返回，但也要注意，你读10个字节，也不一定能读取10个字节，可能会比10个字节小，因为read总是在接收缓冲区有","date":"2020-05-13","objectID":"/ftplib_source/:2:1","tags":["c"],"title":"ftplib源码分析","uri":"/ftplib_source/"},{"categories":["C"],"content":"动态链接库和静态链接库 静态链接库会在编译时包含到可执行文件中，这样的程序虽然没有依赖问题，但是可执行文件体积较大，包含相同的公共代码，非常浪费内存。 动态链接库的好处就是节省内存空间，还有将一些程序升级变得简单。用户只需要升级动态链接库，而无需重新编译链接其他原有的代码就可以完成整个程序的升级。 在windows下动态链接库是以.dll后缀的文件，静态链接库是以.lib的文件 而在Linux中，动态链接库是以.so作后缀的文件，静态链接库是以.a（archive的缩写）的文件。 本文中，我们的链接库来自于ftplib，这是一个用C语言实现的跨平台FTP库，我们将会用它生成的动态链接库写个简单的程序（连接ftp服务器，然后查询当前目录）。 本文环境： OS：Ubuntu 18.04.4 LTS 还有 Windows 10专业版 ftplib：V4.0-1 gcc： 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04) ","date":"2020-05-03","objectID":"/c_dynamic-linkc/:1:0","tags":["C"],"title":"C语言动态链接库回顾","uri":"/c_dynamic-linkc/"},{"categories":["C"],"content":"Linux下 在Linux中，标准库的大部分函数通常放在文件 libc.a 中（这是静态链接库），或者放在用于共享的动态链接文件 libc.so 中（文件名后缀.so代表“share object”，译为“共享对象”，这是动态链接库）。这些链接库一般位于 /lib/ 或 /usr/lib/，或者位于 GCC 默认搜索的其他目录（默认搜索目录有/lib /usr/lib /usr/local/lib）。 观察一下ftplib的Makefile .... install : all install qftp /usr/local/bin install -m 644 libftp.so.$(SOVERSION) /usr/local/lib install -m 644 ftplib.h /usr/local/include (cd /usr/local/lib \u0026\u0026 \\ ln -sf libftp.so.$(SOVERSION) libftp.so.$(SONAME) \u0026\u0026 \\ ln -sf libftp.so.$(SONAME) libftp.so) -(cd /usr/local/bin \u0026\u0026 \\ for f in ftpdir ftpget ftplist ftprm ftpsend; \\ do ln -s qftp $$f; done) ... make install的时候会把ftplib.h放到/usr/local/include，把libftp.so放到/usr/local/lib，一个是gcc默认的头文件搜索目录，一个是gcc默认的库文件搜索目录。 ","date":"2020-05-03","objectID":"/c_dynamic-linkc/:2:0","tags":["C"],"title":"C语言动态链接库回顾","uri":"/c_dynamic-linkc/"},{"categories":["C"],"content":"安装动态链接库 在ftplib的src目录中执行 make sudo make install 以上操作会把动态链接库放入到我们的系统中。 ","date":"2020-05-03","objectID":"/c_dynamic-linkc/:3:0","tags":["C"],"title":"C语言动态链接库回顾","uri":"/c_dynamic-linkc/"},{"categories":["C"],"content":"程序引用 然后我们写一个简单的程序 #include \u003cstdio.h\u003e #include \"ftplib.h\" netbuf *con = NULL; char host[] = \"192.168.1.175:2121\"; // 小米手机的ftp服务 char username[] = \"**********\"; char password[] = \"********\"; int main() { if(!FtpConnect(host, \u0026con)) { printf(\"connect failed!!\\n\"); return 0; } // 登录 if(!FtpLogin(username, password, con)) { printf(\"login failed!\\n\"); FtpQuit(con); return 0; } printf(\"Login successfully!\\n\"); char currentDir[20]; FtpPwd(currentDir, 10, con); printf(\"Current Directory is %s\\n\", currentDir); FtpQuit(con); return 0; } 好了，现在我们可以用gcc编译它了，因为这里引用了ftplib库，所以我们需要手动添加链接库 gcc main.c -o main /usr/local/lib/libftp.so 上面使用了链接库的完整路径，其实我们可以用-l选项，因为生成的链接库命名是规范的（-lXX会去找libxx.so这样的文件，自动加lib前缀）而且也在gcc的默认搜索目录中 gcc main.c -o main -lftp 另外说一句，有时候我们想增加一个自定义的搜索目录，可以使用-L选项，例如 gcc main.c -o main.out -L/usr/lib -lhello 另外也可以使用环境变量LD_LIBRARY_PATH指定搜索目录（在程序执行之前定义这个量就行），路径之间用冒号”:”分隔。 我们可以用ldd命令查看程序用到的链接库： $ ldd main linux-vdso.so.1 (0x00007fff7a7fa000) libftp.so.4 =\u003e /usr/local/lib/libftp.so.4 (0x00007f7b5215a000) libc.so.6 =\u003e /lib/x86_64-linux-gnu/libc.so.6 (0x00007f7b51d69000) /lib64/ld-linux-x86-64.so.2 (0x00007f7b52563000) 参考： Shared libraries with GCC on Linux ","date":"2020-05-03","objectID":"/c_dynamic-linkc/:3:1","tags":["C"],"title":"C语言动态链接库回顾","uri":"/c_dynamic-linkc/"},{"categories":["Docker","Linux"],"content":" 本文环境： OS：Ubuntu 18.04.4 LTS Golang版本：1.12.13 ","date":"2020-04-28","objectID":"/step_to_step_docker%E4%B9%8Bdocker_network_underlying/:0:0","tags":["Docker","Linux"],"title":"一步步自己做个Docker之Docker网络原理","uri":"/step_to_step_docker%E4%B9%8Bdocker_network_underlying/"},{"categories":["Docker","Linux"],"content":"自己创建Docker网络 当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。 同时，Docker 随机分配一个本地未占用的私有网段（在 RFC1918 中定义）中的一个地址给 docker0 接口。比如典型的 172.17.42.1，掩码为 255.255.0.0。此后启动的容器内的网口也会自动分配一个同一网段（172.17.0.0/16）的地址。 当创建一个 Docker 容器的时候，同时会创建了一对 veth pair 接口（当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包）。这对接口一端在容器内，即 eth0；另一端在本地并被挂载到 docker0 网桥，名称以 veth 开头（例如 vethAQI2QT）。通过这种方式，主机可以跟容器通信，容器之间也可以相互通信。Docker 就创建了在主机和所有容器之间一个虚拟共享网络。如图 下面以自定义的容器方式，一步步配置网络, 达到以下目标: 容器间能够通信 容器能够联外网 首先创建一个容器，但不使用默认网络配置，使用--net=none选项: docker run -t -i --net=none ubuntu:14.04 bash docker ps # 获取容器id=6414d7278905 获取容器pid: docker inspect 6414d7278905 | grep -i \"\\\u003cpid\\\"\" # \"Pid\": 11776, pid=11776 创建一个新的netns，并把容器放入新建的netns中。（根据约定，命名的 network namespace 是可以打开的 /var/run/netns/ 目录下的一个对象。比如有一个名称为 net1 的 network namespace 对象，则可以由打开 /var/run/netns/net1 对象产生的文件描述符引用 network namespace net1。通过引用该文件描述符，可以修改进程的 network namespace。） sudo ip netns add netns666 # 会产生一个/var/run/netns/netns666的文件 sudo ip netns ls # 查看新创建netns netns666 sudo mount --bind /proc/$pid/ns/net /var/run/netns/netns666 # 加入新的netns sudo ip netns pids netns666 # 查看netns666中进程的 PID 11776 接下来创建一个veth对，其中一个设置为容器所在的netns，即netns666 sudo ip link add name veth_d366 type veth peer name veth_d366_peer sudo ip link set veth_d366_peer netns netns666 进入netns666 netns设置网卡名称和ip: sudo ip netns exec netns666 bash sudo ip link set veth_d366_peer name eth0 sudo ifconfig eth0 10.0.0.2/24 # 设置ip为10.0.0.2 ping 10.0.0.2 # 能ping通 exit 上述命令给veth_d366_peer配置完ip的情况： ip addr show 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 36: eth0@if37: \u003cNO-CARRIER,BROADCAST,MULTICAST,UP\u003e mtu 1500 qdisc noqueue state LOWERLAYERDOWN group default qlen 1000 link/ether 9e:67:30:e3:65:34 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 10.0.0.2/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever 在容器中ping 10.0.0.2也能ping通,说明设置正确 ping 10.0.0.2 # 宿主机上应该不通 docker exec 6414d7278905 ping 10.0.0.2 # 成功ping通 创建网桥，并把veth另一端的虚拟网卡加入新创建的网桥中: sudo brctl addbr br666 # 创建新网桥br666 sudo brctl addif br666 veth_d366 # 把虚拟网卡加入网桥br666中 sudo ifconfig br666 10.0.0.1/24 # 设置网桥ip sudo ip link set veth_d366 up # 启动虚拟网卡 测试下： ping 10.0.0.2 # 宿主机上成功ping通 docker exec 6414d7278905 ping 10.0.0.1 # 成功ping通 若以上两个都能ping通说明配置成功！ 最后，我们需要使得容器能够联外网，需要设置NAT，使用iptables设置: sudo iptables -t nat -A POSTROUTING -s 10.0.0.0/24 -o em1 -j MASQUERADE em1是真正的物理网卡对应的网络设备，不同电脑上名字不一样，我的Ubuntu上为enp7s0。 另外，还需要设置FORWARD规则（允许br666转发，IP forwarding要开启，使用sudo sysctl -w net.ipv4.ip_forward=1） sudo iptables -A FORWARD -i br666 -o br666 -j ACCEPT sudo iptables -A FORWARD -i br666 ! -o br666 -j ACCEPT sudo iptables -A FORWARD ! -i br666 -o br666 -j ACCEPT 设置容器默认路由为网桥ip（注意在容器内使用route add 添加, 会出现SIOCADDRT: Operation not permitted错误), 因此只能使用ip netns exec设置: sudo ip netns exec netns666 route add default gw 10.0.0.1 测试，此时请确保宿主机能够联外网,进入容器内部: ping baidu.com # 成功ping通，确保icmp没有被禁 效果图： ","date":"2020-04-28","objectID":"/step_to_step_docker%E4%B9%8Bdocker_network_underlying/:1:0","tags":["Docker","Linux"],"title":"一步步自己做个Docker之Docker网络原理","uri":"/step_to_step_docker%E4%B9%8Bdocker_network_underlying/"},{"categories":["Docker","Linux"],"content":"Docker网络和虚拟机网络区别 ","date":"2020-04-28","objectID":"/step_to_step_docker%E4%B9%8Bdocker_network_underlying/:2:0","tags":["Docker","Linux"],"title":"一步步自己做个Docker之Docker网络原理","uri":"/step_to_step_docker%E4%B9%8Bdocker_network_underlying/"},{"categories":["Docker","Linux"],"content":"虚拟机 虚拟机，如图，虚拟机通过tun/tap或者其它类似的虚拟网络设备，将虚拟机内的网卡同br0连接起来，这样就达到和真实交换机一样的效果，虚拟机发出去的数据包先到达br0，然后由br0交给eth0发送出去，数据包都不需要经过host机器的协议栈，效率高。 ","date":"2020-04-28","objectID":"/step_to_step_docker%E4%B9%8Bdocker_network_underlying/:2:1","tags":["Docker","Linux"],"title":"一步步自己做个Docker之Docker网络原理","uri":"/step_to_step_docker%E4%B9%8Bdocker_network_underlying/"},{"categories":["Docker","Linux"],"content":"Docker docker，如图，由于容器运行在自己单独的network namespace里面，所以都有自己单独的协议栈，情况和上面的虚拟机差不多，但它采用了另一种方式来和外界通信 容器中配置网关为.9.1，发出去的数据包先到达br0，然后交给host机器的协议栈，由于目的IP是外网IP，且host机器开启了IP forward功能，于是数据包会通过eth0发送出去，由于.9.1是内网IP，所以一般发出去之前会先做NAT转换（NAT转换和IP forward功能都需要自己配置）。由于要经过host机器的协议栈，并且还要做NAT转换，所以性能没有上面虚拟机那种方案好，优点是容器处于内网中，安全性相对要高点。（由于数据包统一由IP层从eth0转发出去，所以不存在mac地址的问题，在无线网络环境下也工作良好） 参考： Linux ip netns 命令 docker网络原理.md Docker 网络之理解 bridge 驱动 Linux内核网络设备——bridge设备 ","date":"2020-04-28","objectID":"/step_to_step_docker%E4%B9%8Bdocker_network_underlying/:2:2","tags":["Docker","Linux"],"title":"一步步自己做个Docker之Docker网络原理","uri":"/step_to_step_docker%E4%B9%8Bdocker_network_underlying/"},{"categories":["Linux"],"content":"简介 管理网络流量是系统管理员必需处理的最棘手工作之一，我们必需规定连接系统的用户满足防火墙的传入和传出要求，以最大限度保证系统免受攻击。iptables正是这样的工具。 其实不是真正的防火墙，我们可以把它理解成一个客户端代理，用户通过iptables这个代理，将用户的安全设定执行到对应的\"安全框架\"中，这个\"安全框架\"才是真正的防火墙，这个框架的名字叫netfilter。 ","date":"2020-04-26","objectID":"/linux_iptables/:1:0","tags":["Linux","iptables"],"title":"Linux之iptables","uri":"/linux_iptables/"},{"categories":["Linux"],"content":"流程 iptables有5个链:PREROUTING,INPUT,FORWARD,OUTPUT,POSTROUTING,4个表:filter,nat,mangle,raw。（4表5链） 4个表的优先级由高到低的顺序为:raw–\u003emangle–\u003enat–\u003efilter filter：一般的过滤功能 nat:用于nat功能（端口映射，地址映射等） mangle:用于对特定数据包的修改 raw:优先级最高，设置raw时一般是为了不再让iptables做数据包的链接跟踪处理，提高性能 图片中，PREROUTING会有个分叉，系统是根据IP数据包中的destination ip address中的IP地址对数据包进行分发。 如果destination ip adress是本机地址，数据将会被转交给INPUT链。如果不是本机地址，则交给FORWARD链检测。 ","date":"2020-04-26","objectID":"/linux_iptables/:2:0","tags":["Linux","iptables"],"title":"Linux之iptables","uri":"/linux_iptables/"},{"categories":["Linux"],"content":"使用 ","date":"2020-04-26","objectID":"/linux_iptables/:3:0","tags":["Linux","iptables"],"title":"Linux之iptables","uri":"/linux_iptables/"},{"categories":["Linux"],"content":"启动、停止和重启iptables 虽然 iptables 并不是一项服务，但在 Linux 中还是可以像服务一样对其状态进行管理。 基于SystemD的系统 systemctl start iptables systemctl stop iptables systemctl restart iptables ","date":"2020-04-26","objectID":"/linux_iptables/:3:1","tags":["Linux","iptables"],"title":"Linux之iptables","uri":"/linux_iptables/"},{"categories":["Linux"],"content":"查看规则 查看iptables防火墙策略 sudo iptables -vL 或者带上序号 sudo iptables -vL --line-number //--line-number可以显示规则序号，在删除的时候比较方便 以上命令是查看默认的 FILTER 表，如果你只希望查看特定的表，可以在 -t 参数后跟上要单独查看的表名。例如只查看 NAT 表中的规则，可以使用如下命令： sudo iptables -vL -t nat ","date":"2020-04-26","objectID":"/linux_iptables/:3:2","tags":["Linux","iptables"],"title":"Linux之iptables","uri":"/linux_iptables/"},{"categories":["Linux"],"content":"添加规则 命令格式为：“iptables [-t 表名] 选项 [链名] [条件] [-j 控制动作]\"。 此处列出一些常用的动作： ACCEPT：允许数据包通过。 DROP：直接丢弃数据包，不给任何回应信息，这时候客户端会感觉自己的请求泥牛入海了，过了超时时间才会有反应。 REJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息，客户端刚请求就会收到拒绝的信息。 SNAT：源地址转换，解决内网用户用同一个公网地址上网的问题。 MASQUERADE：是SNAT的一种特殊形式，适用于动态的、临时会变的ip上。 DNAT：目标地址转换。 REDIRECT：在本机做端口映射。 LOG：在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配。 拒绝转发来自192.168.1.10主机的数据，允许转发来自192.168.0.0/24网段的数据 iptables -A FORWARD -s 192.168.1.11 -j REJECT iptables -A FORWARD -s 192.168.0.0/24 -j ACCEPT 说明：注意要把拒绝的放在前面不然就不起作用了啊。 允许本机开放从TCP端口20-1024提供的应用服务。 iptables -A INPUT -p tcp --dport 20:1024 -j ACCEPT iptables -A OUTPUT -p tcp --sport 20:1024 -j ACCEPT 允许转发来自192.168.0.0/24局域网段的DNS解析请求数据包。 iptables -A FORWARD -s 192.168.0.0/24 -p udp --dport 53 -j ACCEPT iptables -A FORWARD -d 192.168.0.0/24 -p udp --sport 53 -j ACCEPT ","date":"2020-04-26","objectID":"/linux_iptables/:3:3","tags":["Linux","iptables"],"title":"Linux之iptables","uri":"/linux_iptables/"},{"categories":["Linux"],"content":"DNAT和SNAT 我们要做的DNAT要在进入这个菱形转发区域之前，也就是在PREROUTING链中做，例如要把访问202.103.96.112的访问转发到192.168.0.112上： iptables -t nat -A PREROUTING -d 202.103.96.112 -j DNAT --to-destination 192.168.0.112 而SNAT自然是要在数据包流出这台机器之前的最后一个链也就是POSTROUTING链来进行操作 iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j SNAT --to-source 58.20.51.66 假如当前系统用的是ADSL/3G/4G动态拨号方式，那么每次拨号，出口IP都会改变，SNAT就会有局限性。 iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -o eth0 -j MASQUERADE 重点在那个『 MASQUERADE 』！这个设定值就是『IP伪装成为封包出去(-o)的那块装置上的IP』！ 不管现在eth0的出口获得了怎样的动态ip，MASQUERADE会自动读取eth0现在的ip地址然后做SNAT出去，这样就实现了很好的动态SNAT地址转换。 ","date":"2020-04-26","objectID":"/linux_iptables/:3:4","tags":["Linux","iptables"],"title":"Linux之iptables","uri":"/linux_iptables/"},{"categories":["Linux"],"content":"删除iptables规则 iptables -D INPUT 3 //删除input的第3条规则 iptables -t nat -D POSTROUTING 1 //删除nat表中postrouting的第一条规则 iptables -F INPUT //清空 filter表INPUT所有规则 iptables -F //清空所有规则 iptables -t nat -F POSTROUTING //清空nat表POSTROUTING所有规则 ","date":"2020-04-26","objectID":"/linux_iptables/:3:5","tags":["Linux","iptables"],"title":"Linux之iptables","uri":"/linux_iptables/"},{"categories":["Linux"],"content":"保存和恢复 iptables 命令修改后规则只存在于内存中，但是我们保存当前规则用来恢复 iptables-save \u003e /etc/sysconfig/iptables.20180606 iptables-restore \u003c /etc/sysconfig/iptables.20180606 参考： iptables之FORWARD转发链 iptables中DNAT、SNAT和MASQUERADE iptables介绍 Linux iptables用法与NAT ","date":"2020-04-26","objectID":"/linux_iptables/:3:6","tags":["Linux","iptables"],"title":"Linux之iptables","uri":"/linux_iptables/"},{"categories":["Java"],"content":"Elasticsearch Elasticsearch是一个基于Lucene的搜索服务器（Lucene可以被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库）。Elasticsearch使用Java编写并使用Lucene来建立索引并实现搜索功能，但是它的目的是通过简单连贯的RESTful API让全文搜索变得简单并隐藏Lucene的复杂性。 ","date":"2020-04-21","objectID":"/elasticsearch_to_know/:1:0","tags":["Java","Elasticsearch"],"title":"Elasticsearch简单使用","uri":"/elasticsearch_to_know/"},{"categories":["Java"],"content":"安装单节点Elasticsearch Elasticsearch是用Java语言开发的，所以你需要安装Java环境，但为了方便起见，我这里选用了Docker安装ES（其实ES官网也有用Docker安装的例子，这里我就把它写成了docker-compose服务）。 docker-compose.yml version: '2.2' services: es: image: elasticsearch:6.7.0 container_name: es0 environment: - node.name=es0 - \"discovery.type=single-node\" - node.data=true - bootstrap.memory_lock=true - network.host=0.0.0.0 - \"ES_JAVA_OPTS=-Xms1g -Xmx1g\" ulimits: memlock: soft: -1 hard: -1 volumes: - ./data:/usr/share/elasticsearch/data ports: - 9200:9200 - 9300:9300 Elasticsearch 启动后，启动了两个端口 9200 和 9300： 9200 端口：HTTP RESTful 接口的通讯端口 9300 端口：TCP 通讯端口，用于集群间节点通信和与 Java 客户端通信的端口 - bootstrap.memory_lock=true ... ulimits: memlock: soft: -1 hard: -1 这两部分是为了禁止使用swap内存，因为当jvm开始swapping时ES的效率会降低。 -Xms1g -Xmx1g是设置了JVM的初始堆大小和最大堆大小（具体参数含义可以参考这里）。 启动之前还是需要调高JVM线程数限制数量，不然启动会报错 vim /etc/sysctl.conf # 添加这个 vm.max_map_count=262144 # 保存后执行这个命令 sysctl -p ","date":"2020-04-21","objectID":"/elasticsearch_to_know/:2:0","tags":["Java","Elasticsearch"],"title":"Elasticsearch简单使用","uri":"/elasticsearch_to_know/"},{"categories":["Java"],"content":"概念 在进一步使用 Elasticsearch 之前，让我们先了解几个关键概念。 在逻辑层面： Index (索引)和Type (类型)：这里的 Index 是名词，在之前开始的时候，我们把**索引（index）和类型（type）**类比于SQL数据库中的 database 和 table，但是这样类比是不合适的。刚开始的ES版本一个索引可以有多个类型，在ES6之后每个索引只能有一个类型，所以他们现在都可以当做一张数据表了。 Document (文档)：Elasticsearch 使用 JSON 文档来表示一个对象，就像是关系数据库中一个 Table 中的一行数据 Field (字段)：每个文档包含多个字段，类似关系数据库中一个 Table 的列 为什么要移除映射类型 开始的时候，我们把**索引（index）和类型（type）**类比于SQL数据库中的 database 和 table，但是这样类比是不合适的。在SQL数据库中，表之间是相互独立的。一个表中的各列并不会影响到其它表中的同名的列。而在映射类型（mapping type）中却不是这样的。 在同一个 Elasticsearch 索引中，其中不同映射类型中的同名字段在内部是由同一个 Lucene 字段来支持的。换句话说，使用上面的例子，user 类型中的 user_name 字段与 tweet 类型中的 user_name 字段是完全一样的，并且两个 user_name 字段在两个类型中必须具有相同的映射（定义）。 这会在某些情况下导致一些混乱，比如，在同一个索引中，当你想在其中的一个类型中将 deleted 字段作为 date 类型，而在另一个类型中将其作为 boolean 字段。 在此之上需要考虑一点，如果同一个索引中存储的各个实体如果只有很少或者根本没有同样的字段，这种情况会导致稀疏数据，并且会影响到Lucene的高效压缩数据的能力 在物理层面： Node (节点)：node 是一个运行着的 Elasticsearch 实例，一个 node 就是一个单独的 server Cluster (集群)：cluster 是多个 node 的集合 Shard (分片)：数据分片，一个 index 可能会存在于多个 shard ","date":"2020-04-21","objectID":"/elasticsearch_to_know/:3:0","tags":["Java","Elasticsearch"],"title":"Elasticsearch简单使用","uri":"/elasticsearch_to_know/"},{"categories":["Java"],"content":"使用 下面，我们将创建一个存储电影信息的 Document： Index 的名称为 movie Type 为 adventure Document 有两个字段：name 和 actors 我们使用 Elasticsearch 提供的 RESTful API 来执行上述操作，如图所示： 用 url 表示一个资源，比如 /movie/adventure/1 就表示一个 index 为 movie，type 为 adventure，id 为 1 的 document 用 http 方法操作资源，如使用 GET 获取资源，使用 POST、PUT 新增或更新资源，使用 DELETE 删除资源等 用curl命令实现上述操作： curl -i -X PUT \"localhost:9200/movie/adventure/1\" -H 'Content-Type: application/json' -d '{\"name\": \"Life of Pi\", \"actors\": [\"Suraj\", \"Irrfan\"]}' ES6之后需要加上headContent-Type: application/json 上述命令返回： HTTP/1.1 201 Created Location: /movie/adventure/1 content-type: application/json; charset=UTF-8 content-length: 158 {\"_index\":\"movie\",\"_type\":\"adventure\",\"_id\":\"4\",\"_version\":1,\"result\":\"created\",\"_shards\":{\"total\":2,\"successful\":1,\"failed\":0},\"_seq_no\":1,\"_primary_term\":1} ","date":"2020-04-21","objectID":"/elasticsearch_to_know/:4:0","tags":["Java","Elasticsearch"],"title":"Elasticsearch简单使用","uri":"/elasticsearch_to_know/"},{"categories":["Java"],"content":"elasticsearch.yml配置说明 #集群的名称 cluster.name: es6.2 #节点名称,其余两个节点分别为node-2 和node-3 node.name: node-1 #指定该节点是否有资格被选举成为master节点，默认是true，es是默认集群中的第一台机器为master，如果这台机挂了就会重新选举master node.master: true #允许该节点存储数据(默认开启) node.data: true #索引数据的存储路径 path.data: /usr/local/elk/elasticsearch/data #日志文件的存储路径 path.logs: /usr/local/elk/elasticsearch/logs #设置为true来锁住内存。因为内存交换到磁盘对服务器性能来说是致命的，当jvm开始swapping时es的效率会降低，所以要保证它不swap bootstrap.memory_lock: true #绑定的ip地址 network.host: 0.0.0.0 #设置对外服务的http端口，默认为9200 http.port: 9200 # 设置节点间交互的tcp端口,默认是9300 transport.tcp.port: 9300 #Elasticsearch将绑定到可用的环回地址，并将扫描端口9300到9305以尝试连接到运行在同一台服务器上的其他节点。 #这提供了自动集群体验，而无需进行任何配置。数组设置或逗号分隔的设置。每个值的形式应该是host:port或host #（如果没有设置，port默认设置会transport.profiles.default.port 回落到transport.tcp.port）。 #请注意，IPv6主机必须放在括号内。默认为127.0.0.1, [::1] discovery.zen.ping.unicast.hosts: [\"192.168.8.101:9300\", \"192.168.8.103:9300\", \"192.168.8.104:9300\"] #如果没有这种设置,遭受网络故障的集群就有可能将集群分成两个独立的集群 - 分裂的大脑 - 这将导致数据丢失 discovery.zen.minimum_master_nodes: 3 参考： Elasticsearch6.2集群搭建 Elasticsearch入门，这一篇就够了 ","date":"2020-04-21","objectID":"/elasticsearch_to_know/:5:0","tags":["Java","Elasticsearch"],"title":"Elasticsearch简单使用","uri":"/elasticsearch_to_know/"},{"categories":["Python"],"content":"Python曲线拟合 本文环境： OS：Ubuntu 18.04.4 LTS Python版本：3.6.9 ","date":"2020-04-12","objectID":"/python_curve_fit/:1:0","tags":["Python","Matplotlib"],"title":"Python曲线拟合","uri":"/python_curve_fit/"},{"categories":["Python"],"content":"曲线拟合 现在我们有一组数据，表达的含义是在不同的时间点的充值金额，反映在坐标上就是一系列的散点，我们希望选择适当的曲线类型（如y = a*x^2 + b）“最佳”地逼近或拟合已知数据，这便是曲线拟合（curve fitting）。当然，变量间未必都是线性关系，我们可能会用到指数函数、对数函数、幂函数等。 ","date":"2020-04-12","objectID":"/python_curve_fit/:2:0","tags":["Python","Matplotlib"],"title":"Python曲线拟合","uri":"/python_curve_fit/"},{"categories":["Python"],"content":"Python拟合库 Python的SciPy库是一个用于数学、科学、工程领域的常用软件包，可以处理插值、积分、优化、图像处理、常微分方程数值解的求解、信号处理等问题。SciPy是基于NumPy，所以你也需要安装NumPy，另外用了Matplotlib库来绘制图表，所以也需要安装Matplotlib。（Python在科学计算领域，numpy、Scipy、Matplotlib是非常受欢迎的三个库） ","date":"2020-04-12","objectID":"/python_curve_fit/:3:0","tags":["Python","Matplotlib"],"title":"Python曲线拟合","uri":"/python_curve_fit/"},{"categories":["Python"],"content":"使用案例 首先安装所需依赖（pip使用豆瓣镜像） pip install -i https://pypi.doubanio.com/simple/ numpy scipy matplotlib ","date":"2020-04-12","objectID":"/python_curve_fit/:4:0","tags":["Python","Matplotlib"],"title":"Python曲线拟合","uri":"/python_curve_fit/"},{"categories":["Python"],"content":"多项式拟合 第一种是进行多项式拟合，数学上可以证明，任意函数都可以表示为多项式形式。用的函数是numpy的polyfit函数 import numpy as np import matplotlib.pyplot as plt # 定义x、y散点坐标 x = [10, 20, 30, 40, 50, 60, 70, 80] y = [174, 236, 305, 334, 349, 351, 342, 323] # 转化为numpy的数组 x = np.array(x) y = np.array(y) # 这里的3表示最高幂，也就是函数形式为y = a* x^3 + b * x^2 + c * x + d parameter = np.polyfit(x, y, 3) print('函数系数为:\\n', parameter) func1 = np.poly1d(parameter) print('函数为 :\\n', func1) # 也可使用newY=np.polyval(func1, x) newY = func1(x) # 拟合y值 # 绘图 plot1 = plt.plot(x, y, 's', label='original values') plot2 = plt.plot(x, newY, 'r', label='polyfit values') plt.xlabel('x') plt.ylabel('y') plt.legend(loc=4) # 指定legend的位置右下角 plt.title('polyfitting') plt.show() 拟合结果: ","date":"2020-04-12","objectID":"/python_curve_fit/:4:1","tags":["Python","Matplotlib"],"title":"Python曲线拟合","uri":"/python_curve_fit/"},{"categories":["Python"],"content":"给定函数形式拟合 scipy模块的子模块optimize中提供了一个专门用于曲线拟合的函数curve_fit() 下面通过示例来说明一下如何使用curve_fit()进行直线和曲线的拟合与绘制。 import numpy as np import matplotlib.pyplot as plt from scipy import optimize #直线方程函数 def f_1(x, A, B): return A*x + B #二次曲线方程 def f_2(x, A, B, C): return A*x*x + B*x + C #三次曲线方程 def f_3(x, A, B, C, D): return A*x*x*x + B*x*x + C*x + D def plot_test(): plt.figure() #拟合点 x0 = [1, 2, 3, 4, 5] y0 = [1, 3, 8, 18, 36] #绘制散点 plt.scatter(x0[:], y0[:], 25, \"red\") #直线拟合与绘制 A1, B1 = optimize.curve_fit(f_1, x0, y0)[0] x1 = np.arange(0, 6, 0.01) y1 = A1*x1 + B1 plt.plot(x1, y1, \"blue\") #二次曲线拟合与绘制 A2, B2, C2 = optimize.curve_fit(f_2, x0, y0)[0] x2 = np.arange(0, 6, 0.01) y2 = A2*x2*x2 + B2*x2 + C2 plt.plot(x2, y2, \"green\") #三次曲线拟合与绘制 A3, B3, C3, D3= optimize.curve_fit(f_3, x0, y0)[0] x3 = np.arange(0, 6, 0.01) y3 = A3*x3*x3*x3 + B3*x3*x3 + C3*x3 + D3 plt.plot(x3, y3, \"purple\") plt.title(\"test\") plt.xlabel('x') plt.ylabel('y') plt.show() return 当然，curve_fit()函数不仅可以用于直线、二次曲线、三次曲线的拟合和绘制，仿照代码中的形式，可以适用于任意形式的曲线的拟合和绘制，只要定义好合适的曲线方程即可。 参考： np.polyfit()与np.poly1d()将点拟合成曲线 直线和曲线的拟合与绘制 ","date":"2020-04-12","objectID":"/python_curve_fit/:4:2","tags":["Python","Matplotlib"],"title":"Python曲线拟合","uri":"/python_curve_fit/"},{"categories":["Java"],"content":" 本文环境： OS：Ubuntu 18.04.4 LTS Java版本：1.8.0_221 ","date":"2020-04-09","objectID":"/java_lookback_java-web/:0:0","tags":["Java","Java Web"],"title":"Java经典回顾之Java Web","uri":"/java_lookback_java-web/"},{"categories":["Java"],"content":"Java Web 虽然我们现在会用SpringBoot快速创建一个Web Demo，但是基础不能忘（SpringBoot或者SpringMVC都是封装后的产物），下面就让我们回顾一下一个最基本的Java Web项目。 ","date":"2020-04-09","objectID":"/java_lookback_java-web/:1:0","tags":["Java","Java Web"],"title":"Java经典回顾之Java Web","uri":"/java_lookback_java-web/"},{"categories":["Java"],"content":"创建项目 这里我们使用IDEA来创建项目，点击菜单File=\u003eNew=\u003eProject，选择Java Enterprise，在Additional Libraries and Framework中，选择Web Application（我这里是4.0，旧版本的IDEA可能其他的），Application Server就是Java Web项目编译打包后运行所需要的Web服务器（你需要自己配置一下）。 点击Next后，填写项目名称就好了，这里我创建了一个simplejavaweb的项目。 我们来看一下项目结构 src就是我们写Java代码的地方 web目录是web应用部署根目录 web中的WEB_INF是Java的web应用的安全目录。所谓安全就是客户端无法访问，只有服务端可以访问的目录。如果想在页面中直接访问其中的文件，必须通过web.xml文件对要访问的文件进行相应映射才能访问。 WEB_INF中的web.xml是Java web 项目最主要的构成部分之一，它是Web应用程序配置文件，描述了 servlet 和其他的应用组件配置及命名规则。 ","date":"2020-04-09","objectID":"/java_lookback_java-web/:2:0","tags":["Java","Java Web"],"title":"Java经典回顾之Java Web","uri":"/java_lookback_java-web/"},{"categories":["Docker"],"content":" 本文环境： OS：Ubuntu 18.04.4 LTS Golang版本：1.12.13 ","date":"2020-04-06","objectID":"/docker_cgroups/:0:0","tags":["Docker","Cgroups"],"title":"一步步自己做个Docker之Cgroups","uri":"/docker_cgroups/"},{"categories":["Docker"],"content":"什么是Linux Cgroups Linux Cgroups（Control Groups）提供了对一组进程及将来的子进程的资源限制、控制和统计的能力，这些资源包括CPU、内存、存储、网络等。本质上来说，Cgroups 是内核附加在程序上的一系列钩子(hook)，通过程序运行时对资源的调度触发相应的钩子以达到资源追踪和限制的目的。 参考： linux cgroups 简介 ","date":"2020-04-06","objectID":"/docker_cgroups/:1:0","tags":["Docker","Cgroups"],"title":"一步步自己做个Docker之Cgroups","uri":"/docker_cgroups/"},{"categories":["Java"],"content":"GC GC就是垃圾回收（Garbage Collection），如果你写过C++或者C程序的，你就会知道new一个数据后，就需要delete它的内存，这就是手动管理内存，但这样如果你粗心点的话，就容易造成内存泄露，所以就有了自动垃圾回收，也就我们这里所讨论的GC。Java的GC会对JVM（Java Virtual Machine）中的内存进行标记，并确定哪些内存需要回收，根据一定的回收策略，自动的回收内存，永不停息（Nerver Stop）的保证JVM中的内存空间，防止出现内存泄露和溢出问题。 其实GC很早就有了，1960年诞生于MIT的Lisp是第一门真正使用内存动态分配和垃圾收集技术的语言。 ","date":"2020-04-01","objectID":"/java_gc/:1:0","tags":["GC","Java"],"title":"Java之GC","uri":"/java_gc/"},{"categories":["Java"],"content":"内存布局 JVM 在执行 Java 程序的过程中会把它所管理的内存划分为若干个不同的数据区域。有的区域依赖线程的启动和结束而建立和销毁，这样的区域可看作是线程私有的区域（Per-Thread Data Area）；其他的区域则随着虚拟机进程的启动而存在，可以看做是线程间共享的区域。 具体而言，JVM 的运行时数据区域包括如下： 程序计数器（Program Counter Register）：线程私有的数据区域，保存当前正在执行的虚拟机指令的地址； Java 虚拟机栈（Java Virtual Machine Stack）：线程私有的数据区域，每个栈帧中存放当前执行方法的本地变量及返回地址； Java 堆（Heap）：线程共享的数据区域，对象及数组的分配空间； 方法区（Method Area）：线程共享的数据区域，存放由类加载器加载的类型信息、常量及静态变量； 本地方法栈（Native Method Stack）：用于 Native 方法的方法栈 运行时常量池（Runtime Constant Pool）是方法区的一部分，用于存储编译器生成的常量和引用。一般来说，常量的分配在编译时就能确定，但也不全是，也可以存储在运行时期产生的常量。比如String类的intern（）方法，作用是String类维护了一个常量池，如果调用的字符\"hello\"已经在常量池中，则直接返回常量池中的地址，否则新建一个常量加入池中，并返回地址。 ","date":"2020-04-01","objectID":"/java_gc/:2:0","tags":["GC","Java"],"title":"Java之GC","uri":"/java_gc/"},{"categories":["Java"],"content":"GC大致过程 在JVM的堆内存中，被分为了年轻代（Young Generation）和老年代（Old Generation、持久代（Permanent Generation）。其中年轻代又被分为Eden区和survivor区，而survivor区又被分为大小相等的2个区，分别称为S1区和S2区。持久代在Sun Hotpot虚拟机中就是指方法区（有些JVM根本就没有持久代这一说法） 当程序需要在堆上分配内存时，会首先在eden区进行分配。 当eden区内存已满无法再分配对象时，会触发第一次minor gc，将eden区存活的对象拷贝到其中一个survivor区，比如S1，并把eden区的内存清空，以备使用。 当eden区的内存再次被使用完时，会触发第二次minor gc，将eden区和S1区中存活的对象拷贝到S2区，并将eden区和S1区的内存清空以备使用。在有的书中会提到from区和to区，其实from区和to区是相对而言的，当把S1区的内容拷贝到S2区时，S1为from区，S2为to区。而将S2区的内容拷贝到S1时，S2为from区，S1为to区。 当eden区的内存再次被用完时，会触发第三次minor gc，将eden区和S2区存活的对象拷贝到S1区，并清空eden区和S2区的内存，以备使用。 上述过程循环往复。 当某个对象经历了一次minor gc并且存活下来，没有被清理掉，则说这个对象长大了一岁。当某个对象的年龄大于一定阈值，通常是15岁时，该对象在下次minor gc时会被放到老年代中。 当老年代中的内存不够用时，会触发full gc。 ","date":"2020-04-01","objectID":"/java_gc/:3:0","tags":["GC","Java"],"title":"Java之GC","uri":"/java_gc/"},{"categories":["Docker","Golang"],"content":" 本文环境： OS：Ubuntu 18.04.4 LTS Golang版本：1.12.13 ","date":"2020-03-26","objectID":"/docker_go_namespace/:0:0","tags":["Docker","Linux"],"title":"一步步自己做个Docker之Go调用Namespace","uri":"/docker_go_namespace/"},{"categories":["Docker","Golang"],"content":"Golang Go语言是Google开发的一种静态类型、编译型的高级语言，它设计的蛮简单的，学过C的话，其实上手Go很快的，当然相比于C的话，Go有垃圾回收和并发支持，所以写起来心智负担更低一点。 对于Go的安装和配置，我以前写过一篇文章——go语言基本配置，我这里就不在赘述了。Go1.11增加了go modules，使用它的话，就没必要一定要把代码放到GOPATH下面啦~(≧▽≦)/~。 go modules详细 使用请参考go mod 使用。 ","date":"2020-03-26","objectID":"/docker_go_namespace/:1:0","tags":["Docker","Linux"],"title":"一步步自己做个Docker之Go调用Namespace","uri":"/docker_go_namespace/"},{"categories":["Docker","Golang"],"content":"Go调用Namespace 其实对于Namespace这种系统调用，使用C语言描述是最好的（上一篇文章就是用C写的示例），但是C比较难，而且Docker也是用Go是实现的，所以我后面的文章都会用Go来写示例代码。 这里我先写了一个UTS Namespace的例子，UTS Namespace主要用来隔离nodename和domainname这两个系统标识： package main import ( \"log\" \"os\" \"os/exec\" \"syscall\" ) func main() { cmd := exec.Command(\"sh\") cmd.SysProcAttr = \u0026syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS, } cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err != nil { log.Fatal(err) } } exec.Command(\"sh\")是指定了fork出来的新进程内的初始命令，cmd.SysProcAttr这行就是设置了系统调用函数，Go帮我们封装了clone()函数，syscall.CLONE_NEWUTS这个标识符标明创建一个UTS Namespace。 go build .编译代码后，执行程序时我们会遇到错误fork/exec /bin/sh: operation not permitted，这是因为clone()函数需要CAP_SYS_ADMIN权限（这个问题我在v站上问过），解决方法是添加设置 uid 映射： package main import ( \"log\" \"os\" \"os/exec\" \"syscall\" ) func main() { cmd := exec.Command(\"sh\") cmd.SysProcAttr = \u0026syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWUSER, UidMappings: []syscall.SysProcIDMap{ { ContainerID: 0, HostID: os.Getuid(), Size: 1, }, }, GidMappings: []syscall.SysProcIDMap{ { ContainerID: 0, HostID: os.Getgid(), Size: 1, }, }, } // set identify for this demo cmd.Env = []string{\"PS1=-[namespace-process]-# \"} cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err != nil { log.Fatal(err) } } 我增加了CLONE_NEWUSER标识，让新进程在User Namespace中变成root用户。 $ ./uts-easy -[namespace-process]-# id uid=0(root) gid=0(root) groups=0(root),65534(nogroup) -[namespace-process]-# hostname -b bird -[namespace-process]-# hostname bird 启动另一个shell，查看宿主机上hostname: $ hostname salamander-PC 可以看到，外部的hostname并没有被内部的修改所影响，这里我们大致感受了下UTS Namespace的作用。 ","date":"2020-03-26","objectID":"/docker_go_namespace/:2:0","tags":["Docker","Linux"],"title":"一步步自己做个Docker之Go调用Namespace","uri":"/docker_go_namespace/"},{"categories":["Docker","Golang"],"content":"增加IPC Namespace IPC Namespace用来隔离System V IPC和POSIX message queues。每一个IPC Namespace都有自己的System V IPC和POSIX message queues。我们稍微改动一下上面的代码。 package main import ( \"log\" \"os\" \"os/exec\" \"syscall\" ) func main() { cmd := exec.Command(\"sh\") cmd.SysProcAttr = \u0026syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWUSER | syscall.CLONE_NEWIPC, // 增加IPC Namespace UidMappings: []syscall.SysProcIDMap{ { ContainerID: 0, HostID: os.Getuid(), Size: 1, }, }, GidMappings: []syscall.SysProcIDMap{ { ContainerID: 0, HostID: os.Getgid(), Size: 1, }, }, } // set identify for this demo cmd.Env = []string{\"PS1=-[namespace-process]-# \"} cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err != nil { log.Fatal(err) } } 新开一个shell，在宿主机上创建一个message queue: $ ipcs -q --------- 消息队列 ----------- 键 msqid 拥有者 权限 已用字节数 消息 $ ipcmk -Q 消息队列 id：0 $ ipcs -q --------- 消息队列 ----------- 键 msqid 拥有者 权限 已用字节数 消息 0xc59399dd 0 salamander 644 0 0 运行我们自己的程序： $ ./uts-easy -[namespace-process]-# ipcs -q ------ Message Queues -------- key msqid owner perms used-bytes messages 可以看到，在新的Namespace中，看不到宿主机上创建的message queue,说明IPC是隔离的。 ","date":"2020-03-26","objectID":"/docker_go_namespace/:3:0","tags":["Docker","Linux"],"title":"一步步自己做个Docker之Go调用Namespace","uri":"/docker_go_namespace/"},{"categories":["Docker","Golang"],"content":"增加PID Namespace PID Namespace是用来隔离进程ID的。我们自己进入Docker 容器的时候，就会发现里面的前台进程的PID为1，但是在容器外PID却不是1，这就是通过PID Namespace做到的。修改上述的代码，增加CLONE_NEWPID： package main import ( \"log\" \"os\" \"os/exec\" \"syscall\" ) func main() { cmd := exec.Command(\"sh\") cmd.SysProcAttr = \u0026syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWUSER | syscall.CLONE_NEWIPC | syscall.CLONE_NEWPID, // 增加PID Namespace UidMappings: []syscall.SysProcIDMap{ { ContainerID: 0, HostID: os.Getuid(), Size: 1, }, }, GidMappings: []syscall.SysProcIDMap{ { ContainerID: 0, HostID: os.Getgid(), Size: 1, }, }, } // set identify for this demo cmd.Env = []string{\"PS1=-[namespace-process]-# \"} cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err != nil { log.Fatal(err) } } 运行我们的程序： ./uts-easy -[namespace-process]-# echo $$ 1 可以看到在新的PID Namespace中进程ID为1。 $ pstree -pl | grep easy | | |-bash(10739)---uts-easy(10768)-+-sh(10773) | | | |-{uts-easy}(10769) | | | |-{uts-easy}(10770) | | | |-{uts-easy}(10771) | | | `-{uts-easy}(10772) 而我们在宿主机上可以看到它实际的PID（uts-easy这个进程）为10768。 如果细心点，我们会发现，在我们的程序中使用ps，top这些命令出来的结果跟宿主机上是一样的，这是因为这些命令其实是去使用**/proc**这个文件夹的内容，这个就需要下面的Mount Namespace了。 ","date":"2020-03-26","objectID":"/docker_go_namespace/:4:0","tags":["Docker","Linux"],"title":"一步步自己做个Docker之Go调用Namespace","uri":"/docker_go_namespace/"},{"categories":["Docker","Golang"],"content":"增加Mount Namespace Mount Namespace用来隔离各个进程看到的挂载点视图。在不同Namespace的进程中，看到的文件系统层次是不一样的。在Mount Namespace中调用mount()和unmount()只会影响当前Namespace内的文件系统，而对全局的文件系统是没有影响的。 看到这里，也许会想到chroot()。它也能将某一个子目录变为根节点。但是，Mount Namespace不仅能实现这个功能，而且能以更加灵活和安全的方式实现。 现在继续修改上述代码，增加CLONE_NEWNS（Mount Namespace是Linux实现的第一个Namespace类型，因为，它的系统调用参数是NEWNS，NS是New Namespace的缩写。当时人们没有意识到，以后还会有很多类型的Namespace加入Linux大家庭）。 package main import ( \"log\" \"os\" \"os/exec\" \"syscall\" ) func main() { cmd := exec.Command(\"sh\") cmd.SysProcAttr = \u0026syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWUSER | syscall.CLONE_NEWIPC | syscall.CLONE_NEWPID| syscall.CLONE_NEWNS, // 增加Mount Namespace UidMappings: []syscall.SysProcIDMap{ { ContainerID: 0, HostID: os.Getuid(), Size: 1, }, }, GidMappings: []syscall.SysProcIDMap{ { ContainerID: 0, HostID: os.Getgid(), Size: 1, }, }, } // set identify for this demo cmd.Env = []string{\"PS1=-[namespace-process]-# \"} cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err != nil { log.Fatal(err) } } 运行程序，查看/proc的文件内容。 -[namespace-process]-# ls /proc 1 1537 198 212 2487 2818 29 3131 329 3363 3422 3557 3793 4250 492 5273 595 62 6519 72 80 87 919 crypto kmsg schedstat vmstat 10 16 1983 213 2501 2841 2902 3139 3297 3367 3425 3571 38 430 493 53 598 6220 654 7221 8042 88 922 devices kpagecgroup scsi zoneinfo 1025 17 2 2133 2506 2846 2913 3156 .... 这里输出的结果很多，因为**/proc还是宿主机的，下面将/proc** mount到我们自己的Namespace下面来： -[namespace-process]-# mount -t proc proc /proc -[namespace-process]-# ls /proc 1 buddyinfo consoles diskstats fb iomem kcore kpagecgroup locks modules pagetypeinfo schedstat softirqs sysrq-trigger tty vmallocinfo 4 bus cpuinfo dma filesystems ioports key-users kpagecount mdstat mounts partitions scsi stat sysvipc uptime vmstat acpi cgroups crypto driver fs irq keys kpageflags meminfo mtrr pressure self swaps thread-self version zoneinfo asound cmdline devices execdomains interrupts kallsyms kmsg loadavg misc net sched_debug slabinfo sys timer_list version_signature 结果一下子少了很多，这里我们就可以用ps来查看系统的进程了。 -[namespace-process]-# ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 17:07 pts/1 00:00:00 sh root 5 1 0 17:11 pts/1 00:00:00 ps -ef 可以看到，当前的Namespace中，sh进程是PID为1的进程。 ","date":"2020-03-26","objectID":"/docker_go_namespace/:5:0","tags":["Docker","Linux"],"title":"一步步自己做个Docker之Go调用Namespace","uri":"/docker_go_namespace/"},{"categories":["Docker","Golang"],"content":"增加Network Namespace Network Namespace是用来隔离网络设备、IP地址端口等网络栈的Namespace。Network Namespace可以让每个容器拥有自己独立（虚拟的）网络设备，而且容器内的应用可以绑定到自己的端口，每个Namespace内的端口都不会互相冲突。在宿主机上搭建网桥后，就能很方便地实现容器之间通讯，而且不同容器上的应用可以使用相同的端口。 继续上述代码，加入CLONE_NEWNET： package main import ( \"log\" \"os\" \"os/exec\" \"syscall\" ) func main() { cmd := exec.Command(\"sh\") cmd.SysProcAttr = \u0026syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWUSER | syscall.CLONE_NEWIPC | syscall.CLONE_NEWPID| syscall.CLONE_NEWNS | syscall.CLONE_NEWNET, // 增加Network Namespace UidMappings: []syscall.SysProcIDMap{ { ContainerID: 0, HostID: os.Getuid(), Size: 1, }, }, GidMappings: []syscall.SysProcIDMap{ { ContainerID: 0, HostID: os.Getgid(), Size: 1, }, }, } // set identify for this demo cmd.Env = []string{\"PS1=-[namespace-process]-# \"} cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err != nil { log.Fatal(err) } } 运行我们的程序，查看网络设备，发现为空 -[namespace-process]-# ifconfig -[namespace-process]-# 在宿主机上查看网络设备，发现有lo, enp7s0这些网络设备。 enp7s0: flags=4099\u003cUP,BROADCAST,MULTICAST\u003e mtu 1500 ether 98:fa:9b:f0:85:c2 txqueuelen 1000 (以太网) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73\u003cUP,LOOPBACK,RUNNING\u003e mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10\u003chost\u003e loop txqueuelen 1000 (本地环回) RX packets 16381 bytes 23729834 (23.7 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 16381 bytes 23729834 (23.7 MB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 .... 从上面的结果我们可以看出Network是隔离了。 ","date":"2020-03-26","objectID":"/docker_go_namespace/:6:0","tags":["Docker","Linux"],"title":"一步步自己做个Docker之Go调用Namespace","uri":"/docker_go_namespace/"},{"categories":["protocol","https"],"content":"https https就是在http的基础上又增加了一个TLS层，它就是一个套壳协议。 ","date":"2020-03-21","objectID":"/https_more/:1:0","tags":["https","协议"],"title":"https深入分析","uri":"/https_more/"},{"categories":["protocol","https"],"content":"加密和解密 https的发展和密码学的发展是分不开的。加密方式可以大体分为对称加密和非对称加密 对称加密，就是加密和解密都是用同一个秘钥，这种方式优点就是速度快，缺点就是在管理和分配秘钥的时候不安全。 非对称加密算法，非对称加密有一个秘钥对，叫做公钥和私钥，私钥自己持有，公钥可以公开的发送给使用的人。使用公钥进行加密的信息，只有和其配对的私钥可以解开。目前常见的非对称加密算法是RSA，非对称的加密算法的优点是安全，因为他不需要把私钥暴露出去。 在正式的使用场景中一般都是对称加密和非对称加密结合使用，使用非对称加密完成秘钥的传递，然后使用对称秘钥进行数据加密和解密 ","date":"2020-03-21","objectID":"/https_more/:2:0","tags":["https","协议"],"title":"https深入分析","uri":"/https_more/"},{"categories":["protocol","https"],"content":"https的简要流程 先是经典的TCP三次握手，这里不详细展开了。 client Hello,客户端（通常是浏览器）先向服务器发出加密通信的请求 * 支持的协议版本，比如TLS 1.0版。 * 一个客户端生成的随机数 random1，稍后用于生成\"对话密钥\"。 * 支持的加密方法，比如RSA公钥加密。 * 支持的压缩方法。 服务器收到请求,然后响应 (server Hello) * 确认使用的加密通信协议版本，比如TLS 1.0版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信。 * 一个服务器生成的随机数random2，稍后用于生成\"对话密钥\"。 * 确认使用的加密方法，比如RSA公钥加密。 * 服务器证书。 客户端收到证书之后会首先会进行验证 验证通过之后，客户端会生成一个随机数pre-master secret，然后使用证书中的公钥进行加密，然后传递给服务器端 服务器收到使用公钥加密的内容，在服务器端使用私钥解密之后获得随机数pre-master secret，然后根据radom1、radom2、pre-master secret通过一定的算法得出session Key和MAC算法秘钥，作为后面交互过程中使用对称秘钥。同时客户端也会使用radom1、radom2、pre-master secret，和同样的算法生成session Key和MAC算法的秘钥。 ","date":"2020-03-21","objectID":"/https_more/:3:0","tags":["https","协议"],"title":"https深入分析","uri":"/https_more/"},{"categories":["protocol","https"],"content":"https证书 服务器发给了客户端证书，客户端是如何验证证书的有效性的呢？这里我们分析一下它的原理。 SSL 证书中包含的具体内容有： （1）证书的发布机构CA （2）证书的有效期 （3）公钥 （4）证书所有者 （5）签名 … CA机构在签发证书的时候，都会使用自己的私钥对证书进行签名，如果我们使用的是购买的证书，那么很有可能，颁发这个证书的CA机构的公钥已经预置在操作系统中。这样浏览器就可以使用CA机构的公钥对服务器的证书进行验签，验签之后得到的是CA机构使用sha256得到的证书摘要，客户端就会对服务器发送过来的证书使用sha256进行哈希计算得到一份摘要，然后对比之前由CA得出来的摘要，就可以知道这个证书是不是正确的，是否被修改过。 所以说原理就是因为CA机构的公钥已经预存于我们的操作系统之中。 完整的验证过程如下： 首先浏览器读取证书中的证书所有者、有效期等信息进行一一校验； 浏览器开始查找操作系统中已内置的受信任的证书发布机构CA，与服务器发来的证书中的颁发者CA比对，用于校验证书是否为合法机构颁发； 如果找不到，浏览器就会报错，说明服务器发来的证书是不可信任的； 如果找到，那么浏览器就会从操作系统中取出 颁发者CA 的公钥，然后对服务器发来的证书里面的签名进行解密； 浏览器使用相同的hash算法计算出服务器发来的证书的hash值，将这个计算的hash值与证书中签名做对比； 对比结果一致，则证明服务器发来的证书合法，没有被冒充； 此时浏览器就可以读取证书中的公钥，用于后续加密了 参考： 深入理解HTTPS协议 HTTPS协议原理和流程分析 ","date":"2020-03-21","objectID":"/https_more/:4:0","tags":["https","协议"],"title":"https深入分析","uri":"/https_more/"},{"categories":["Java"],"content":" Zookeeper 是 Apache 的一个顶级项目，为分布式应用提供高效、高可用的分布式协调服务，提供了诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知和分布式锁等分布式基础服务。 由于 ZooKeeper 便捷的使用方式、卓越的性能和良好的稳定性，被广泛地应用于诸如 Hadoop、HBase、Kafka 和 Dubbo 等大型分布式系统中。 ","date":"2020-03-12","objectID":"/zookeeper_cluster_lock/:0:0","tags":["zookeeper","Java"],"title":"基于Zookeeper的分布式锁","uri":"/zookeeper_cluster_lock/"},{"categories":["Java"],"content":"搭建Zookeeper集群 这里我们用Docker在本机上快速搭建一个zk集群，根据官方的zookeeper镜像给的docker-compose文件，我们稍加修改就可以了： version: '2' services: zoo1: image: zookeeper:3.4 restart: always hostname: zoo1 ports: - 2181:2181 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=0.0.0.0:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 volumes: - ./zoo1/data:/data - ./zoo1/datalog:/datalog zoo2: image: zookeeper:3.4 restart: always hostname: zoo2 ports: - 2182:2181 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zoo3:2888:3888 volumes: - ./zoo2/data:/data - ./zoo2/datalog:/datalog zoo3: image: zookeeper:3.4 restart: always hostname: zoo3 ports: - 2183:2181 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=0.0.0.0:2888:3888 volumes: - ./zoo3/data:/data - ./zoo3/datalog:/datalog docker-compose up 启动集群，然后查看服务状态： $ docker-compose ps Name Command State Ports ------------------------------------------------------------------------------------------------------------------------ zookeeper-cluster_zoo1_1 /docker-entrypoint.sh zkSe ... Up 0.0.0.0:2181-\u003e2181/tcp, 2888/tcp, 3888/tcp, 8080/tcp zookeeper-cluster_zoo2_1 /docker-entrypoint.sh zkSe ... Up 0.0.0.0:2182-\u003e2181/tcp, 2888/tcp, 3888/tcp, 8080/tcp zookeeper-cluster_zoo3_1 /docker-entrypoint.sh zkSe ... Up 0.0.0.0:2183-\u003e2181/tcp, 2888/tcp, 3888/tcp, 8080/tcp $ docker-compose exec zoo1 ./bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /conf/zoo.cfg Mode: follower $ docker-compose exec zoo2 ./bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /conf/zoo.cfg Mode: follower $ docker-compose exec zoo3 ./bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /conf/zoo.cfg Mode: leader 可以看到zoo3这个节点是leader节点（zookeeper3.5的镜像似乎有点问题，集群起来后有个节点一直出错，所以我用了3.4）。 ","date":"2020-03-12","objectID":"/zookeeper_cluster_lock/:1:0","tags":["zookeeper","Java"],"title":"基于Zookeeper的分布式锁","uri":"/zookeeper_cluster_lock/"},{"categories":["Java"],"content":"zookeeper配置文件 zoo.cfg配置文件常见配置 tickTime=2000 initLimit=10 syncLimit=5 dataLogDir=/opt/zookeeper/logs dataDir=/opt/zookeeper/data clientPort=2181 autopurge.snapRetainCount=500 autopurge.purgeInterval=24 server.1= 192.168.1.148:2888:3888 server.2= 192.168.1.149:2888:3888 server.3= 192.168.1.150:2888:3888 zoo.cfg配置文件参数详细说明 参数名 说明 clientPort 客户端连接server的端口，即对外服务端口，一般设置为2181吧。 dataDir 存储快照文件snapshot的目录。默认情况下，事务日志也会存储在这里。建议同时配置参数dataLogDir, 事务日志的写性能直接影响zk性能。 tickTime ZK中的一个时间单元。ZK中所有时间都是以这个时间单元为基础，进行整数倍配置的。例如，session的最小超时时间是2*tickTime。 dataLogDir 事务日志输出目录。尽量给事务日志的输出配置单独的磁盘或是挂载点，这将极大的提升ZK性能。 （No Java system property） globalOutstandingLimit 最大请求堆积数。默认是1000。ZK运行的时候， 尽管server已经没有空闲来处理更多的客户端请求了，但是还是允许客户端将请求提交到服务器上来，以提高吞吐性能。当然，为了防止Server内存溢出，这个请求堆积数还是需要限制下的。 (Java system property:zookeeper.globalOutstandingLimit. ) preAllocSize 预先开辟磁盘空间，用于后续写入事务日志。默认是64M，每个事务日志大小就是64M。如果ZK的快照频率较大的话，建议适当减小这个参数。(Java system property:zookeeper.preAllocSize ) snapCount 每进行snapCount次事务日志输出后，触发一次快照(snapshot), 此时，ZK会生成一个snapshot.文件，同时创建一个新的事务日志文件log.。默认是100000.（真正的代码实现中，会进行一定的随机数处理，以避免所有服务器在同一时间进行快照而影响性能）(Java system property:zookeeper.snapCount ) traceFile 用于记录所有请求的log，一般调试过程中可以使用，但是生产环境不建议使用，会严重影响性能。(Java system property:? requestTraceFile ) maxClientCnxns 单个客户端与单台服务器之间的连接数的限制，是ip级别的，默认是60，如果设置为0，那么表明不作任何限制。请注意这个限制的使用范围，仅仅是单台客户端机器与单台ZK服务器之间的连接数限制，不是针对指定客户端IP，也不是ZK集群的连接数限制，也不是单台ZK对所有客户端的连接数限制。指定客户端IP的限制策略，这里有一个patch，可以尝试一下：http://rdc.taobao.com/team/jm/archives/1334（No Java system property） clientPortAddress 对于多网卡的机器，可以为每个IP指定不同的监听端口。默认情况是所有IP都监听 clientPort 指定的端口。 New in 3.3.0 minSessionTimeoutmaxSessionTimeoutSession 超时时间限制，如果客户端设置的超时时间不在这个范围，那么会被强制设置为最大或最小时间。默认的Session超时时间是在2 * tickTime ~ 20 * tickTime 这个范围 New in 3.3.0 fsync.warningthresholdms 事务日志输出时，如果调用fsync方法超过指定的超时时间，那么会在日志中输出警告信息。默认是1000ms。(Java system property: fsync.warningthresholdms )New in 3.3.4 autopurge.purgeInterval 在上文中已经提到，3.4.0及之后版本，ZK提供了自动清理事务日志和快照文件的功能，这个参数指定了清理频率，单位是小时，需要配置一个1或更大的整数，默认是0，表示不开启自动清理功能。(No Java system property) New in 3.4.0 autopurge.snapRetainCount 这个参数和上面的参数搭配使用，这个参数指定了需要保留的文件数目。默认是保留3个。(No Java system property) New in 3.4.0 electionAlg 在之前的版本中， 这个参数配置是允许我们选择leader选举算法，但是由于在以后的版本中，只会留下一种“TCP-based version of fast leader election”算法，所以这个参数目前看来没有用了，这里也不详细展开说了。(No Java system property) initLimitFollowe r在启动过程中，会从Leader同步所有最新数据，然后确定自己能够对外服务的起始状态。Leader允许F在 initLimit 时间内完成这个工作。通常情况下，我们不用太在意这个参数的设置。如果ZK集群的数据量确实很大了，F在启动的时候，从Leader上同步数据的时间也会相应变长，因此在这种情况下，有必要适当调大这个参数了。(No Java system property) syncLimit 在运行过程中，Leader负责与ZK集群中所有机器进行通信，例如通过一些心跳检测机制，来检测机器的存活状态。如果L发出心跳包在syncLimit之后，还没有从F那里收到响应，那么就认为这个F已经不在线了。注意：不要把这个参数设置得过大，否则可能会掩盖一些问题。(No Java system property) leaderServes 默认情况下，Leader是会接受客户端连接，并提供正常的读写服务。但是，如果你想让Leader专注于集群中机器的协调，那么可以将这个参数设置为no，这样一来，会大大提高写操作的性能。(Java system property: zookeeper. leaderServes )。 server.x=[hostname]:nnnnn[:nnnnn] 这里的x是一个数字，与myid文件中的id是一致的。右边可以配置两个端口，第一个端口用于F和L之间的数据同步和其它通信，第二个端口用于Leader选举过程中投票通信。 (No Java system property) group.x=nnnnn[:nnnnn]weight.x=nnnnn 对机器分组和权重设置，可以 参见这里(No Java system property) cnxTimeoutLeader 选举过程中，打开一次连接的超时时间，默认是5s。(Java system property: zookeeper. cnxTimeout) zookeeper.DigestAuthenticationProvider.superDigestZK 权限设置相关，具体参见 《 使用super 身份对有权限的节点进行操作 》 和 《 ZooKeeper 权限控制 》 skipACL 对所有客户端请求都不作ACL检查。如果之前节点上设置有权限限制，一旦服务器上打开这个开头，那么也将失效。(Java system property: zookeeper.skipACL ) forceSync 这个参数确定了是否需要在事务日志提交的时候调用 FileChannel .force来保证数据完全同步到磁盘。(Java system property: zookeeper.forceSync ) jute.maxbuffer 每个节点最大数据量，是默认是1M。这个限制必须在server和client端都进行设置才会生效。(Java system property: jute.maxbuffer ) 上面的docker-compose.yml文件中，我没用配置文件，但是上面的配置项其实可以用zookeeper镜像里的环境变量来实现，例如ZOO_TICK_TIME。 ","date":"2020-03-12","objectID":"/zookeeper_cluster_lock/:2:0","tags":["zookeeper","Java"],"title":"基于Zookeeper的分布式锁","uri":"/zookeeper_cluster_lock/"},{"categories":["Java"],"content":"Zookeeper分布式锁实现 ","date":"2020-03-12","objectID":"/zookeeper_cluster_lock/:3:0","tags":["zookeeper","Java"],"title":"基于Zookeeper的分布式锁","uri":"/zookeeper_cluster_lock/"},{"categories":["Java"],"content":"Zookeeper的节点 要用Zookeeper实现分布式锁，我就不得不说说Zookeeper的数据存储。首先zookeeper的核心保存结构是一个DataTree数据结构，其实内部是一个Map\u003cString, DataNode\u003e nodes的数据结构，其中key是path，DataNode才是真正保存数据的核心数据结构，DataNode核心字段包括byte data[]用于保存节点内容。 节点是Zookeeper（zk）中数据存储的基础结构，zk中万物皆节点，就好比Java中万物皆对象一样。zk的数据模型就是基于节点的树形结构，但zk规定每个节点的引用规则是路径引用。每个节点中包含子节点引用、存储数据、访问权限以及节点元数据等四部分。 zookeeper中提供了节点类型主要有： 持久节点：节点创建后，就一直存在，直到有删除操作来主动清除。 顺序节点：假如当前有一个父节点为/lock，我们可以在这个父节点下面创建子节点；zk提供了一个可选的有序特性，例如我们可以创建子节点“/lock/test_”并且指明有序，那么zk在生成子节点时会根据当前子节点数量自动添加整数序号，如果第一个子节点为/lock/test_0000000000，下一个节点则为/lock/test_0000000001，依次类推。 临时节点：客户端可以建立一个临时节点，在会话结束或者会话超时后，zookeeper会自动删除该节点。 ","date":"2020-03-12","objectID":"/zookeeper_cluster_lock/:3:1","tags":["zookeeper","Java"],"title":"基于Zookeeper的分布式锁","uri":"/zookeeper_cluster_lock/"},{"categories":["Java"],"content":"synchronized 在Java多线程编程中，我们最先碰到的也是最简单的方法就利用synchronized关键字。用它的方式有三种： 修饰实例方法，锁是当前实例对象 修饰静态方法，锁是当前类的class对象（每个类都有一个Class对象） 修饰代码块，锁定括号里的对象 加上synchronized之后，我们的代码就变成了同步代码，神奇又强大，但有的时候也不禁会思考下：Java底层是怎么实现synchronized关键字的？ 在阅读了一些文章之后，我在这里做了一些归纳和总结。 首先，看一段简单的Java代码： public class SyncTest { public synchronized void test1(){ } public void test2(){ synchronized (this){ } } } 先用javac SyncTest.java编译出class文件，再利用javap -v -c SyncTest.class查看synchronized的实现。javap是jdk自带的反解析工具。它的作用就是根据class字节码文件，反解析出当前类对应的code区（汇编指令）、本地变量表、异常表和代码行偏移量映射表、常量池等等信息。 反解析结果为： .... { public synchronized void test1(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=0, locals=1, args_size=1 0: return LineNumberTable: line 4: 0 public void test2(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter // 监视器进入，获取锁 4: aload_1 5: monitorexit // 监视器退出，释放锁 6: goto 14 9: astore_2 10: aload_1 11: monitorexit 12: aload_2 13: athrow 14: return Exception table: from to target type 4 6 9 any 9 12 9 any LineNumberTable: line 7: 0 line 9: 4 line 10: 14 StackMapTable: number_of_entries = 2 frame_type = 255 /* full_frame */ offset_delta = 9 locals = [ class SyncTest, class java/lang/Object ] stack = [ class java/lang/Throwable ] frame_type = 250 /* chop */ offset_delta = 4 } SourceFile: \"SyncTest.java\" 从上面可以看出，同步代码块是使用monitorenter和monitorexit指令实现的，同步方法（在这看不出来需要看JVM底层实现）依靠的是方法修饰符上的ACC_SYNCHRONIZED实现。 ","date":"2020-02-25","objectID":"/java_synchronized_underlying/:1:0","tags":["synchronized","java"],"title":"Java之synchronized的实现原理","uri":"/java_synchronized_underlying/"},{"categories":["Java"],"content":"Java对象头 Java对象头和monitor是实现synchronized的基础。 HotSpot虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 普通对象的对象头包括两部分：Mark Word 和 Class Metadata Address （类型指针）（如上图所示），如果是数组对象还包括一个额外的Array length数组长度部分（这里我没给出图片）。 在32位虚拟机中，一字宽等于四字节，即32bit。 HotSpot虚拟机的对象头(Object Header)包括两部分信息，第一部分用于存储对象自身的运行时数据， 如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等等，这部分数据的长度在32位和64位的虚拟机（暂不考虑开启压缩指针的场景）中分别为32个和64个Bits，官方称它为“Mark Word”（标记字段）。 对象需要存储的运行时数据很多，其实已经超出了32、64位Bitmap结构所能记录的限度，但是对象头信息是与对象自身定义的数据无关的额 外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。例如在32位的HotSpot虚拟机 中对象未被锁定的状态下，Mark Word的32个Bits空间中的25Bits用于存储对象哈希码（HashCode），4Bits用于存储对象分代年龄，2Bits用于存储锁标志 位，1Bit固定为0，在其他状态（轻量级锁定、重量级锁定、GC标记、可偏向）下对象的存储内容如下表所示： 注意偏向锁、轻量级锁、重量级锁等都是jdk 1.6以后引入的。 ","date":"2020-02-25","objectID":"/java_synchronized_underlying/:2:0","tags":["synchronized","java"],"title":"Java之synchronized的实现原理","uri":"/java_synchronized_underlying/"},{"categories":["Java"],"content":"monitor对象 轻量级锁和偏向锁是Java 6 对 synchronized 锁进行优化后新增加的，稍后我们会简要分析。这里我们主要分析一下重量级锁也就是通常说synchronized的对象锁，锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的）： ObjectMonitor() { _header = NULL; _count = 0; //记录个数 _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; //处于wait状态的线程，会被加入到_WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; //处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; } ObjectMonitor中有两个队列，_WaitSet和_EntryList，用来保存ObjectWaiter对象列表(每个等待锁的线程都会被封装成ObjectWaiter对象)，_owner指向持有ObjectMonitor对象的线程，当多个线程同时访问一段同步代码时，首先会进入 _EntryList 集合，当线程获取到对象的monitor 后进入 _Owner 区域并把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1，若线程调用wait()方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入WaitSet集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。如下图所示： ","date":"2020-02-25","objectID":"/java_synchronized_underlying/:3:0","tags":["synchronized","java"],"title":"Java之synchronized的实现原理","uri":"/java_synchronized_underlying/"},{"categories":["Java"],"content":"锁优化 从上一节看出，synchronized的实现依赖于与某个对象向关联的monitor（监视器）实现，而monitor是基于底层操作系统的Mutex Lock实现的，而基于Mutex Lock实现的同步必须经历从用户态到核心态的转换，这个开销特别大，成本非常高。所以频繁的通过Synchronized实现同步会严重影响到程序效率，而这种依赖于Mutex Lock实现的锁机制也被称为“重量级锁”，为了减少重量级锁带来的性能开销，JDK对synchronized进行了种种优化。 Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。 ","date":"2020-02-25","objectID":"/java_synchronized_underlying/:4:0","tags":["synchronized","java"],"title":"Java之synchronized的实现原理","uri":"/java_synchronized_underlying/"},{"categories":["Java"],"content":"偏向锁 Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。 获取锁： 检测Mark Word是否为可偏向状态，即是否为偏向锁1，锁标识位为01； 若为可偏向状态，则测试线程ID是否为当前线程ID，如果是，则执行步骤（5），否则执行步骤（3）； 如果线程ID不为当前线程ID，则通过CAS操作竞争锁，竞争成功，则将Mark Word的线程ID替换为当前线程ID，否则执行线程（4）； 通过CAS竞争锁失败，证明当前存在多线程竞争情况，当到达全局安全点，获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码块； 执行同步代码块 释放锁： 偏向锁的释放采用了一种只有竞争才会释放锁的机制，线程是不会主动去释放偏向锁，需要等待其他线程来竞争。偏向锁的撤销需要等待全局安全点（这个时间点是上没有正在执行的代码）。其步骤如下： 暂停拥有偏向锁的线程，判断锁对象石是否还处于被锁定状态； 撤销偏向苏，恢复到无锁状态（01）或者轻量级锁的状态； ","date":"2020-02-25","objectID":"/java_synchronized_underlying/:4:1","tags":["synchronized","java"],"title":"Java之synchronized的实现原理","uri":"/java_synchronized_underlying/"},{"categories":["Java"],"content":"轻量级锁 引入轻量级锁的主要目的是在多没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。 当关闭偏向锁功能或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁，则会尝试获取轻量级锁，其步骤如下： 获取锁： 判断当前对象是否处于无锁状态（hashcode、0、01），若是，则JVM首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝（官方把这份拷贝加了一个Displaced前缀，即Displaced Mark Word）；否则执行步骤（3）； JVM利用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指正，如果成功表示竞争到锁，则将锁标志位变成00（表示此对象处于轻量级锁状态），执行同步操作；如果失败则执行步骤（3）； 判断当前对象的Mark Word是否指向当前线程的栈帧，如果是则表示当前线程已经持有当前对象的锁，则直接执行同步代码块；否则只能说明该锁对象已经被其他线程抢占了，这时轻量级锁需要膨胀为重量级锁，锁标志位变成10，后面等待的线程将会进入阻塞状态； 释放锁： 轻量级锁的释放也是通过CAS操作来进行的，主要步骤如下： 取出在获取轻量级锁保存在Displaced Mark Word中的数据； 用CAS操作将取出的数据替换当前对象的Mark Word中，如果成功，则说明释放锁成功，否则执行（3）； 如果CAS操作替换失败，说明有其他线程尝试获取该锁，则需要在释放锁的同时需要唤醒被挂起的线程。 轻量级锁状态时，位置被锁指针占用，那hashCode等信息要存到哪里？这里的问题就比较简单了，因为有拷贝的mark word，所以Displaced Mark Word中存在所需要的信息。 ","date":"2020-02-25","objectID":"/java_synchronized_underlying/:4:2","tags":["synchronized","java"],"title":"Java之synchronized的实现原理","uri":"/java_synchronized_underlying/"},{"categories":["Java"],"content":"重量级锁 重量级锁通过对象内部的监视器（monitor）实现，其中monitor的本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的切换，切换成本非常高。 ","date":"2020-02-25","objectID":"/java_synchronized_underlying/:4:3","tags":["synchronized","java"],"title":"Java之synchronized的实现原理","uri":"/java_synchronized_underlying/"},{"categories":["Java"],"content":"自旋锁 轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。自旋是把双刃剑，如果旋的时间过长会影响整体性能，时间过短又达不到延迟阻塞的目的。显然，自旋的周期选择显得非常重要，但这与操作系统、硬件体系、系统的负载等诸多场景相关，很难选择，如果选择不当，不但性能得不到提高，可能还会下降。 ","date":"2020-02-25","objectID":"/java_synchronized_underlying/:4:4","tags":["synchronized","java"],"title":"Java之synchronized的实现原理","uri":"/java_synchronized_underlying/"},{"categories":["Java"],"content":"适应自旋锁 JDK 1.6引入了更加聪明的自旋锁，即自适应自旋锁。所谓自适应就意味着自旋的次数不再是固定的，它是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。它怎么做呢？线程如果自旋成功了，那么下次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。反之，如果对于某个锁，很少有自旋能够成功的，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。 ","date":"2020-02-25","objectID":"/java_synchronized_underlying/:4:5","tags":["synchronized","java"],"title":"Java之synchronized的实现原理","uri":"/java_synchronized_underlying/"},{"categories":["Java"],"content":"锁消除 为了保证数据的完整性，我们在进行操作时需要对这部分操作进行同步控制，但是在有些情况下，JVM检测到不可能存在共享数据竞争，这是JVM会对这些同步锁进行锁消除。锁消除的依据是逃逸分析的数据支持。 如果不存在竞争，为什么还需要加锁呢？所以锁消除可以节省毫无意义的请求锁的时间。变量是否逃逸，对于虚拟机来说需要使用数据流分析来确定，但是对于我们程序员来说这还不清楚么？我们会在明明知道不存在数据竞争的代码块前加上同步吗？但是有时候程序并不是我们所想的那样？我们虽然没有显示使用锁，但是我们在使用一些JDK的内置API时，如StringBuffer、Vector、HashTable等，这个时候会存在隐形的加锁操作。比如StringBuffer的append()方法，Vector的add()方法。 ","date":"2020-02-25","objectID":"/java_synchronized_underlying/:4:6","tags":["synchronized","java"],"title":"Java之synchronized的实现原理","uri":"/java_synchronized_underlying/"},{"categories":["Java"],"content":"锁的膨胀流程 在前面偏向锁和轻量级锁的小节中已经大概了解的锁的膨胀流程： 偏向锁-\u003e轻量级锁-\u003e重量级锁 偏向所锁，轻量级锁都是乐观锁，重量级锁是悲观锁。 一个对象刚开始实例化的时候，没有任何线程来访问它的时候。它是可偏向的，意味着，它现在认为只可能有一个线程来访问它，所以当第一个线程来访问它的时候，它会偏向这个线程，此时，对象持有偏向锁。 偏向第一个线程，这个线程在修改对象头成为偏向锁的时候使用CAS操作，并将对象头中的ThreadID改成自己的ID，之后再次访问这个对象时，只需要对比ID，不需要再使用CAS在进行操作。 一旦有第二个线程访问这个对象，因为偏向锁不会主动释放，所以第二个线程可以看到对象是偏向状态，这时表明在这个对象上已经存在竞争了，检查原来持有该对象锁的线程是否依然存活，如果挂了，则可以将对象变为无锁状态，然后重新偏向新的线程，如果原来的线程依然存活，则马上执行那个线程的操作栈，检查该对象的使用情况，如果仍然需要持有偏向锁，则偏向锁升级为轻量级锁，（偏向锁就是这个时候升级为轻量级锁的）。如果不存在使用了，则可以将对象回复成无锁状态，然后重新偏向。 轻量级锁认为竞争存在，但是竞争的程度很轻，一般两个线程对于同一个锁的操作都会错开，或者说稍微等待一下（自旋），另一个线程就会释放锁。 但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁膨胀为重量级锁，重量级锁使除了拥有锁的线程以外的线程都阻塞，防止CPU空转。 参考： 【死磕Java并发】—–深入分析synchronized的实现原理 java对象在内存中的结构（HotSpot虚拟机） Difference between lock and monitor – Java Concurrency ","date":"2020-02-25","objectID":"/java_synchronized_underlying/:4:7","tags":["synchronized","java"],"title":"Java之synchronized的实现原理","uri":"/java_synchronized_underlying/"},{"categories":["Java",""],"content":" 其实，无论是Mybatis、Hibernate都是ORM的一种实现框架，都是对JDBC的一种封装。 之前我写过一篇Spring Boot集成MyBatis操作MySQL，不过在这里让我们脱离Spring（不过很多代码是一样的,Dao类，Model类，数据库配置），就单独回顾下MyBatis的使用，来了解下MyBatis的使用流程。 ","date":"2020-02-21","objectID":"/mybatis_getstart_lookback/:0:0","tags":["MyBatis"],"title":"MyBatis经典入门回顾","uri":"/mybatis_getstart_lookback/"},{"categories":["Java",""],"content":"Mybatis工作流程 通过Reader对象读取Mybatis配置文件 通过SqlSessionFactoryBuilder对象创建SqlSessionFactory对象 获取当前线程的SQLSession 事务默认开启 通过SQLSession读取映射文件中的操作编号，从而读取SQL语句 提交事务 关闭资源 SqlSessionFactory是一个很重要的类，每个基于 MyBatis 的应用都是以一个 SqlSessionFactory 的实例为核心的。SqlSessionFactory 的实例可以通过 SqlSessionFactoryBuilder 获得。而 SqlSessionFactoryBuilder 则可以从 XML 配置文件或一个预先定制的 Configuration 的实例构建出 SqlSessionFactory 的实例。 ","date":"2020-02-21","objectID":"/mybatis_getstart_lookback/:1:0","tags":["MyBatis"],"title":"MyBatis经典入门回顾","uri":"/mybatis_getstart_lookback/"},{"categories":["Java",""],"content":"pom.xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cgroupId\u003ecom.51lucy.test\u003c/groupId\u003e \u003cartifactId\u003emybatis-simple\u003c/artifactId\u003e \u003cversion\u003e1.0\u003c/version\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.mybatis\u003c/groupId\u003e \u003cartifactId\u003emybatis\u003c/artifactId\u003e \u003cversion\u003e3.5.3\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003emysql\u003c/groupId\u003e \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e \u003cversion\u003e5.1.41\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e ","date":"2020-02-21","objectID":"/mybatis_getstart_lookback/:2:0","tags":["MyBatis"],"title":"MyBatis经典入门回顾","uri":"/mybatis_getstart_lookback/"},{"categories":["Java",""],"content":"数据库配置jdbc.properties 在src/main/resources文件夹下创建jdbc.properties文件： jdbc.driverClassName=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/spring_db jdbc.username=root jdbc.password=*********** ","date":"2020-02-21","objectID":"/mybatis_getstart_lookback/:3:0","tags":["MyBatis"],"title":"MyBatis经典入门回顾","uri":"/mybatis_getstart_lookback/"},{"categories":["Java",""],"content":"mybatis配置文件 在src/main/resources文件夹下创建mybatis-config.xml文件： \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"\u003e \u003cconfiguration\u003e \u003cproperties resource=\"jdbc.properties\"/\u003e \u003cenvironments default=\"development\"\u003e \u003c!-- 设置一个默认的连接环境信息 --\u003e \u003cenvironment id=\"development\"\u003e \u003ctransactionManager type=\"JDBC\"/\u003e \u003cdataSource type=\"POOLED\"\u003e \u003cproperty name=\"driver\" value=\"${jdbc.driverClassName}\"/\u003e \u003cproperty name=\"url\" value=\"${jdbc.url}\"/\u003e \u003cproperty name=\"username\" value=\"${jdbc.username}\"/\u003e \u003cproperty name=\"password\" value=\"${jdbc.password}\"/\u003e \u003c/dataSource\u003e \u003c/environment\u003e \u003c/environments\u003e \u003cmappers\u003e \u003cmapper resource=\"mappers/User.xml\"/\u003e \u003c/mappers\u003e \u003c/configuration\u003e ","date":"2020-02-21","objectID":"/mybatis_getstart_lookback/:4:0","tags":["MyBatis"],"title":"MyBatis经典入门回顾","uri":"/mybatis_getstart_lookback/"},{"categories":["Java",""],"content":"添加Dao接口 UserDao接口（其实就是Mapper接口） package com.lucy.test.dao; import com.lucy.test.model.User; public interface UserDao { User findByName(String name); int insertUser(User user); } ","date":"2020-02-21","objectID":"/mybatis_getstart_lookback/:5:0","tags":["MyBatis"],"title":"MyBatis经典入门回顾","uri":"/mybatis_getstart_lookback/"},{"categories":["Java",""],"content":"xml映射文件 在src/main/resources/mappers文件夹下创建User.xml文件： \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"\u003e \u003c!--namespace要写对--\u003e \u003cmapper namespace=\"com.lucy.test.dao.UserDao\"\u003e \u003cselect id=\"findByName\" parameterType=\"java.lang.String\" resultType=\"com.lucy.test.model.User\"\u003e select uid, name, age, address, created_time from user where name = #{name} \u003c/select\u003e \u003cinsert id=\"insertUser\" parameterType=\"com.lucy.test.model.User\"\u003e insert into user(name, age, address, created_time) VALUES ( #{name}, #{age}, #{address}, #{createdDatetime} ) \u003c/insert\u003e \u003c/mapper\u003e ","date":"2020-02-21","objectID":"/mybatis_getstart_lookback/:6:0","tags":["MyBatis"],"title":"MyBatis经典入门回顾","uri":"/mybatis_getstart_lookback/"},{"categories":["Java",""],"content":"测试类 让我们写个测试类看看效果： package com.lucy.test; import com.lucy.test.dao.UserDao; import com.lucy.test.model.User; import org.apache.ibatis.io.Resources; import org.apache.ibatis.session.SqlSession; import org.apache.ibatis.session.SqlSessionFactory; import org.apache.ibatis.session.SqlSessionFactoryBuilder; import java.io.IOException; import java.io.InputStream; public class Main { public static void main(String[] args) throws IOException { String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession sqlSession = sqlSessionFactory.openSession(); try { UserDao userMapper = sqlSession.getMapper(UserDao.class); User user = userMapper.findByName(\"meng\"); System.out.println(user.toString()); sqlSession.commit(); } catch (Exception ex) { ex.printStackTrace(); } finally { sqlSession.close(); } } } 参考： MyBatis Tutorial – CRUD Operations and Mapping Relationships – Part 1 ","date":"2020-02-21","objectID":"/mybatis_getstart_lookback/:7:0","tags":["MyBatis"],"title":"MyBatis经典入门回顾","uri":"/mybatis_getstart_lookback/"},{"categories":["C++","Qt"],"content":"本文环境： OS：Ubuntu 18.04.3 LTS Qt版本：5.14.1 Qt Creator版本：4.10.1 ","date":"2020-02-12","objectID":"/qt%E4%B9%8B%E5%B8%83%E5%B1%80%E7%AE%A1%E7%90%86/:0:0","tags":["Qt"],"title":"Qt之布局管理","uri":"/qt%E4%B9%8B%E5%B8%83%E5%B1%80%E7%AE%A1%E7%90%86/"},{"categories":["C++","Qt"],"content":"布局器概览 我们以下图的 Qt 设计师界面来说明布局功能，QtCreator 设计模式的布局功能与 Qt 设计师是一样的。 在设计师左边列表，可以看到 Layouts 栏目里有四个布局器： 直布局器 QVBoxLayout：将内部的控件按照垂直方向排布，一行一个。 ◆ 水平布局器 QHBoxLayout：将内部的控件按照水平方向排布，一列一个。 ◆ 网格布局器 QGridLayout：按照多行、多列的网格排布内部控件，单个控件可以占一个格子或者占据连续多个格子。 ◆ 表单布局器 QFormLayout：Qt 设计师里把这个布局器称为窗体布局器，窗体布局器这个叫法不准。这个布局器就是对应网页设计的表单，通常用于接收用户输入。该布局器就如它的图标一样，就是固定的两列控 件，第一列通常是标签，第二列是输入控件或含有输入控件的布局器。 ◆ Qt 另外还有一个堆栈布局器 QStackedLayout，通常用于容纳多个子窗口布局，每次只显示其中一个。这个布局器隐含在堆栈部件 QStackedWidget 内部，一般直接用 QStackedWidget 就行了，不需要专门设置堆栈布局器。 与布局紧密关联的是两个空白条（或叫弹簧条）：Horizontal Spacer 水平空白条和 Vertical Spacer 垂直空白条，空白条的作用就是填充无用的空隙，如果不希望看到控件拉伸后变丑，就可以塞一个空白条到布局器里面，布局器通常会优先拉伸空白条。两种空白条的类名都是 QSpacerItem，两种空白条只是默认的拉伸方向不一样。 ","date":"2020-02-12","objectID":"/qt%E4%B9%8B%E5%B8%83%E5%B1%80%E7%AE%A1%E7%90%86/:1:0","tags":["Qt"],"title":"Qt之布局管理","uri":"/qt%E4%B9%8B%E5%B8%83%E5%B1%80%E7%AE%A1%E7%90%86/"},{"categories":["C++","Qt"],"content":"QBoxLayout 水平布局器 QHBoxLayout 和垂直布局器 QVBoxLayout 的基类都是 QBoxLayout，只是二者排列方向不同。水平和垂直布局器的主要功能函数都位于基类 QBoxLayout 里面，我们这里专门介绍一下这个基类的功能。 QBoxLayout 构造函数和 setDirection() 都可以指定布局器的方向： QBoxLayout(Direction dir, QWidget * parent = 0) void setDirection(Direction direction) QBoxLayout 布局器的方向 QBoxLayout::​Direction 枚举不仅可以指定水平和垂直，还能指定反方向排列： 枚举常量 数值 描述 QBoxLayout::LeftToRight 0 水平布局，从左到右排列 QBoxLayout::RightToLeft 1 水平布局，从右到左排列 QBoxLayout::TopToBottom 2 垂直布局，从上到下排列 QBoxLayout::BottomToTop 3 垂直布局，从下到上排列 水平布局器 QHBoxLayout 和垂直布局器 QVBoxLayout 默认是其中的两种：QBoxLayout::LeftToRight 和 QBoxLayout::TopToBottom 。 布局器是一定要往里面添加控件才有用，添加控件的函数如下： void addWidget(QWidget * widget, int stretch = 0, Qt::Alignment alignment = 0) void insertWidget(int index, QWidget * widget, int stretch = 0, Qt::Alignment alignment = 0) widget 就是要添加的控件指针，stretch 是伸展因子，伸展因子越大，窗口变大时拉伸越 多，alignment 一般不需要指定，用默认的即可。 第一个 addWidget() 是将控件添加到布局里面的控件列表末尾，第二个 insertWidget() 是将控件插入到布局里控件列表序号为 index 的位置。 下面看个例子，我在垂直布局器中添加了5个Label，它们高度按不同的比例分配 mainwwindow.cpp MainWindow::MainWindow(QWidget *parent) : QMainWindow(parent) , ui(new Ui::MainWindow) { ui-\u003esetupUi(this); QLabel *label1 = new QLabel(\"One\"); QLabel *label2 = new QLabel(\"Two\"); QLabel *label3 = new QLabel(\"Three\"); QLabel *label4 = new QLabel(\"Four\"); QLabel *label5 = new QLabel(\"Five\"); label1-\u003esetStyleSheet(\"background-color: red\"); label2-\u003esetStyleSheet(\"background-color: yellow\"); label3-\u003esetStyleSheet(\"background-color: green\"); label4-\u003esetStyleSheet(\"background-color: black\"); label5-\u003esetStyleSheet(\"background-color: orange\"); QVBoxLayout *layout = new QVBoxLayout; layout-\u003eaddWidget(label1); layout-\u003eaddWidget(label2, 2); layout-\u003eaddWidget(label3, 3); layout-\u003eaddWidget(label4, 4); layout-\u003eaddWidget(label5, 5); auto central = new QWidget; central-\u003esetLayout(layout); this-\u003esetCentralWidget(central); } 最终呈现的效果是： 然后，我再添加一个水品布局器，在里头放入3个label QHBoxLayout *layoutH = new QHBoxLayout; layout-\u003eaddLayout(layoutH, 4); // stretch比例为4 QLabel *label6 = new QLabel(\"Six\"); QLabel *label7 = new QLabel(\"seven\"); QLabel *label8 = new QLabel(\"eight\"); label6-\u003esetStyleSheet(\"background-color: #7B72E9\"); label7-\u003esetStyleSheet(\"background-color: #1B9AF7\"); label8-\u003esetStyleSheet(\"background-color: #FF4351\"); layoutH-\u003eaddWidget(label6); layoutH-\u003eaddWidget(label7); layoutH-\u003eaddWidget(label8); 最终效果为： 参考： 6.2 水平和垂直布局器 ","date":"2020-02-12","objectID":"/qt%E4%B9%8B%E5%B8%83%E5%B1%80%E7%AE%A1%E7%90%86/:2:0","tags":["Qt"],"title":"Qt之布局管理","uri":"/qt%E4%B9%8B%E5%B8%83%E5%B1%80%E7%AE%A1%E7%90%86/"},{"categories":["C++","Qt"],"content":"本文环境： OS：Ubuntu 18.04.3 LTS Qt版本：5.14.1 Qt Creator版本：4.10.1 ","date":"2020-01-18","objectID":"/qt_begin/:0:0","tags":["Qt","Qt Creator"],"title":"Qt之初步尝试","uri":"/qt_begin/"},{"categories":["C++","Qt"],"content":"Qt安装 首先，我们得明白一些概念。 Qt是一个C++库，或者说是开发框架，里面集成了一些库函数，提高开发效率。 Qt Creator是Qt集成开发环境，你可以在这里编写，编译，运行你的程序。所以最开始写Qt只安装Qt Creator这个是不行的，因为还没有相关的Qt库呢，但是新版的Qt Creator（5.9开始）已经集成了Qt了，所以入门就方便很多了。 关于Qt下载，大家可以打开这里的链接，里面有各版本Qt（Qt和Qt Creator的集成包），操作简单，最新版本是5.14。 windows版本只要双击exe就可以安装了，Linux版本需要先添加执行权限然后运行文件 $ chmod +x qt-opensource-linux-x64-5.13.2.run $ ./qt-opensource-linux-x64-5.13.2.run 对于Linux系统，需要安装C/C++编译器，以Ubuntu为例，需要执行： sudo apt-get install -y gcc g++ 在用到WebEngine组件的会遇到问题 error: GL/gl.h: No such file or directory，需要 sudo apt-get install mesa-common-dev Note: Just installing the above-mentioned mesa-common-dev kit is not sufficient for more recent Ubuntu versions. Based on a comment in the Qt forum an additional package needs installation. Execute following command: sudo apt-get install libglu1-mesa-dev -y Tested with Qt5.3.1 and Ubuntu 14.04 and it solved the problem with missing -lGL. 这一步需要注册一个账号，随便注册一个即可。 这一步选择你需要的组件（不清楚的话，就像我这样选择好了） 最后来到Qt Creator的启动界面 ","date":"2020-01-18","objectID":"/qt_begin/:1:0","tags":["Qt","Qt Creator"],"title":"Qt之初步尝试","uri":"/qt_begin/"},{"categories":["C++","Qt"],"content":"配置环境变量 这一步配置的环境变量在打包Qt程序的时候是需要的。 编辑vim ~/.bashrc，加入以下变量 export QTDIR=/home/salamander/Qt5.14.1/5.14.1/gcc_64 #这个路径依据你安装的Qt路径定 export PATH=$QTDIR/bin:$PATH export MANPATH=$QTDIR/man:$MANPATH export LD_LIBRARY_PATH=$QTDIR/lib:$LD_LIBRARY_PATH 但是在你执行qmake命令的时候，你会发现错误： qmake: could not exec '/usr/lib/x86_64-linux-gnu/qt4/bin/qmake': no such file or directory 我们发现qmake默认指向了qt4（Ubuntu 18默认装了qt4），其实现在qt官方推荐使用qtchooser来管理多个qt版本。 ","date":"2020-01-18","objectID":"/qt_begin/:2:0","tags":["Qt","Qt Creator"],"title":"Qt之初步尝试","uri":"/qt_begin/"},{"categories":["C++","Qt"],"content":"什么是qtchooser qtchooser其实和jdk版本管理软件一样,是一个qt版本管理软件.用于设置安装多个qt的系统中默认使用的qt版本.我们知道环境变量有一个缺陷:一次只支持一个版本的qt,有的应用可能只兼容低版本qt,这样又要配置环境变量非常麻烦.使用qtchooser方便快速切换qt版本而又不用每次重新配置环境变量 首先，我们导入自己安装的qt sudo qtchooser -install 5.14.1 /home/salamander/Qt5.14.1/5.14.1/gcc_64/bin/qmake 注意目录一定要精确到qmake这个程序,然后用qtchooser -l查看当前系统所有的qt版本,得到如下输出: 4 5.14.1 5 default qt4-x86_64-linux-gnu qt4 qt5-x86_64-linux-gnu qt5 可以看到我们自己新安装并命名的5.14.1已经导入了,接下来就是设定默认qt版本了,按照qtchooser使用提示,可以添加一个名为QT_SELECT的环境变量,来选择默认qt版本: export QT_SELECT=5.14.1 可以看出这个环境变量后面的值跟的是系统已安装的qt的名称,这些名称可以用qtchooser -l查看. 执行qmake -v，发现版本已经是我们自己安装的了： $ qmake -v QMake version 3.1 Using Qt version 5.14.1 in /home/salamander/Qt5.14.1/5.14.1/gcc_64/lib 每次export这个QT_SELECT变量有点麻烦，你可以编辑.bashrc来自动切换qt版本。 ","date":"2020-01-18","objectID":"/qt_begin/:2:1","tags":["Qt","Qt Creator"],"title":"Qt之初步尝试","uri":"/qt_begin/"},{"categories":["C++","Qt"],"content":"写个hello world 点击文件菜单，然后新建项目，选择Qt Console Application。 编辑main.cpp文件，代码为： #include \u003cQCoreApplication\u003e #include \u003cQDebug\u003e int main(int argc, char *argv[]) { QCoreApplication a(argc, argv); qDebug() \u003c\u003c \"hello world\"; return a.exec(); } 点击左下角的Run按钮，就可以启动程序。 ","date":"2020-01-18","objectID":"/qt_begin/:3:0","tags":["Qt","Qt Creator"],"title":"Qt之初步尝试","uri":"/qt_begin/"},{"categories":["C++","Qt"],"content":"信号和槽 信号和槽机制是 QT 的核心机制，要精通 QT 编程就必须对信号和槽有所了解。不同于传统的函数回调方式。信号和插槽是 Qt 中非常有特色的地方，可以说是Qt编程区别于其它编程的标志。信号和槽是一种高级接口，应用于对象之间的通信，它是 Qt 的核心特性。 ","date":"2020-01-18","objectID":"/qt_begin/:4:0","tags":["Qt","Qt Creator"],"title":"Qt之初步尝试","uri":"/qt_begin/"},{"categories":["C++","Qt"],"content":"信号（signal） 当一个对象中某些可能会有别的对象关心的状态被修改时，将会发出信号。只有定义了信号的类及其子类可以发出信号。 当一个信号被发出时，连接到这个信号的槽立即被调用，就像一个普通的函数调用。当这种情况发生时，信号槽机制独立于任何 GUI 事件循环。emit 语句之后的代码将在所有的槽返回之后被执行。这种情况与使用连接队列略有不同：使用连接队列的时候，emit 语句之后的代码将立即被执行，而槽在之后执行。 如果一个信号连接了多个槽，当信号发出时，这些槽将以连接的顺序一个接一个地被执行（顺序不确定）。 ","date":"2020-01-18","objectID":"/qt_begin/:4:1","tags":["Qt","Qt Creator"],"title":"Qt之初步尝试","uri":"/qt_begin/"},{"categories":["C++","Qt"],"content":"槽（slot） 当连接到的信号发出时，槽就会被调用。槽是普通的 C++ 函数，能够被正常的调用。它们的唯一特点是能够与信号连接。 既然信号就是普通的成员函数，当它们像普通函数一样调用的时候，遵循标准 C++ 的规则。但是，作为槽，它们又能够通过信号槽的连接被任何组件调用，不论这个组件的访问级别。这意味着任意类的实例发出的信号，都可以使得不相关的类的私有槽被调用。 你也能把槽定义成虚的，这一点在实际应用中非常有用。 ","date":"2020-01-18","objectID":"/qt_begin/:4:2","tags":["Qt","Qt Creator"],"title":"Qt之初步尝试","uri":"/qt_begin/"},{"categories":["C++","Qt"],"content":"信号与槽的关联 通过调用 QObject 对象的 connect 函数来将某个对象的信号与另外一个对象的槽函数相关联，这样当发射者发射信号时，接收者的槽函数将被调用。 connect()语句的原型类似于： connect(sender, SIGNAL(signal), receiver, SLOT(slot)); 这里，sender 和 receiver 都是 QObject 类型的，singal 和 slot 都是没有参数名称的函数签名。SINGAL()和SLOT()宏用于把参数转换成字符串。 一个信号可以和多个槽相连： connect(slider, SIGNAL(valueChanged(int)), spinBox, SLOT(setValue(int))); connect(slider, SIGNAL(valueChanged(int)), this, SLOT(updateStatusBarIndicator(int))); ","date":"2020-01-18","objectID":"/qt_begin/:4:3","tags":["Qt","Qt Creator"],"title":"Qt之初步尝试","uri":"/qt_begin/"},{"categories":["C++","Qt"],"content":"Gui简单例子 这个例子中，我们用了上面槽的知识，我们在界面上放了一个button，然后添加了slot获得了button的click事件发送者的objectName。 界面 mainwindow.h #ifndef MAINWINDOW_H #define MAINWINDOW_H #include \u003cQMainWindow\u003e QT_BEGIN_NAMESPACE namespace Ui { class MainWindow; } QT_END_NAMESPACE class MainWindow : public QMainWindow { Q_OBJECT public: MainWindow(QWidget *parent = nullptr); ~MainWindow(); private: Ui::MainWindow *ui; private slots: void handleButton(); // 处理函数 }; #endif // MAINWINDOW_H mainwindow.cpp #include \"mainwindow.h\" #include \"ui_mainwindow.h\" #include \u003cQDebug\u003e MainWindow::MainWindow(QWidget *parent) : QMainWindow(parent) , ui(new Ui::MainWindow) { ui-\u003esetupUi(this); connect(ui-\u003emyPushButton, SIGNAL(clicked()), this, SLOT(handleButton())); } void MainWindow::handleButton() { QObject *senderObj = sender(); // This will give Sender object QString senderObjName = senderObj-\u003eobjectName(); qDebug() \u003c\u003c senderObjName; // get myPushButton } MainWindow::~MainWindow() { delete ui; } ","date":"2020-01-18","objectID":"/qt_begin/:5:0","tags":["Qt","Qt Creator"],"title":"Qt之初步尝试","uri":"/qt_begin/"},{"categories":["C++","Qt"],"content":"参考 油管上VoidRealms的Qt视频 Install Qt5 On Ubuntu Ubuntu 18.04安装QtCreator+配置qt环境+qtchooser ","date":"2020-01-18","objectID":"/qt_begin/:6:0","tags":["Qt","Qt Creator"],"title":"Qt之初步尝试","uri":"/qt_begin/"},{"categories":["linux"],"content":"Veth Veth缩写是Virtual ETHernet。veth设备是在linux内核中是成对出现（所以也叫veth-pair），两个设备彼此相连，一个设备从协议栈读取数据后，会将数据发送到另一个设备上去。这个设备其实是专门为container所建的，作用就是把一个network namespace发出的数据包转发到另一个namespace（通常就是宿主机）。 ","date":"2020-01-14","objectID":"/linu_veth_and_bridge/:1:0","tags":["linux","network"],"title":"Linux网络虚拟化技术之Veth和Bridge","uri":"/linu_veth_and_bridge/"},{"categories":["linux"],"content":"添加Veth设备 $ sudo ip netns add net0 $ sudo ip netns add net1 $ sudo ip link add veth0 netns net0 type veth peer name veth1 netns net1 #添加 veth 设备对 上面的命令将创建两个命名空间net0和net1，以及一对veth设备，并将veth1分配给命名空间net0，将veth2分配给命名空间net1。这两个名称空间与此VETH对相连。分配一对IP地址，你就可以ping通两者之间的通讯。 $ ip netns ls # 查看创建的network namespace net1 net0 $ sudo ip netns exec net0 ip addr # 查看net0下的网络设备 1: lo: \u003cLOOPBACK\u003e mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: veth0@if2: \u003cBROADCAST,MULTICAST\u003e mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether d6:6e:4f:fb:6b:76 brd ff:ff:ff:ff:ff:ff link-netnsid 0 $ sudo ip netns exec net1 ip addr 1: lo: \u003cLOOPBACK\u003e mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: veth1@if2: \u003cBROADCAST,MULTICAST\u003e mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether 92:05:82:e6:da:73 brd ff:ff:ff:ff:ff:ff link-netnsid 0 我们给这对 veth pair 配置上 ip 地址，并启用它们以及 lo 接口: sudo ip netns exec net0 ip link set veth0 up sudo ip netns exec net0 ip addr add 10.0.1.1/24 dev veth0 sudo ip netns exec net0 ip link set lo up sudo ip netns exec net0 ip route 10.0.1.0/24 dev veth0 proto kernel scope link src 10.0.1.1 linkdown sudo ip netns exec net1 ip link set veth1 up sudo ip netns exec net1 ip addr add 10.0.1.2/24 dev veth1 sudo ip netns exec net1 ip link set lo up sudo ip netns exec net1 ip route 10.0.1.0/24 dev veth1 proto kernel scope link src 10.0.1.2 可以看到，在每个 namespace 中，在配置了 ip 之后，还自动生成了对应的 路由表信息，网络 10.0.1.0/24 数据报文都会通过 vethpair 进行传输。下面使用 ping 命令 可以验证它们的连通性，并在 veth0 和 veth1 上抓包： sudo ip netns exec net0 ping -c 3 10.0.1.2 ","date":"2020-01-14","objectID":"/linu_veth_and_bridge/:1:1","tags":["linux","network"],"title":"Linux网络虚拟化技术之Veth和Bridge","uri":"/linu_veth_and_bridge/"},{"categories":["linux"],"content":"Bridge Bridge（桥）是 Linux 上用来做 TCP/IP 二层协议交换的设备，与现实世界中的交换机功能相似。Bridge 设备实例可以和 Linux 上其他网络设备实例连接，既 attach 一个从设备，类似于在现实世界中的交换机和一个用户终端之间连接一根网线。当有数据到达时，Bridge 会根据报文中的 MAC 信息进行广播、转发、丢弃处理。 使用Bridge前，需要安装bridge-utils包 sudo apt install bridge-utils ","date":"2020-01-14","objectID":"/linu_veth_and_bridge/:2:0","tags":["linux","network"],"title":"Linux网络虚拟化技术之Veth和Bridge","uri":"/linu_veth_and_bridge/"},{"categories":["linux"],"content":"查看bridge $ brctl show bridge name bridge id STP enabled interfaces br-1f7059361887 8000.0242740c4703 no veth35716a0 vethc51a0aa vethd17adab br-4646ac4e576a 8000.02421afdd01b no br-4b05476c9f71 8000.024240053946 no br-5282ac3290df 8000.0242ad5bae1e no br-638972aaac40 8000.024278b6d203 no br-67973b91b458 8000.024279f6c039 no br-96dbd98373e7 8000.0242f23b4758 no veth13b0e48 veth3af358a veth52b951a veth5adc514 veth6e141f8 veth6fcb89b veth710d968 vethc9477cd vethcf35aff docker0 8000.0242fee4c327 no 上面这个是docker0的是Docker给你创建的bridge（如果你设备上装有docker的话 就可以看到）。 ","date":"2020-01-14","objectID":"/linu_veth_and_bridge/:2:1","tags":["linux","network"],"title":"Linux网络虚拟化技术之Veth和Bridge","uri":"/linu_veth_and_bridge/"},{"categories":["linux"],"content":"创建一个bridge brctl addbr br66 上面命令创建一个名为br66的桥。 接下来我们可以把已有的网络设备绑定到这个桥上，在这之前可以看看我们有有哪些网卡接口，可以用 ip addr show 假设上面查出来，有eth0和eth1两个网卡接口，下面我们把他们用命令绑定到一起 brctl addif br0 eth0 eth1 # eth0和eth1的顺序不重要，不影响结果 再来查看绑定关系 $ brctl show bridge name bridge id STP enabled interfaces br66 8000.001ec952d26b yes eth0 eth1 就是说eth0和eth1绑定到了br0这个桥上了。 ","date":"2020-01-14","objectID":"/linu_veth_and_bridge/:2:2","tags":["linux","network"],"title":"Linux网络虚拟化技术之Veth和Bridge","uri":"/linu_veth_and_bridge/"},{"categories":["linux"],"content":"参考文章 Linux 上的基础网络设备详解 ","date":"2020-01-14","objectID":"/linu_veth_and_bridge/:3:0","tags":["linux","network"],"title":"Linux网络虚拟化技术之Veth和Bridge","uri":"/linu_veth_and_bridge/"},{"categories":["linux"],"content":"我们都知道，Linux实际是通过网络设备去操作和使用网卡的，系统安装了一个网卡之后会为其生成一个网络设备实例，比如eth0（或者叫enp7s0，不同发行版默认网卡命名规则不同）。随着网络虚拟化技术的发展，Linux支持创建出虚拟化的设备，可以通过虚拟化设备的组合实现多种多样的功能和网络拓扑。 常见的虚拟化设备有tun/tap、Veth、Bridge、802.1q VLAN device。 本文环境： OS：Ubuntu 18.04.3 LTS 先回顾一下经典的OSI七层网络模型： ┌───────┐ │　应用层　│←第七层 ├───────┤ │　表示层　│ ├───────┤ │　会话层　│ ├───────┤ │　传输层　│ ├───────┤ │　网络层　│ ├───────┤ │数据链路层│ ├───────┤ │　物理层　│←第一层 └───────┘ OSI七层参考模型 ","date":"2020-01-13","objectID":"/tun-tap/:0:0","tags":["network","linux","tun","tap"],"title":"Linux网络虚拟化技术之tun/tap","uri":"/tun-tap/"},{"categories":["linux"],"content":"虚拟设备和物理设备的区别 对于一个网络设备来说，就像一个管道（pipe）一样，有两端，从其中任意一端收到的数据将从另一端发送出去。 比如一个物理网卡eth0，它的两端分别是内核协议栈（通过内核网络设备管理模块间接的通信）和外面的物理网络，从物理网络收到的数据，会转发给内核协议栈，而应用程序从协议栈发过来的数据将会通过物理网络发送出去。 那么对于一个虚拟网络设备呢？首先它也归内核的网络设备管理子系统管理，对于Linux内核网络设备管理模块来说，虚拟设备和物理设备没有区别，都是网络设备，都能配置IP，从网络设备来的数据，都会转发给协议栈，协议栈过来的数据，也会交由网络设备发送出去，至于是怎么发送出去的，发到哪里去，那是设备驱动的事情，跟Linux内核就没关系了，所以说虚拟网络设备的一端也是协议栈，而另一端是什么取决于虚拟网络设备的驱动实现。 ","date":"2020-01-13","objectID":"/tun-tap/:1:0","tags":["network","linux","tun","tap"],"title":"Linux网络虚拟化技术之tun/tap","uri":"/tun-tap/"},{"categories":["linux"],"content":"tun/tap ","date":"2020-01-13","objectID":"/tun-tap/:2:0","tags":["network","linux","tun","tap"],"title":"Linux网络虚拟化技术之tun/tap","uri":"/tun-tap/"},{"categories":["linux"],"content":"tun分析实验 先上图说话： 上图中是tun设备的数据走向。 图中nsfocus_tun0就是tun0，是一个tun/tap虚拟设备，而eno16777736就是eth0。 socket、协议栈（Newwork Protocol Stack）和网络设备（eth0和tun0）部分都在内核层，其实socket是协议栈的一部分，这里分开来的目的是为了看的更直观。 从上图中可以看出它和物理设备eth0的差别，它们的一端虽然都连着协议栈，但另一端不一样，eth0的另一端是物理网络，这个物理网络可能就是一个交换机，而tun0的另一端是一个用户层的程序，协议栈发给tun0的数据包能被这个应用程序读取到，并且应用程序能直接向tun0写数据。 数据流向分析： User Application A通过套接字（socket A）发数据发给使用与eno16777736处于同一个网段ip的应用程序，数据走向为通过socket A发给协议栈，最后通过netdevice子系统中的eno16777736的设备驱动（以太网驱动）发送出去，这个是通过真实的物理网卡发送出去。 User Application B通过套接字（socket B）发送数据给使用与nsfocus_tun0处于同一个网段ip的应用程序，数据走向为通过socket B发送给协议栈，最后通过netdevice子系统中的nsfocus_tun0的设备驱动（tun驱动）发送出去。由于tun设备没有对应真实的物理网卡，所以nsfocus_tun0对端收取数据的是User Application C。User Application C通过读写/dev/tun设备文件进行数据的收发。 其实一般User Application C就是个VPN程序（例如openvpn），它收到数据包之后，做一些跟业务相关的处理，然后构造一个新的数据包，将原来的数据包嵌入在新的数据包中，最后通过socket B将数据包转发出去，这时候新数据包的源地址变成了eth0的地址，而目的IP地址变成了一个其它的地址，比如是10.33.0.1（VPN服务器地址），协议栈根据本地路由，发现这个数据包应该要通过eth0发送出去，于是将数据包交给eth0，最后eth0通过物理网络将数据包发送出去。 从上面的流程中可以看出，数据包选择走哪个网络设备完全由路由表控制，所以如果我们想让某些网络流量走应用程序B的转发流程，就需要配置路由表让这部分数据走tun0。 ","date":"2020-01-13","objectID":"/tun-tap/:2:1","tags":["network","linux","tun","tap"],"title":"Linux网络虚拟化技术之tun/tap","uri":"/tun-tap/"},{"categories":["linux"],"content":"示例程序 为了使用tun/tap设备，用户层程序需要通过系统调用打开/dev/net/tun获得一个读写该设备的文件描述符(FD)，并且调用ioctl()向内核注册一个TUN或TAP类型的虚拟网卡(实例化一个tun/tap设备)，其名称可能是tap7b7ee9a9-c1/vnetXX/tunXX/tap0等。 这里写了一个程序，它收到tun设备的数据包之后，只打印出收到了多少字节的数据包，其它的什么都不做。 #include \u003cnet/if.h\u003e #include \u003csys/ioctl.h\u003e #include \u003csys/stat.h\u003e #include \u003cfcntl.h\u003e #include \u003cstring.h\u003e #include \u003csys/types.h\u003e #include \u003clinux/if_tun.h\u003e #include\u003cstdlib.h\u003e #include\u003cstdio.h\u003e int tun_alloc(int flags) { struct ifreq ifr; int fd, err; char *clonedev = \"/dev/net/tun\"; if ((fd = open(clonedev, O_RDWR)) \u003c 0) { return fd; } memset(\u0026ifr, 0, sizeof(ifr)); ifr.ifr_flags = flags; if ((err = ioctl(fd, TUNSETIFF, (void *) \u0026ifr)) \u003c 0) { close(fd); return err; } printf(\"Open tun/tap device: %s for reading...\\n\", ifr.ifr_name); return fd; } int main() { int tun_fd, nread; char buffer[1500]; /* Flags: IFF_TUN - TUN device (no Ethernet headers) * IFF_TAP - TAP device * IFF_NO_PI - Do not provide packet information */ tun_fd = tun_alloc(IFF_TUN | IFF_NO_PI); if (tun_fd \u003c 0) { perror(\"Allocating interface\"); exit(1); } while (1) { nread = read(tun_fd, buffer, sizeof(buffer)); if (nread \u003c 0) { perror(\"Reading from interface\"); close(tun_fd); exit(1); } printf(\"Read %d bytes from tun/tap device\\n\", nread); } return 0; } 编译、运行程序，会发现多出一个网络设备 $ gcc -o tun tun.c $ sudo ./tun Open tun/tap device: tun0 for reading... $ ip addr ... 8: tun0: \u003cPOINTOPOINT,MULTICAST,NOARP\u003e mtu 1500 qdisc noop state DOWN group default qlen 500 link/none tun0就是新增的网络设备，现在给它配置一个ip，查看接口信息 $ sudo ifconfig tun0 192.168.10.11/24 $ ip addr ... 8: tun0: \u003cPOINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP\u003e mtu 1500 qdisc fq_codel state UNKNOWN group default qlen 500 link/none inet 192.168.10.11/24 scope global tun0 valid_lft forever preferred_lft forever inet6 fe80::dd59:736:65ee:e31a/64 scope link stable-privacy valid_lft forever preferred_lft forever 这时候我们ping地址192.168.10.12 ping 192.168.10.12 -c 2 发现tun程序收到了数据 ","date":"2020-01-13","objectID":"/tun-tap/:2:2","tags":["network","linux","tun","tap"],"title":"Linux网络虚拟化技术之tun/tap","uri":"/tun-tap/"},{"categories":["linux"],"content":"tun和tap区别 两者很类似，只是tun和tap设备他们工作的协议栈层次不同，tap等同于一个以太网设备，用户层程序向tap设备读写的是二层数据包如以太网数据帧，tap设备最常用的就是作为虚拟机网卡。tun则模拟了网络层设备，操作第三层数据包比如IP数据包，openvpn使用TUN设备在C/S间建立VPN隧道。 ","date":"2020-01-13","objectID":"/tun-tap/:2:3","tags":["network","linux","tun","tap"],"title":"Linux网络虚拟化技术之tun/tap","uri":"/tun-tap/"},{"categories":["linux"],"content":"tap分析实验 tap设备最常见的用途就是作为虚拟机网卡。 ","date":"2020-01-13","objectID":"/tun-tap/:2:4","tags":["network","linux","tun","tap"],"title":"Linux网络虚拟化技术之tun/tap","uri":"/tun-tap/"},{"categories":["linux"],"content":"参考文章 Linux虚拟网络设备之tun/tap 云计算底层技术-虚拟网络设备(tun/tap,veth) ","date":"2020-01-13","objectID":"/tun-tap/:3:0","tags":["network","linux","tun","tap"],"title":"Linux网络虚拟化技术之tun/tap","uri":"/tun-tap/"},{"categories":["kubernetes"],"content":" Kubernetes，简称 k8s（k，8 个字符，s——明白了？）或者 “kube”，是一个开源的 Linux 容器自动化运维平台，它消除了容器化应用程序在部署、伸缩时涉及到的许多手动操作。换句话说，你可以将多台主机组合成集群来运行 Linux 容器，而 Kubernetes 可以帮助你简单高效地管理那些集群。构成这些集群的主机还可以跨越公有云、私有云以及混合云。 本文环境： OS：Ubuntu 18.04.3 LTS Vagrant版本：2.2.6 VirtualBox版本：6.0.14 r133895 (Qt5.9.5) Kubernetes版本：1.16.3 ","date":"2019-12-16","objectID":"/vagrant_kubernetes_cluster/:0:0","tags":["kubernetes","vagrant","virtualbox"],"title":"Vagrant本地快速启动Kubernetes集群","uri":"/vagrant_kubernetes_cluster/"},{"categories":["kubernetes"],"content":"安装Vagrant Vagrant是一个基于Ruby的工具，用于创建和部署虚拟化开发环境。它使用Oracle的开源VirtualBox（其实也可以用别的）虚拟化系统，使用Chef创建自动化虚拟环境。 首先到官网下载最新的Vagrant，现在最新的版本是2.2.6，当然你也可以通过命令行下载： wget https://releases.hashicorp.com/vagrant/2.2.6/vagrant_2.2.6_x86_64.deb 验证Vagrant安装成功 $ vagrant --version Vagrant 2.2.6 ","date":"2019-12-16","objectID":"/vagrant_kubernetes_cluster/:1:0","tags":["kubernetes","vagrant","virtualbox"],"title":"Vagrant本地快速启动Kubernetes集群","uri":"/vagrant_kubernetes_cluster/"},{"categories":["kubernetes"],"content":"安装VirtualBox Vagrant是基于虚拟机（VirtualBox，VMware这些）的，所以我们还需要安装VirtualBox。在Vagrant官网可以它适配的VirtualBox版本 Vagrant comes with support out of the box for VirtualBox, a free, cross-platform consumer virtualization product. The VirtualBox provider is compatible with VirtualBox versions 4.0.x, 4.1.x, 4.2.x, 4.3.x, 5.0.x, 5.1.x, 5.2.x, and 6.0.x. 这里我下载6.0版本的VirtualBox，下载地址 wget https://download.virtualbox.org/virtualbox/6.0.14/virtualbox-6.0_6.0.14-133895~Ubuntu~bionic_amd64.deb 注意：不要通过apt-get安装VirtualBox，因为5.1.0版本开始，VirtualBox已经不需要DKMS，apt官方源中VirtualBox比较老，是会带上DKMS的： DKMS isn't required by VirtualBox since 5.1.0. Which means that you downloaded VirtualBox from your Debian \"store\". That's a fork, not supported. You can either ask in their forums for help, or completely remove/uninstall/delete/purge their version and install the official version from the Downloads section of VirtualBox (https://www.virtualbox.org/wiki/Downloads). ","date":"2019-12-16","objectID":"/vagrant_kubernetes_cluster/:2:0","tags":["kubernetes","vagrant","virtualbox"],"title":"Vagrant本地快速启动Kubernetes集群","uri":"/vagrant_kubernetes_cluster/"},{"categories":["kubernetes"],"content":"启动虚拟机 Vagrant跟docker类似，可以提供一致性环境的，它可以编写Vagrantfile（类似docker-compose.yml）来定义虚拟机中安装什么软件，环境和配置，它使用ruby语法。Vagrant也做了box源，类似docker image。 下面给出一个小栗子感受下，这里使用ubuntu/xenial64（Ubuntu 16.06 64位）这个box # -*- mode: ruby -*- # vi: set ft=ruby : # All Vagrant configuration is done below. The \"2\" in Vagrant.configure # configures the configuration version (we support older styles for # backwards compatibility). Please don't change it unless you know what # you're doing. Vagrant.configure(\"2\") do |config| ##### DEFINE VM ##### # The most common configuration options are documented and commented below. # For a complete reference, please see the online documentation at # https://docs.vagrantup.com. # Every Vagrant development environment requires a box. You can search for # boxes at https://app.vagrantup.com/boxes/search. config.vm.box = \"ubuntu/xenial64\" config.vm.hostname = \"ubuntu-01\" config.vm.box_check_update = false # Create a private network, which allows host-only access to the machine # using a specific IP. config.vm.network \"private_network\", ip: \"192.168.10.50\" # Create a public network, which generally matched to bridged network. # Bridged networks make the machine appear as another physical device on # your network. # config.vm.network \"public_network\" # Share an additional folder to the guest VM. The first argument is # the path on the host to the actual folder. The second argument is # the path on the guest to mount the folder. And the optional third # argument is a set of non-required options. # config.vm.synced_folder \"../data\", \"/vagrant_data\" # Provider-specific configuration so you can fine-tune various # backing providers for Vagrant. These expose provider-specific options. # Example for VirtualBox: # # config.vm.provider \"virtualbox\" do |vb| # # Display the VirtualBox GUI when booting the machine # vb.gui = true # # # Customize the amount of memory on the VM: # vb.memory = \"1024\" # end # # View the documentation for the provider you are using for more # information on available options. config.vm.provider \"virtualbox\" do |v| v.name = \"ubuntu-for-fun\" v.customize [\"modifyvm\", :id, \"--memory\", \"2048\"] v.customize [\"modifyvm\", :id, \"--cpus\", \"2\"] end # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine. In the example below, # accessing \"localhost:8080\" will access port 80 on the guest machine. # config.vm.network \"forwarded_port\", guest: 80, host: 8080 end 更多虚拟机的配置可以查看官方文档 在Vagrantfile对应的目录下终端键入：vagrant up，然后Vagrant会帮我们下载ubuntu/xenial64这个box，不过在中国下载速度非常慢，在运行vagrant up时我们可以看到这个box的下载url，你可以用迅雷这些工具直接下载，然后在本地手动添加box $ vagrant up Bringing machine 'default' up with 'virtualbox' provider... ==\u003e default: Box 'ubuntu/xenial64' could not be found. Attempting to find and install... default: Box Provider: virtualbox default: Box Version: \u003e= 0 ==\u003e default: Loading metadata for box 'ubuntu/xenial64' default: URL: https://vagrantcloud.com/ubuntu/xenial64 ==\u003e default: Adding box 'ubuntu/xenial64' (v20191217.0.0) for provider: virtualbox default: Downloading: https://vagrantcloud.com/ubuntu/boxes/xenial64/versions/20191217.0.0/providers/virtualbox.box ==\u003e default: Box download is resuming from prior download progress default: Download redirected to host: cloud-images.ubuntu.com ......... $ cd ~/box-add $ ls metadata.json virtualbox.box $ vagrant box add metadata.json ==\u003e box: Loading metadata for box 'metadata.json' box: URL: file:///home/lucy/vm-add/metadata.json ==\u003e box: Adding box 'ubuntu/xenial64' (v20191217.0.0) for provider: virtualbox box: Downloading: ./virtualbox.box ==\u003e box: Successfully added box 'ubuntu/xenial64' (v20191217.0.0) for 'virtualbox'! $ vagrant box list ubuntu/xenial64 (virtualbox, 20191217.0.0) 下载box的URL是https://vagrantcloud.com/ubuntu/boxes/xenial64/versions/20191217.0.0/providers/virtualbox.box，可以看到下载的版本是20191217.0.0，另外注意一下这里添加box的是使用一个metadata.json文件，使用这样的方式可以定义box版本号，它的内容是： { \"name\": \"ubuntu/xenial64\", \"versions\": [{ \"version\": \"20191217.0.0\"","date":"2019-12-16","objectID":"/vagrant_kubernetes_cluster/:3:0","tags":["kubernetes","vagrant","virtualbox"],"title":"Vagrant本地快速启动Kubernetes集群","uri":"/vagrant_kubernetes_cluster/"},{"categories":["kubernetes"],"content":"启动Kubernetes集群 这里我编写了一个Vagrantfile，一键启动集群： # -*- mode: ruby -*- # vi: set ft=ruby : k8sVersion = '1.16.3' servers = [ { :name =\u003e \"k8s-head\", :type =\u003e \"master\", :box =\u003e \"ubuntu/xenial64\", :box_version =\u003e \"20191217.0.0\", :eth1 =\u003e \"192.168.205.10\", :mem =\u003e \"2048\", :cpu =\u003e \"2\" }, { :name =\u003e \"k8s-node-1\", :type =\u003e \"node\", :box =\u003e \"ubuntu/xenial64\", :box_version =\u003e \"20191217.0.0\", :eth1 =\u003e \"192.168.205.11\", :mem =\u003e \"2048\", :cpu =\u003e \"2\" }, { :name =\u003e \"k8s-node-2\", :type =\u003e \"node\", :box =\u003e \"ubuntu/xenial64\", :box_version =\u003e \"20191217.0.0\", :eth1 =\u003e \"192.168.205.12\", :mem =\u003e \"2048\", :cpu =\u003e \"2\" } ] # This script to install k8s using kubeadm will get executed after a box is provisioned $configureBox = \u003c\u003c-SCRIPT cp /etc/apt/sources.list /etc/apt/sources.list.bak # use Aliyun apt source cat \u003e /etc/apt/sources.list\u003c\u003cEOF # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiverse EOF export DEBIAN_FRONTEND=noninteractive # install docker v17.03 # reason for not using docker provision is that it always installs latest version of the docker, but kubeadm requires 17.03 or older apt-get update # step 1: 安装必要的一些系统工具 apt-get install -y apt-transport-https ca-certificates curl software-properties-common # step 2: 安装GPG证书 curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - add-apt-repository \"deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/$(. /etc/os-release; echo \"$ID\") $(lsb_release -cs) stable\" apt-get update \u0026\u0026 apt-get install -y docker-ce=$(apt-cache madison docker-ce | grep 17.03 | head -1 | awk '{print $3}') # run docker commands as vagrant user (sudo not required) usermod -aG docker vagrant # 修改docker配置 sudo bash -c 'cat \u003e /etc/docker/daemon.json \u003c\u003cEOF { \"exec-opts\": [\"native.cgroupdriver=systemd\"], \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"100m\" }, \"storage-driver\": \"overlay2\" } EOF' sudo systemctl daemon-reload sudo systemctl restart docker # install kubeadm apt-get install -y apt-transport-https curl curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add - # aliyun GPG cat \u003c\u003cEOF \u003e/etc/apt/sources.list.d/kubernetes.list deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main EOF apt-get update apt-get install -y kubelet=#{k8sVersion}-00 kubeadm=#{k8sVersion}-00 kubectl=#{k8sVersion}-00 apt-mark hold kubelet kubeadm kubectl # kubelet requires swap off swapoff -a # keep swap off after reboot sudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab # ip of this box IP_ADDR=`ifconfig enp0s8 | grep Mask | awk '{print $2}'| cut -f2 -d:` # set node-ip sudo sh -c 'echo KUBELET_EXTRA_ARGS= \u003e\u003e /etc/default/kubelet' sudo sed -i \"/^[^#]*KUBELET_EXTRA_ARGS=/c\\KUBELET_EXTRA_ARGS=--node-ip=$IP_ADDR\" /etc/default/kubelet sudo systemctl restart kubelet SCRIPT $configureMaster = \u003c\u003c-SCRIPT export DEBIAN_FRONTEND=noninteractive echo \"This is master\" # ip of this box IP_ADDR=`ifconfig enp0s8 | grep Mask | awk '{print $2}'| cut -f2 -d:` # install k8s master HOST_NAME=$(hostname -s) kubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v#{k8sVersion} \\ --apiserver-advertise-address=$IP_ADDR --apiserver-cert-extra-sans=$IP_ADDR --node-name $HOST_NAME -","date":"2019-12-16","objectID":"/vagrant_kubernetes_cluster/:4:0","tags":["kubernetes","vagrant","virtualbox"],"title":"Vagrant本地快速启动Kubernetes集群","uri":"/vagrant_kubernetes_cluster/"},{"categories":["kubernetes"],"content":"安装官方Dashboard Dashboard是Kubernetes的一个插件，代码单独放在Github的一个仓库里。 按照官方文档，步骤也蛮简单的，首先执行命令： $ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta8/aio/deploy/recommended.yaml 查看一下Dashboard的服务： $ kubectl get pod,deploy,svc -n kubernetes-dashboard NAME READY STATUS RESTARTS AGE pod/dashboard-metrics-scraper-6c554969c6-jqhjx 1/1 Running 0 5h5m pod/kubernetes-dashboard-56c5f95c6b-jrj58 1/1 Running 5 5h5m NAME READY UP-TO-DATE AVAILABLE AGE deployment.extensions/dashboard-metrics-scraper 1/1 1 1 5h5m deployment.extensions/kubernetes-dashboard 1/1 1 1 5h5m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/dashboard-metrics-scraper ClusterIP 10.106.117.224 \u003cnone\u003e 8000/TCP 5h5m service/kubernetes-dashboard ClusterIP 10.98.23.78 \u003cnone\u003e 443/TCP 5h5m # 我们可以看到官方的dashboard帮我们启动了web-ui，并且帮我们启动了一个Metric服务 # 但是dashboard默认使用的https的443端口 # 测试下Dashboard是否正常 $ curl https://10.98.23.78:443 -k -I HTTP/1.1 200 OK Accept-Ranges: bytes Cache-Control: no-store Content-Length: 1262 Content-Type: text/html; charset=utf-8 Last-Modified: Fri, 06 Dec 2019 15:14:02 GMT Date: Tue, 31 Dec 2019 06:35:55 GMT ","date":"2019-12-16","objectID":"/vagrant_kubernetes_cluster/:5:0","tags":["kubernetes","vagrant","virtualbox"],"title":"Vagrant本地快速启动Kubernetes集群","uri":"/vagrant_kubernetes_cluster/"},{"categories":["kubernetes"],"content":"访问Dashboard 访问Dashboard有好几种方式 将kubernetes-dashboard Service暴露 NodePort，使用 http://NodeIP:nodePort 地址访问 dashboard 使用Ingress之类的入口服务进行代理访问 通过 API server 访问 dashboard（https 6443端口和http 8080端口方式） 通过 kubectl proxy 访问 dashboard kubectl proxy 首先这里我们通过kubectl proxy，在k8s-head节点执行： $ kubectl proxy --address='0.0.0.0' --accept-hosts='^*$' 在访问之前，我们需要先创建一个User（一个ServiceAccount，k8s内概念），创建dashboard-adminuser.yaml文件，写入 apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard 执行kubectl apply -f dashboard-adminuser.yaml。 查看用户token（之后在浏览器中输入） $ kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '{print $1}') Name: admin-user-token-mxmtr Namespace: kubernetes-dashboard Labels: \u003cnone\u003e Annotations: kubernetes.io/service-account.name: admin-user kubernetes.io/service-account.uid: 54ddc041-f3af-41fa-a824-6a3e29f0ffa3 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 20 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLW14bXRyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI1NGRkYzA0MS1mM2FmLTQxZmEtYTgyNC02YTNlMjlmMGZmYTMiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.osyqbUwS4pLDEhZ0iL0aAu2f5me82bGTEfXEW8ycS5-JRar4iYcWkqhJZ9FhZV47P0WKLT9UWiLcDw1rVPZbMSHrRnFZcRHmLO35tVBaijjvgsgm2X5856G-HS1VNMgQBSZXiQXr1Lt3Dj9JHHksbiLGg-3wRy7HqD-I8JcR1pHZ_ViOqQ1j6WIbvhfEE3FpTuuSPAcjwVNutXAfur6oJktjYAcwMjWTQ4-yMQ2NRSWM7AcJtjp_7p3WwnHmO6fH6LtrGQzmXwHh5ICmei2LrAE2cxwN251aMVnrPGt00Ff4ij2-yLyI4VZOgAsNuPegctm-GuCOTGNX9Ew-o1si_Q 为了在宿主机上能访问，我们需要用VirutalBox管理界面添加一个端口映射： 好了，现在我们可以访问Dashboard了，浏览内输入http://localhost:31694/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/.，可以看到 NodePort 这个过程比kubectl proxy简单，再安装Dashboard之前，把Service类型改成NodePort即可： $ wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta8/aio/deploy/recommended.yaml #下载yaml $ vim recommended.yaml 找到Service部分，改成NodePort kind: Service apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard spec: type: NodePort # 这个是新增部分 ports: - port: 443 targetPort: 8443 selector: k8s-app: kubernetes-dashboard ``` 查看，Service的随机端口： ``` $ kubectl get pods,svc --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system pod/calico-node-ffn9k 2/2 Running 10 32d kube-system pod/calico-node-fz8v6 2/2 Running 12 32d kube-system pod/calico-node-gvjft 2/2 Running 8 32d kube-system pod/coredns-94d74667-8jp5k 1/1 Running 4 32d kube-system pod/coredns-94d74667-tlph7 1/1 Running 4 32d kube-system pod/etcd-k8s-head 1/1 Running 4 32d kube-system pod/kube-apiserver-k8s-head 1/1 Running 4 32d kube-system pod/kube-controller-manager-k8s-head 1/1 Running 4 32d kube-system pod/kube-proxy-4rsp4 1/1 Running 5 32d kube-system pod/kube-proxy-dccdc 1/1 Running 5 32d kube-system pod/kube-proxy-x82tl 1/1 Running 4 32d kube-system pod/kube-scheduler-k8s-head 1/1 Running 4 32d kubernetes-dashboard pod/dashboard-metrics-scraper-6c554969c6-wmwpt 1/1 Running 0 18m kubernetes-dashboard pod/kubernetes-dashboard-56c5f95c6b-s66g8 1/1 Running 0 18m NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default service/kubernetes ClusterIP 10.96.0.1 \u003cnone\u003e 443/TCP 32d kube-system service/calico-typha ClusterIP 10.104.182.223 \u003cnone\u003e 5473/TCP 32d kube-system service/kube-dns ClusterIP 10.96.0.10 \u003cnone\u003e 53/UDP,53/T","date":"2019-12-16","objectID":"/vagrant_kubernetes_cluster/:5:1","tags":["kubernetes","vagrant","virtualbox"],"title":"Vagrant本地快速启动Kubernetes集群","uri":"/vagrant_kubernetes_cluster/"},{"categories":["算法",""],"content":" 解决最小生成树（Minimum spanning tree）问题的算法，书上介绍了两个：Prime算法和Kruskal算法。 ","date":"2019-12-10","objectID":"/min_spanning_tree/:0:0","tags":["图","最小生成树","数据结构"],"title":"最小生成树回顾","uri":"/min_spanning_tree/"},{"categories":["算法",""],"content":"Prim算法 #include \u003cstdio.h\u003e #include \"graph.h\" extern void DispMat1(MGraph); void Prim(MGraph g, int v) { int lowcost[MAXV], min, n = g.n; int closest[MAXV], i, j, k; for (i = 0; i \u003c n; i++) { lowcost[i] = g.edges[v][i]; closest[i] = v; } for (i = 1; i \u003c n; i++) // 找出n - 1个顶点 { min = INF; for (j = 0; j \u003c n; j++) { if (lowcost[j] != 0 \u0026\u0026 lowcost[j] \u003c min) { min = lowcost[j]; k = j; } } printf(\" 边（%d， %d）权为：%d\\n\", closest[k], k, min); lowcost[k] = 0; // 标记k已经加入U for (j = 0; j \u003c n; j++) { if (g.edges[k][j] != 0 \u0026\u0026 g.edges[k][j] \u003c lowcost[j]) { lowcost[j] = g.edges[k][j]; lowcost[j] = k; } } } } ","date":"2019-12-10","objectID":"/min_spanning_tree/:1:0","tags":["图","最小生成树","数据结构"],"title":"最小生成树回顾","uri":"/min_spanning_tree/"},{"categories":["算法",""],"content":"Kruskal算法 实现克鲁斯卡尔算法的关键是判断选取的边是否与生成树中已保留的边形成回路，这可以通过判断边的两个顶点所在的连通分量来解决（给顶点所在连通分量编号）。 typedef struct { int u; // 边的起始顶点 int v; // 边的终止顶点 int w; // 边的权值 } Edge; void Kruskal(MGraph g, int v) { int i, j, u1, v1, sn1, sn2, k; int vset[MAXV]; // 存放所有边 Edge E[MaxSize]; // e数组的下标从0开始计 k = 0; for (i = 0; i \u003c g.n; i++) // 由g产生的边集E { for (j = 0; j \u003c g.n; j++) { if (g.edges[i][j] != 0 \u0026\u0026 g.edges[i][j] != INF) { E[k].u = i; E[k].v = i; E[k].w = g.edges[i][j]; k++; } } } InsertSort(E, g.e); for (i = 0; i \u003c g.n; i++) { vset[i] = i; } k = 1; // k表示当前构造生成树的第几条边，初值为1 j = 0; // E中边的下标，初值为0 while (k \u003c g.n) { u1 = E[j].u; v1 = E[j].v; sn1 = vset[u1]; sn2 = vset[v1]; if (sn1 != sn2) { printf(\" (%d, %d): %d\\n\", u1, v1, E[j].w); k++; // 生成边数增1 for (i = 0; i \u003c g.n; i++) // 两个集合统一编号 { if (vset[i] == sn2) // 集合编号为sn2的改为sn1 { if (vset[i] == sn2) { vset[i] = sn1; } } } } j++; } } 算法参考： 《数据结构教程（第4版）》（李春葆） ","date":"2019-12-10","objectID":"/min_spanning_tree/:2:0","tags":["图","最小生成树","数据结构"],"title":"最小生成树回顾","uri":"/min_spanning_tree/"},{"categories":["Docker"],"content":" 本文环境： OS：Ubuntu 18.04.3 LTS 内核版本： 5.0.0-36-generic ","date":"2019-11-28","objectID":"/docker-linux-namespace-intro/:0:0","tags":["Docker","Namespace","Cgroup"],"title":"一步步自己做个Docker之Linux Namespace 简介","uri":"/docker-linux-namespace-intro/"},{"categories":["Docker"],"content":"Linux Namespaces Docker的所用的两个关键技术，一个是Namespaces，一个是Cgroups。它俩都不是新技术，Linux内核很早就支持，但是Docker把它们有机地结合起来，加上自己创新，使得现在容器技术非常流行。 Linux Namespaces其实是做到了进程之间全局资源的隔离，譬如，UTS Namespace隔离了Hostname空间。这意味着在新的UTS Namespace中的进程，可以拥有不同于宿主机的主机名。 目前Linux内核主要实现了以下几种不同的资源Namespace： 名称 宏定义 隔离的内容 IPC CLONE_NEWIPC System V IPC, POSIX message queues (since Linux 2.6.19) Network CLONE_NEWNET network device interfaces, IPv4 and IPv6 protocol stacks, IP routing tables, firewall rules, the /proc/net and /sys/class/net directory trees, sockets, etc (since Linux 2.6.24) Mount CLONE_NEWNS Mount points (since Linux 2.4.19) PID CLONE_NEWPID Process IDs (since Linux 2.6.24) User CLONE_NEWUSER User and group IDs (started in Linux 2.6.23 and completed in Linux 3.8) UTS CLONE_NEWUTS Hostname and NIS domain name (since Linux 2.6.19) Cgroup CLONE_NEWCGROUP Cgroup root directory (since Linux 4.6) 要注意一点的是，不是所有的系统资源都能隔离，时间就是个例外，没有对应的Namespace，因此同一台Linux启动的容器时间都是相同的。 ","date":"2019-11-28","objectID":"/docker-linux-namespace-intro/:1:0","tags":["Docker","Namespace","Cgroup"],"title":"一步步自己做个Docker之Linux Namespace 简介","uri":"/docker-linux-namespace-intro/"},{"categories":["Docker"],"content":"尝试一下Namespace lucy@lucy-computer:~$ unshare -h 用法： unshare [选项] [\u003c程序\u003e [\u003c参数\u003e...]] 以某些未与父(进程)共享的名字空间运行某个程序。 选项： -m, --mount[=\u003c文件\u003e] 取消共享 mounts 名字空间 -u, --uts[=\u003c文件\u003e] 取消共享 UTS 名字空间(主机名等) -i, --ipc[=\u003c文件\u003e] 取消共享 System V IPC 名字空间 -n, --net[=\u003cfile\u003e] 取消共享网络名字空间 -p, --pid[=\u003c文件\u003e] 取消共享 pid 名字空间 -U, --user[=\u003c文件\u003e] 取消共享用户名字空间 -C, --cgroup[=\u003c文件\u003e] 取消共享 cgroup 名字空间 -f, --fork 在启动\u003c程序\u003e前 fork --mount-proc[=\u003c目录\u003e] 先挂载 proc 文件系统(连带打开 --mount) -r, --map-root-user 将当前用户映射为 root (连带打开 --user) --propagation slave|shared|private|unchanged 修改 mount 名字空间中的 mount 传播 -s, --setgroups allow|deny 控制用户名字空间中的 setgroups 系统调用 -h, --help display this help -V, --version display version unshare命令可以让你在新的名称空间集中启动一个新的程序（unshared本身的含义就是不和父进程共享）。 下面的例子使用了UTS namespace，可以看到在新的/bin/sh进程中修改hostname，并没有影响宿主机： $ sudo su # become root user $ hostname # check current hostname lucy-computer $ unshare -u /bin/sh # create a shell in new UTS namespace $ hostname my-new-hostname # set hostname $ hostname # confirm new hostname my-new-hostname $ exit # exit new UTS namespace $ hostname # confirm original hostname unchanged lucy-computer ","date":"2019-11-28","objectID":"/docker-linux-namespace-intro/:1:1","tags":["Docker","Namespace","Cgroup"],"title":"一步步自己做个Docker之Linux Namespace 简介","uri":"/docker-linux-namespace-intro/"},{"categories":["Docker"],"content":"三个系统调用 unshare命令很棒，但是当我们想要对程序中的命名空间进行更细粒度的控制时，那该怎么办呢？ Linux 内核提供的功能都会提供系统调用接口供应用程序使用，Namespace也不例外。和Namespace相关的系统调用主要有三个： clone setns unshare 注意：这些系统调用都是 linux 内核实现的，不能直接适用于其他操作系统。 查看一下它们对应的C语言函数原型： clone：创建新进程并设置它的Namespace clone类似于fork系统调用，可以创建一个新的进程，不同的是你可以指定要子进程要执行的函数以及通过参数控制子进程的运行环境。 实际上，clone() 是在 C 语言库中定义的一个封装(wrapper)函数，它负责建立新进程的堆栈并且调用对编程者隐藏的 clone() 系统调用。Clone() 其实是 linux 系统调用 fork() 的一种更通用的实现方式，它可以通过 flags 来控制使用多少功能。 #define _GNU_SOURCE #include \u003csched.h\u003e int clone(int (*fn)(void *), void *child_stack, int flags, void *arg); fn：指定一个由新进程执行的函数。当这个函数返回时，子进程终止。该函数返回一个整数，表示子进程的退出代码。 child_stack：传入子进程使用的栈空间，也就是把用户态堆栈指针赋给子进程的 esp 寄存器。调用进程(指调用 clone() 的进程)应该总是为子进程分配新的堆栈。 flags：表示使用哪些 CLONE_ 开头的标志位，与 namespace 相关的有CLONE_NEWIPC、CLONE_NEWNET、CLONE_NEWNS、CLONE_NEWPID、CLONE_NEWUSER、CLONE_NEWUTS 和 CLONE_NEWCGROUP，如果要同时隔离多个 namespace，可以使用 | (按位或)组合这些参数。 arg：指向传递给 fn() 函数的参数。 setns：让进程加入已经存在Namespace setns 能够把某个进程加入到给定的 namespace，它的定义是这样的： #define _GNU_SOURCE #include \u003csched.h\u003e int setns(int fd, int nstype); 和clone()函数一样，C 语言库中的setns()函数也是对setns系统调用的封装。 fd：表示要加入 namespace 的文件描述符。它是一个指向 /proc/[pid]/ns 目录中文件的文件描述符，可以通过直接打开该目录下的链接文件或者打开一个挂载了该目录下链接文件的文件得到。 nstype：参数 nstype 让调用者可以检查 fd 指向的 namespace 类型是否符合实际要求。若把该参数设置为 0 表示不检查。 unshare：让进程加入新的Namespace #define _GNU_SOURCE #include \u003csched.h\u003e int unshare(int flags); unshare()函数比较简单，只有一个参数flags，它的含义和clone()的flags相同。unshare和 setns 的区别是，setns 只能让进程加入到已经存在的namespace中，而unshare则让进程离开当前的namespace，加入到新建的namespace中。 unshare()和clone()的区别在于：unshare()是把当前进程进入到新的namespace；clone()是创建新的进程，然后让新创建的进程（子进程）加入到新的namespace。 ","date":"2019-11-28","objectID":"/docker-linux-namespace-intro/:1:2","tags":["Docker","Namespace","Cgroup"],"title":"一步步自己做个Docker之Linux Namespace 简介","uri":"/docker-linux-namespace-intro/"},{"categories":["Docker"],"content":"C程序中使用clone系统调用 我们先来看看 clone 一个简单的使用例子：创建一个新的进程，并执行 /bin/bash，这样就可以接受命令，方便我们查看新进程的信息。 #define _GNU_SOURCE #include \u003csched.h\u003e #include \u003csys/wait.h\u003e #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e #include \u003cstring.h\u003e // 设置子进程要使用的栈空间 #define STACK_SIZE (1024*1024) static char container_stack[STACK_SIZE]; #define errExit(code, msg); {if(code == -1){perror(msg); exit(-1);} } char* const container_args[] = { \"/bin/bash\", NULL }; static int container_func(void *arg) { pid_t pid = getpid(); printf(\"Container[%d] - inside the container!\\n\", pid); // 用一个新的bash来替换掉当前子进程， // 这样我们就能通过 bash 查看当前子进程的情况. // bash退出后，子进程执行完毕 execv(container_args[0], container_args); // 从这里开始的代码将不会被执行到，因为当前子进程已经被上面的bash替换掉了; // 所以如果执行到这里，一定是出错了 printf(\"Container[%d] - oops!\\n\", pid); return 1; } int main(int argc, char *argv[]) { pid_t pid = getpid(); printf(\"Parent[%d] - create a container!\\n\", pid); // 创建并启动子进程，调用该函数后，父进程将继续往后执行，也就是执行后面的waitpid pid_t child_pid = clone(container_func, // 子进程将执行container_func这个函数 container_stack + sizeof(container_stack), // 这里SIGCHLD是子进程退出后返回给父进程的信号，跟namespace无关 SIGCHLD, NULL); // 传给child_func的参数 errExit(child_pid, \"clone\"); waitpid(child_pid, NULL, 0); // 等待子进程结束 printf(\"Parent[%d] - container exited!\\n\", pid); return 0; } 这段代码不长，但是做了很多事情： 通过clone()创建出一个子进程，并设置启动时的参数 在子进程中调用 execv 来执行 /bin/bash，等待用户进行交互 子进程退出之后，父进程也跟着退出 我们可以用ls -l /proc/$$/ns查看当前进程所在命名空间的信息，运行程序： lucy@lucy-computer:~$ gcc container.c -o container lucy@lucy-computer:~$ ./container Parent[19644] - create a container! Container[19645] - inside the container! lucy@lucy-computer:~$ ls -l /proc/$$/ns 总用量 0 lrwxrwxrwx 1 lucy lucy 0 11月 28 15:36 cgroup -\u003e 'cgroup:[4026531835]' lrwxrwxrwx 1 lucy lucy 0 11月 28 15:36 ipc -\u003e 'ipc:[4026531839]' lrwxrwxrwx 1 lucy lucy 0 11月 28 15:36 mnt -\u003e 'mnt:[4026531840]' lrwxrwxrwx 1 lucy lucy 0 11月 28 15:36 net -\u003e 'net:[4026531992]' lrwxrwxrwx 1 lucy lucy 0 11月 28 15:36 pid -\u003e 'pid:[4026531836]' lrwxrwxrwx 1 lucy lucy 0 11月 28 15:36 pid_for_children -\u003e 'pid:[4026531836]' lrwxrwxrwx 1 lucy lucy 0 11月 28 15:36 user -\u003e 'user:[4026531837]' lrwxrwxrwx 1 lucy lucy 0 11月 28 15:36 uts -\u003e 'uts:[4026531838]' lucy@lucy-computer:~$ exit exit Parent[19644] - container exited! lucy@lucy-computer:~$ ls -l /proc/$$/ns 总用量 0 lrwxrwxrwx 1 lucy lucy 0 11月 28 15:39 cgroup -\u003e 'cgroup:[4026531835]' lrwxrwxrwx 1 lucy lucy 0 11月 28 15:39 ipc -\u003e 'ipc:[4026531839]' lrwxrwxrwx 1 lucy lucy 0 11月 28 15:39 mnt -\u003e 'mnt:[4026531840]' lrwxrwxrwx 1 lucy lucy 0 11月 28 15:39 net -\u003e 'net:[4026531992]' lrwxrwxrwx 1 lucy lucy 0 11月 28 15:39 pid -\u003e 'pid:[4026531836]' lrwxrwxrwx 1 lucy lucy 0 11月 28 15:39 pid_for_children -\u003e 'pid:[4026531836]' lrwxrwxrwx 1 lucy lucy 0 11月 28 15:39 user -\u003e 'user:[4026531837]' lrwxrwxrwx 1 lucy lucy 0 11月 28 15:39 uts -\u003e 'uts:[4026531838]' 各类命名空间id都是一样，因为我们只是单单使用了clone，未设置要隔离的命名空间，现在，我们加入UTS Namespace隔离，UTS namespace 功能最简单，它只隔离了 hostname 和 NIS domain name 两个资源。 同一个 namespace 里面的进程看到的 hostname 和 domain name 是相同的，这两个值可以通过 sethostname(2) 和 setdomainname(2) 来进行设置，也可以通过 uname(2)、gethostname(2) 和 getdomainname(2) 来读取。 注意： UTS 的名字来自于uname函数用到的结构体struct utsname，这个结构体的名字源自于UNIX Time-sharing System。 代码主要修改两个地方：clone 的参数加上了 CLONE_NEWUTS，子进程函数中使用sethostname来设置 hostname。 #define _GNU_SOURCE #include \u003csched.h\u003e #include \u003csys/wait.h\u003e #include \u003csys/utsname.h\u003e #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e #include \u003cstring.h\u003e // 设置子进程要使用的栈空间 #define STACK_SIZE (1024*1024) static char container_stack[STACK_SIZE]; #define errExit(code, msg); {if(code == -1){perror(msg); exit(-1);} } char* const container_args[] = { \"/bin/bash\", NULL }; static int container_func(void *hostname) { pid_t pid = getpid(); printf(\"Container[%d] - inside the container!\\n\", pid); // 使用 sethostname 设置子进程的 hostname 信息 struct utsname uts; if (sethostname(hostname, strlen(hostname)) == -1) { errExit(-1, \"sethostname\") }; // 使用 uname 获取子进程的机器信息，并打印 hostname 出来 if (uname(\u0026uts) == -1){ errExit(-1, \"uname\") } printf(\"Container[%d] - container uts.nodename: [%s]!\\n\", pid, ut","date":"2019-11-28","objectID":"/docker-linux-namespace-intro/:2:0","tags":["Docker","Namespace","Cgroup"],"title":"一步步自己做个Docker之Linux Namespace 简介","uri":"/docker-linux-namespace-intro/"},{"categories":["Docker"],"content":"Let’s Go C语言很底层，能控制到很多细节，但是它对于大部分人有点困难，接下来我们会有Go语言来一步步实现Docker容器。 ","date":"2019-11-28","objectID":"/docker-linux-namespace-intro/:2:1","tags":["Docker","Namespace","Cgroup"],"title":"一步步自己做个Docker之Linux Namespace 简介","uri":"/docker-linux-namespace-intro/"},{"categories":["Docker"],"content":"参考资料 cizixs.com/2017/08/29/linux-namespace Linux Namespace : 简介 ","date":"2019-11-28","objectID":"/docker-linux-namespace-intro/:2:2","tags":["Docker","Namespace","Cgroup"],"title":"一步步自己做个Docker之Linux Namespace 简介","uri":"/docker-linux-namespace-intro/"},{"categories":["C#"],"content":"CefSharp CEF全称：Chromium Embedded Framework。 CefSharp是什么？官网上它是这么写的：CefSharp是在C#或VB.NET应用程序中嵌入全功能标准兼容web浏览器的最简单方法。CefSharp有WinForms和WPF应用程序的浏览器控件，也有自动化项目的无标题（屏幕外）版本。CefSharp基于Chromium嵌入式框架，这是Google Chrome的开源版本。 说白了，就是基于C#或VB语言的可编程浏览器（当然CEF也有其他语言的，如Java，Go）。 本文环境： CefSharp版本：75.1.143 VS版本：2015 操作系统：Windows 10专业版 ","date":"2019-11-16","objectID":"/cefsharp_summary/:1:0","tags":["C#","CefSharp","WPF"],"title":"CefSharp浅尝辄止","uri":"/cefsharp_summary/"},{"categories":["C#"],"content":"WPF引入CefSharp CefSharp有现成的NuGet包，先引入到项目中，然后在XAML中添加响应控件： \u003ccefSharp:ChromiumWebBrowser Name=\"myChrome\" Loaded=\"myChrome_Loaded\"/\u003e 添加cefSharp命名空间： xmlns:cefSharp=\"clr-namespace:CefSharp.Wpf;assembly=CefSharp.Wpf\" 在myChrome_Loaded事件中，我们让浏览器打开百度首页： private void myChrome_Loaded(object sender, RoutedEventArgs e) { String url = \"https://www.baidu.com\"; myChrome.Load(url); } 运行程序，我们就可以看到百度首页了。 ","date":"2019-11-16","objectID":"/cefsharp_summary/:2:0","tags":["C#","CefSharp","WPF"],"title":"CefSharp浅尝辄止","uri":"/cefsharp_summary/"},{"categories":["C#"],"content":"截断请求 根据文档，我们可以看到RequestHandler类中的方法GetResourceRequestHandler会在每次发请求前被调用： GetResourceRequestHandler Called on the CEF IO thread before a resource request is initiated. RequestHandler类是IRequestHandler接口的默认实现，我们自定义请求可以继承这个类： Default implementation of IRequestHandler. This class provides default implementations of the methods from IRequestHandler, therefore providing a convenience base class for any custom request handler. 所以我们可以创建一个继承RequestHandler的类 class CustomRequestHandler : RequestHandler { protected override IResourceRequestHandler GetResourceRequestHandler(IWebBrowser chromiumWebBrowser, IBrowser browser, IFrame frame, IRequest request, bool isNavigation, bool isDownload, string requestInitiator, ref bool disableDefaultHandling) { return new CustomResourceRequestHandler(); } } GetResourceRequestHandler是我们要重点关注的方法，里头我们返回了一个类实例，在这个类中我们就可以自定义请求。 新版的CefSharp（75版本之后）把OnBeforeResourceLoad方法移动到了IResourceRequestHandler接口里（文档），同样的CefSharp也提供了这个接口的默认实现：ResourceRequestHandler，所以我们还需要一个继承ResourceRequestHandler的类（也就是上面代码中的CustomResourceRequestHandler类）： public class CustomResourceRequestHandler : ResourceRequestHandler { protected override CefReturnValue OnBeforeResourceLoad(IWebBrowser chromiumWebBrowser, IBrowser browser, IFrame frame, IRequest request, IRequestCallback callback) { var headers = request.Headers; headers[\"Custom-Header\"] = \"My Custom Header\"; request.Headers = headers; return CefReturnValue.Continue; } } 最后，把自定义请求类设置到CefSharp实例中 myChrome.RequestHandler = new CustomRequestHandler(); 通过Fiddler这样的抓包工具，我们就会发现，自定义的Custom-Header头已经加上了 ","date":"2019-11-16","objectID":"/cefsharp_summary/:3:0","tags":["C#","CefSharp","WPF"],"title":"CefSharp浅尝辄止","uri":"/cefsharp_summary/"},{"categories":["C#"],"content":"添加自定义查询参数 上面的例子中，我们添加了自定义的header，如果我们想改写URL添加一些自定义的查询参数呢，譬如name=foo？这里有个坑，如果我们简单地把request.Url += \"?name=foo\"，这样会导致无限重定向（因为改了Url就会重定向）。解决方法也很简单，就是判断一下我们想要的查询参数是否已经在Url里了： protected override CefReturnValue OnBeforeResourceLoad(IWebBrowser chromiumWebBrowser, IBrowser browser, IFrame frame, IRequest request, IRequestCallback callback) { var headers = request.Headers; headers[\"Custom-Header\"] = \"My Custom Header\"; request.Headers = headers; if (!request.Url.Contains(\"name=foo\")) { request.Url += \"?\" + \"name=foo\"; } return CefReturnValue.Continue; } ","date":"2019-11-16","objectID":"/cefsharp_summary/:3:1","tags":["C#","CefSharp","WPF"],"title":"CefSharp浅尝辄止","uri":"/cefsharp_summary/"},{"categories":["C#"],"content":"添加自定义Body 根据IRequest的文档，我们可以利用PostData属性： protected override CefReturnValue OnBeforeResourceLoad(IWebBrowser chromiumWebBrowser, IBrowser browser, IFrame frame, IRequest request, IRequestCallback callback) { var headers = request.Headers; headers[\"Custom-Header\"] = \"My Custom Header\"; request.Headers = headers; string body = \"name=foo\"; byte[] byteArray = System.Text.Encoding.UTF8.GetBytes(body); request.InitializePostData(); var element = request.PostData.CreatePostDataElement(); element.Bytes = byteArray; request.PostData.AddElement(element); return CefReturnValue.Continue; } 通过Fiddler这样的抓包工具，我们就会发现，POST 数据已经加上了： ","date":"2019-11-16","objectID":"/cefsharp_summary/:3:2","tags":["C#","CefSharp","WPF"],"title":"CefSharp浅尝辄止","uri":"/cefsharp_summary/"},{"categories":["C#"],"content":"加载本地HTML字符串 有时候，我们可能需要渲染一个内存中的HTML字符串，CefSharp也提供这样的接口，代码很简单： private void myChrome_Loaded(object sender, RoutedEventArgs e) { string html = @\"\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003e这是个标题\u003c/title\u003e \u003cmeta charset='utf-8' /\u003e \u003cmeta name = 'viewport' content = 'width=device-width, initial-scale=1' /\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003e这是一个一个简单的HTML\u003c/h1\u003e \u003cp\u003eHello World！\u003c/p \u003e \u003c/body\u003e \u003c/html\u003e\"; String url = \"https://www.baidu.com\"; myChrome.LoadHtml(html, url); } ","date":"2019-11-16","objectID":"/cefsharp_summary/:4:0","tags":["C#","CefSharp","WPF"],"title":"CefSharp浅尝辄止","uri":"/cefsharp_summary/"},{"categories":["C#"],"content":"截断响应 这里的关键在于GetResourceResponseFilter方法，它的签名如下： IResponseFilter GetResourceResponseFilter( IWebBrowser chromiumWebBrowser, IBrowser browser, IFrame frame, IRequest request, IResponse response ) 它返回了一个IResponseFilter接口，在这个接口中，我们可以截取到请求响应的内容。在CefSharp最新版本中，GetResourceResponseFilter已经被放入到IResourceRequestHandler接口中，最新文档。 下面我放了一个截断网页XHR请求的例子： public class TestJsonFilter : IResponseFilter { public List\u003cbyte\u003e DataAll = new List\u003cbyte\u003e(); public FilterStatus Filter(System.IO.Stream dataIn, out long dataInRead, System.IO.Stream dataOut, out long dataOutWritten) { try { if (dataIn == null || dataIn.Length == 0) { dataInRead = 0; dataOutWritten = 0; return FilterStatus.Done; } dataInRead = dataIn.Length; dataOutWritten = Math.Min(dataInRead, dataOut.Length); dataIn.CopyTo(dataOut); dataIn.Seek(0, SeekOrigin.Begin); byte[] bs = new byte[dataIn.Length]; dataIn.Read(bs, 0, bs.Length); DataAll.AddRange(bs); dataInRead = dataIn.Length; dataOutWritten = dataIn.Length; return FilterStatus.NeedMoreData; } catch (Exception ex) { dataInRead = dataIn.Length; dataOutWritten = dataIn.Length; return FilterStatus.Done; } } public bool InitFilter() { return true; } public void Dispose() { } } public class FilterManager { private static Dictionary\u003cstring, IResponseFilter\u003e dataList = new Dictionary\u003cstring, IResponseFilter\u003e(); public static IResponseFilter CreateFilter(string guid) { lock (dataList) { var filter = new TestJsonFilter(); dataList.Add(guid, filter); return filter; } } public static IResponseFilter GetFileter(string guid) { lock (dataList) { if (dataList.ContainsKey(guid)) // 这里要检测key存在，不然会报异常，会导致ContextSwitchDeadlock { return dataList[guid]; } else { return null; } } } } public class CustomResourceRequestHandler : ResourceRequestHandler { protected override CefReturnValue OnBeforeResourceLoad(IWebBrowser chromiumWebBrowser, IBrowser browser, IFrame frame, IRequest request, IRequestCallback callback) { // 截断请求的代码... return CefReturnValue.Continue; } protected override IResponseFilter GetResourceResponseFilter(IWebBrowser chromiumWebBrowser, IBrowser browser, IFrame frame, IRequest request, IResponse response) { if (!(request.ResourceType == ResourceType.Xhr)) // 不是XHR类型就不去过滤 { return null; } var filer = FilterManager.CreateFilter(request.Identifier.ToString()); return filer; } protected override void OnResourceLoadComplete(IWebBrowser chromiumWebBrowser, IBrowser browser, IFrame frame, IRequest request, IResponse response, UrlRequestStatus status, long receivedContentLength) { var filer = FilterManager.GetFileter(request.Identifier.ToString()) as TestJsonFilter; if (filer != null) { Console.WriteLine(ASCIIEncoding.UTF8.GetString(filer.DataAll.ToArray())); // 打印body内容 } } } private void myChrome_Loaded(object sender, RoutedEventArgs e) { String url = \"https://github.com/salamander-mh\"; // github首页上有ajax请求，可以看效果 myChrome.Load(url); } 运行程序，在输出视图就可以看到Ajax请求的body数据。 ","date":"2019-11-16","objectID":"/cefsharp_summary/:5:0","tags":["C#","CefSharp","WPF"],"title":"CefSharp浅尝辄止","uri":"/cefsharp_summary/"},{"categories":["C#"],"content":"截取cookie 建立Cookie读取对象，继承接口 ICookieVisitor public class CookieVisitor : CefSharp.ICookieVisitor { public event Action\u003cCefSharp.Cookie\u003e SendCookie; public bool Visit(Cookie cookie, int count, int total, ref bool deleteCookie) { deleteCookie = false; if (SendCookie != null) { SendCookie(cookie); } return true; } public void Dispose() { } } 在browser事件中进行处理 private void browser_FrameLoadEnd(object sender, CefSharp.FrameLoadEndEventArgs e) { var cookieManager = myChrome.GetCookieManager(); CookieVisitor visitor = new CookieVisitor(); visitor.SendCookie += visitor_SendCookie; cookieManager.VisitAllCookies(visitor); } 回调事件 private void visitor_SendCookie(CefSharp.Cookie obj) { Console.WriteLine(\"获取cookie：\" + obj.Domain.TrimStart('.') + \"^\" + obj.Name + \"^\" + obj.Value + \"$\"); } 设置CefSharp实例事件： private void myChrome_Loaded(object sender, RoutedEventArgs e) { String url = \"https://www.baidu.com\"; myChrome.Load(url); myChrome.FrameLoadEnd += browser_FrameLoadEnd; } 运行程序，在输出视图就可以看到cookie数据了。 ","date":"2019-11-16","objectID":"/cefsharp_summary/:6:0","tags":["C#","CefSharp","WPF"],"title":"CefSharp浅尝辄止","uri":"/cefsharp_summary/"},{"categories":["C#"],"content":"Javascript交互 ","date":"2019-11-16","objectID":"/cefsharp_summary/:7:0","tags":["C#","CefSharp","WPF"],"title":"CefSharp浅尝辄止","uri":"/cefsharp_summary/"},{"categories":["C#"],"content":"C#执行js方法 myChrome.GetBrowser().MainFrame.ExecuteJavaScriptAsync(\"document.getElementById('testid').click();\"); 以上代码就会触发id为testid的元素的click事件。 注意：脚本是在 Frame 级别执行，页面永远至少有一个Frame（ MainFrame ）。 ","date":"2019-11-16","objectID":"/cefsharp_summary/:7:1","tags":["C#","CefSharp","WPF"],"title":"CefSharp浅尝辄止","uri":"/cefsharp_summary/"},{"categories":["C#"],"content":"获取Javascript方法结果 这里需要使用Task\u003cJavascriptResponse\u003e EvaluateScriptAsync(string script, TimeSpan? timeout)方法。 JavaScript代码是异步执行的，因此使用.NET Task 类返回一个响应，其中包含错误消息，结果和一个成功（bool）标志。 // Get Document Height var task = frame.EvaluateScriptAsync(\"(function() { var body = document.body, html = document.documentElement; return Math.max( body.scrollHeight, body.offsetHeight, html.clientHeight, html.scrollHeight, html.offsetHeight ); })();\", null); task.ContinueWith(t =\u003e { if (!t.IsFaulted) { var response = t.Result; EvaluateJavaScriptResult = response.Success ? (response.Result ?? \"null\") : response.Message; } }, TaskScheduler.FromCurrentSynchronizationContext()); ","date":"2019-11-16","objectID":"/cefsharp_summary/:7:2","tags":["C#","CefSharp","WPF"],"title":"CefSharp浅尝辄止","uri":"/cefsharp_summary/"},{"categories":["C#"],"content":"资源清理 关闭应用，发现CefSharp.BrowserSubprocess.exe进程会发现没有结束，其实在退出事件中，我们需要调用Cef.Shutdown()方法 try { if (browser != null) { browser.Dispose(); Cef.Shutdown(); } } catch { } 示例代码下载 参考： StackOverflow How to read the JSON response content from a XMLHttpRequest? CefSharp中文帮助文档 ","date":"2019-11-16","objectID":"/cefsharp_summary/:8:0","tags":["C#","CefSharp","WPF"],"title":"CefSharp浅尝辄止","uri":"/cefsharp_summary/"},{"categories":["ci"],"content":"jenkins是什么？ Jenkins是一个开源的、提供友好操作界面的持续集成(CI)工具，起源于Hudson（Hudson是商用的），主要用于持续、自动的构建/测试软件项目、监控外部任务的运行。Jenkins用Java语言编写，可在Tomcat等流行的servlet容器中运行，也可独立运行。通常与版本管理工具(SCM)、构建工具结合使用。常用的版本控制工具有SVN、GIT，构建工具有Maven、Ant、Gradle。 上面的介绍是抄的（逃，简单讲，就是Jenkins能帮我们自动编译，测试，发布软件。 ","date":"2019-11-07","objectID":"/jenkin_and_docker/:1:0","tags":["jenkins","ci","docker"],"title":"Jenkins在Docker中运行中的坑","uri":"/jenkin_and_docker/"},{"categories":["ci"],"content":"安装运行 Jenkins有单独的war包，通过java -jar jenkins.war直接就可以运行（官网下载，选择Generic Java package (.war)，或者官方镜像），选择LTS Releases 中的war-stable），但是jre环境，当然对于熟悉Java的人来说，这个是配置一下即可。本文介绍在Docker中运行Jenkins以及会遇到的一些问题。 操作系统：Ubuntu 18.04.3 LTS docker版本：19.03.4 jdk版本：java version “1.8.0_221” 在vim中打开中文有时候会乱码，可以通过下面命令解决： sudo locale-gen zh_CN.UTF-8 好了，让我们开始安装Jenkins。 首先，编写一份自定义的Dockerfile： FROM jenkins/jenkins:lts USER root RUN echo ' \\n\\ deb http://mirrors.aliyun.com/debian stretch main contrib non-free \\n\\ deb-src http://mirrors.aliyun.com/debian stretch main contrib non-free \\n\\ deb http://mirrors.aliyun.com/debian stretch-updates main contrib non-free \\n\\ deb-src http://mirrors.aliyun.com/debian stretch-updates main contrib non-free \\n\\ deb http://mirrors.aliyun.com/debian-security stretch/updates main contrib non-free \\n\\ deb-src http://mirrors.aliyun.com/debian-security stretch/updates main contrib non-free ' \u003e /etc/apt/sources.list RUN cat /etc/apt/sources.list #更新源并安装缺少的包 RUN apt-get update \u0026\u0026 apt-get install -y gcc g++ make openssl pkg-config USER jenkins 基础镜像是jenkins/jenkins:lts，观察一下这个镜像 发现它是基于FROM openjdk:8-jdk-stretch，这是带有jdk的debian 9镜像。所以我在Dockerfile中修改了apt源，这里使用了阿里云的apt源（\\n\\是换行加上续行符）。 再配合docker-compose.yml： version: '3' services: jenkins: build: . volumes: - ./data:/var/jenkins_home environment: - \"JAVA_OPTS=-Duser.timezone=Asia/Shanghai -Xms1g -Xmx1g\" ports: - 127.0.0.1:8080:8080 - 50000:50000 现在我们就可以启动Jenkins了，打开终端，键入命令： docker-compose up 这时候，我们会遇到错误： jenkins_1 | touch: cannot touch '/var/jenkins_home/copy_reference_file.log': Permission denied jenkins_1 | Can not write to /var/jenkins_home/copy_reference_file.log. Wrong volume permissions? 看描述是权限问题，观察一下目录下的data文件夹： drwxr-xr-x 2 root root 4096 11月 17 20:47 data 发现目录的属主是root用户，这是什么原因呢？ ","date":"2019-11-07","objectID":"/jenkin_and_docker/:2:0","tags":["jenkins","ci","docker"],"title":"Jenkins在Docker中运行中的坑","uri":"/jenkin_and_docker/"},{"categories":["ci"],"content":"原因探究 查看Jenkins容器的当前用户和目录/var/jenkins_home属主，我们发现当前用户是Jenkins，/var/jenkins_home属主用户是jenkins： docker run -ti --rm --entrypoint=\"/bin/bash\" jenkins/jenkins:lts -c \"whoami \u0026\u0026 id\" jenkins uid=1000(jenkins) gid=1000(jenkins) groups=1000(jenkins) docker run -ti --rm --entrypoint=\"/bin/bash\" jenkins/jenkins:lts -c \"ls -la /var\" drwxr-xr-x 1 root root 4096 Oct 17 08:29 cache drwxr-xr-x 2 jenkins jenkins 4096 Nov 17 14:05 jenkins_home 上述命令中，--rm选项是让容器退出时自动清除，--entrypoint是覆盖镜像中的ENTRYPOINT。 现在我们知道了，因为/var/jenkins_home映射到本地数据卷时，目录的拥有者变成了root用户，所以出现了Permission denied的问题。 发现问题之后，相应的解决方法也很简单：把当前目录的拥有者赋值给uid 1000，再启动\"jenkins\"容器就一切正常了。 sudo chown -R 1000:1000 data 这时利用浏览器访问 “http://localhost:8080/” 就可以看到Jenkins的经典Web界面了。 参考： 谈谈 Docker Volume 之权限管理（一） ","date":"2019-11-07","objectID":"/jenkin_and_docker/:3:0","tags":["jenkins","ci","docker"],"title":"Jenkins在Docker中运行中的坑","uri":"/jenkin_and_docker/"},{"categories":["Java","MyBatis"],"content":"最近学习了一下Spring Boot，它确实做到了简单快速创建Java Web应用。这是一篇简单的笔记，记录了Spring Boot集成MyBatis，实现基本的CURD。 ","date":"2019-10-27","objectID":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/:0:0","tags":["Spring","Spring Boot","MyBatis"],"title":"Spring Boot集成MyBatis操作MySQL","uri":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/"},{"categories":["Java","MyBatis"],"content":"MyBatis集成方式 注解版集成 XML版本集成 XML版本为老式的配置集成方式，重度集成XML文件，SQL语句也是全部写在XML中的，我以前配SSM（Spring+SpringMVC+MyBatis）用的就是这种方式；注解版版本，相对来说比较简约，不需要XML配置，只需要使用注解和代码来操作数据，本文这里不作介绍（其实挺好学的，^_^）。 ","date":"2019-10-27","objectID":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/:1:0","tags":["Spring","Spring Boot","MyBatis"],"title":"Spring Boot集成MyBatis操作MySQL","uri":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/"},{"categories":["Java","MyBatis"],"content":"准备 启动MySQL服务 创建数据库spring_db CREATE DATABASE spring_db CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; 创建user表 create table user ( uid int(11) unsigned auto_increment comment '主键Id' primary key, name varchar(255) null comment '名称', age int null comment '年龄', address varchar(255) null comment '地址', created_time datetime null comment '创建时间', updated_time datetime null comment '更新时间' ) comment '用户表' collate=utf8_general_ci; ","date":"2019-10-27","objectID":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/:2:0","tags":["Spring","Spring Boot","MyBatis"],"title":"Spring Boot集成MyBatis操作MySQL","uri":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/"},{"categories":["Java","MyBatis"],"content":"添加依赖 \u003cdependency\u003e \u003cgroupId\u003emysql\u003c/groupId\u003e \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e \u003cversion\u003e5.1.41\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.mybatis.spring.boot\u003c/groupId\u003e \u003cartifactId\u003emybatis-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e1.3.25\u003c/version\u003e \u003c/dependency\u003e ","date":"2019-10-27","objectID":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/:3:0","tags":["Spring","Spring Boot","MyBatis"],"title":"Spring Boot集成MyBatis操作MySQL","uri":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/"},{"categories":["Java","MyBatis"],"content":"配置数据库连接 设置application.properties文件，添加如下配置 spring.datasource.url=jdbc:mysql://127.0.0.1:3306/spring_db?useUnicode=true\u0026characterEncoding=UTF-8 spring.datasource.username=root spring.datasource.password=2LCqvSOJ6m0Ut6ui spring.datasource.driver-class-name=com.mysql.jdbc.Driver spring.datasource.url 数据库连接字符串 spring.datasource.username 数据库用户名 spring.datasource.password 数据库密码 spring.datasource.driver-class-name 驱动类型（注意MySQL 8.0的值是com.mysql.cj.jdbc.Driver和之前不同） ","date":"2019-10-27","objectID":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/:4:0","tags":["Spring","Spring Boot","MyBatis"],"title":"Spring Boot集成MyBatis操作MySQL","uri":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/"},{"categories":["Java","MyBatis"],"content":"设置 MapperScan 包路径 直接在启动文件SpringbootApplication.java的类上配置@MapperScan，这样就可以省去，单独给每个Mapper（就是我们这里的dao层）上标识@Mapper的麻烦。 @SpringBootApplication @MapperScan(\"com.salamander.springbootdemo.dao\") public class SpringbootdemoApplication { public static void main(String[] args) { SpringApplication.run(SpringbootdemoApplication.class, args); } } ","date":"2019-10-27","objectID":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/:5:0","tags":["Spring","Spring Boot","MyBatis"],"title":"Spring Boot集成MyBatis操作MySQL","uri":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/"},{"categories":["Java","MyBatis"],"content":"添加Entity和Dao层类 com.salamander.springbootdemo.entity下User类（使用了lombok的@Data注解）： @Data public class User implements Serializable { private Long id; private String name; private String address; private int age; private Date createdDatetime; } com.salamander.springbootdemo.dao下UserDao接口： public interface UserDao { User findByName(String name); int insertUser(User user); } ","date":"2019-10-27","objectID":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/:6:0","tags":["Spring","Spring Boot","MyBatis"],"title":"Spring Boot集成MyBatis操作MySQL","uri":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/"},{"categories":["Java","MyBatis"],"content":"XML方式MyBatis 集成 修改application.properties，添加配置 mybatis.config-locations=classpath:mybatis/mybatis-config.xml mybatis.mapper-locations=classpath:mybatis/mapper/*.xml mybatis.config-locations 配置MyBatis基础属性 mybatis.mapper-locations 配置Mapper XML文件 ","date":"2019-10-27","objectID":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/:6:1","tags":["Spring","Spring Boot","MyBatis"],"title":"Spring Boot集成MyBatis操作MySQL","uri":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/"},{"categories":["Java","MyBatis"],"content":"配置XML文件 本例创建两个xml文件，在resource/mybatis下的mybatis-config.xml（配置MyBatis基础属性）和在resource/mybatis/mapper下的UserMapper.xml（用户和数据交互的SQL语句）。 mybatis-config.xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"\u003e \u003cconfiguration\u003e \u003ctypeAliases\u003e \u003ctypeAlias alias=\"Integer\" type=\"java.lang.Integer\"/\u003e \u003ctypeAlias alias=\"Long\" type=\"java.lang.Long\"/\u003e \u003ctypeAlias alias=\"HashMap\" type=\"java.util.HashMap\"/\u003e \u003ctypeAlias alias=\"LinkedHashMap\" type=\"java.util.LinkedHashMap\"/\u003e \u003ctypeAlias alias=\"ArrayList\" type=\"java.util.ArrayList\"/\u003e \u003ctypeAlias alias=\"LinkedList\" type=\"java.util.LinkedList\"/\u003e \u003c/typeAliases\u003e \u003c/configuration\u003e UserMapper.xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"\u003e \u003c!--namespace是命名空间，是dao接口的全路径--\u003e \u003cmapper namespace=\"com.salamander.springbootdemo.dao.UserDao\"\u003e \u003cresultMap id=\"userResultMap\" type=\"com.salamander.springbootdemo.entity.User\"\u003e \u003cid property=\"id\" column=\"uid\"\u003e\u003c/id\u003e \u003cresult column=\"name\" property=\"name\" /\u003e \u003cresult column=\"age\" property=\"age\" /\u003e \u003cresult column=\"address\" property=\"address\" /\u003e \u003cresult column=\"created_time\" property=\"createdDatetime\" /\u003e \u003c/resultMap\u003e \u003cselect id=\"findByName\" parameterType=\"java.lang.String\" resultMap=\"userResultMap\"\u003e select uid, name, age, address, created_time from user where name = #{name} \u003c/select\u003e \u003cinsert id=\"insertUser\" parameterType=\"com.salamander.springbootdemo.entity.User\"\u003e insert into user(name, age, address, created_time) VALUES ( #{name}, #{age}, #{address}, #{createdDatetime} ) \u003c/insert\u003e \u003c/mapper\u003e ","date":"2019-10-27","objectID":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/:7:0","tags":["Spring","Spring Boot","MyBatis"],"title":"Spring Boot集成MyBatis操作MySQL","uri":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/"},{"categories":["Java","MyBatis"],"content":"调用Dao类 HomeController.java类 @RestController public class HomeController { @Resource private UserDao userDao; @RequestMapping(\"/\") public String index() { return \"Hello World!\"; } @RequestMapping(\"/user/{username}\") @ResponseBody public User getUser(@PathVariable(name = \"username\") String name) { return userDao.findByName(name); } @RequestMapping(\"/user/add/{username}\") @ResponseBody public String addUser(@PathVariable(name = \"username\") String name) { User user = new User(); user.setName(name); user.setAge(20); user.setCreatedDatetime(new Date()); userDao.insertUser(user); return \"insert succesfully\"; } } 好了，访问链接http://localhost:8080/user/wang，就会输出wang这个用户的数据，而访问http://localhost:8080/user/add/zhao,会添加一条name为zhao的数据到数据库。 ","date":"2019-10-27","objectID":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/:8:0","tags":["Spring","Spring Boot","MyBatis"],"title":"Spring Boot集成MyBatis操作MySQL","uri":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/"},{"categories":["Java","MyBatis"],"content":"事务支持 在SpringBoot中开启事务非常简单，只需在业务层添加事务注解(@Transactional)即可快速开启事务。好的，让我们来尝试一下。 在上面的使用中，我们是直接把Dao类在控制层中使用的，但一般情况下，我们是在业务层中使用Dao类的。 在com.salamander.springbootdemo下新建Service的package，之后创建接口UserService： package com.salamander.springbootdemo.service; public interface UserService { void addUsers(String name) throws Exception; } 之后在impl的子package中添加实现类UserServiceImpl： package com.salamander.springbootdemo.service.impl; import com.salamander.springbootdemo.dao.UserDao; import com.salamander.springbootdemo.entity.User; import com.salamander.springbootdemo.service.UserService; import org.springframework.stereotype.Service; import org.springframework.transaction.annotation.Transactional; import javax.annotation.Resource; import java.util.Date; @Service public class UserServiceImpl implements UserService { @Resource private UserDao userDao; @Transactional @Override public void addUsers(String name) throws Exception { int num = 5; for (int i = 0; i \u003c num; i++) { User user = getNewUser(name + (i + 1)); userDao.insertUser(user); if (i == 3) { throw new Exception(\"发生内部错误了\"); } } } private User getNewUser(String name) { User user = new User(); user.setName(name); user.setAge(20); user.setCreatedDatetime(new Date()); return user; } } 然后我们在HomeController中注入UserService，并添加路由 @Resource private UserService userService; @RequestMapping(\"/users/add/{username}\") @ResponseBody public String addUsers(@PathVariable(name = \"username\") String name) { try { userService.addUsers(name); return \"batch insert succesfully\"; } catch (Exception e) { return e.getMessage(); } } 可以看到，我们在addUsers方法上添加了@Transactional注解开启了事务，并在插入第4条数据后抛出了异常。好了，让我们访问链接http://localhost:8080/users/add/sun，我们发现数据库多出了四条name为sun的数据，回滚并没有起效果 这是一个常见的坑点，因为Spring的默认的事务规则是遇到运行异常（RuntimeException及其子类）和程序错误（Error）才会进行事务回滚，而Exception是基类就不行了，让我们看下Java的异常类层次图 如果想针对检测异常进行事务回滚，可以在@Transactional注解里使用 rollbackFor属性明确指定异常（或者你可以自己定义一个继承RuntimeException的类，然后抛出这个类）。 现在addUsers改成这样，就可以正常回滚了： @Transactional(rollbackFor = Exception.class) @Override public void addUsers(String name) throws Exception { int num = 5; for (int i = 0; i \u003c num; i++) { User user = getNewUser(name + (i + 1)); userDao.insertUser(user); if (i == 3) { throw new Exception(\"发生内部错误了\"); } } } 项目代码下载 ","date":"2019-10-27","objectID":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/:9:0","tags":["Spring","Spring Boot","MyBatis"],"title":"Spring Boot集成MyBatis操作MySQL","uri":"/spring-boot%E9%9B%86%E6%88%90mybatis%E6%93%8D%E4%BD%9Cmysql/"},{"categories":["机器学习"],"content":" 最近需要在用Pytorch做深度学习，为了加快训练速度，需要用到GPU运算，故在此记录一下安装过程。 我的本机环境： Ubuntu 18.04.3 LTS GeForce RTX 2080s ","date":"2019-09-18","objectID":"/ubuntu_cuda_cudnn/:0:0","tags":["NVI","CUDA","cuDNN"],"title":"Ubuntu上安装NVIDIA显卡驱动和CUDA和cuDNN库","uri":"/ubuntu_cuda_cudnn/"},{"categories":["机器学习"],"content":"检查BIOS启动项 在开机启动项的Security选项中检查UEFI是否开启，如果开启的话请立马关掉它（重要） 在开机启动项的Boot选项中检查Secure Boot是否开启，如果开启的话请立马关掉它（重要），对于有的BIOS，只要删除Secure Boot Key就好了。 ","date":"2019-09-18","objectID":"/ubuntu_cuda_cudnn/:0:1","tags":["NVI","CUDA","cuDNN"],"title":"Ubuntu上安装NVIDIA显卡驱动和CUDA和cuDNN库","uri":"/ubuntu_cuda_cudnn/"},{"categories":["机器学习"],"content":"禁用 nouveau 运行命令 sudo gedit /etc/modprobe.d/blacklist.conf 将下列代码增加到blacklist.conf文件的末尾： blacklist vga16fb blacklist nouveau blacklist rivafb blacklist rivatv blacklist nvidiafb 保存，然后在命令行中更新initramfs，运行： sudo update-initramfs -u 之后，重启主机 reboot 在终端运行，运行以下命令，查看是否禁用nouveau成功（无输出则表示禁用成功）： lsmod | grep nouveau ","date":"2019-09-18","objectID":"/ubuntu_cuda_cudnn/:0:2","tags":["NVI","CUDA","cuDNN"],"title":"Ubuntu上安装NVIDIA显卡驱动和CUDA和cuDNN库","uri":"/ubuntu_cuda_cudnn/"},{"categories":["机器学习"],"content":"安装显卡驱动 在NVIDIA官方选择对应驱动，然后下载： 在安装驱动之前，应该卸载原有的NVIDIA驱动程序 sudo apt-get remove --purge nvidia* 把下载的驱动放到用户目录下，我这里下载文件为NVIDIA-Linux-x86_64-430.50.run 为了安装新的NVIDIA驱动程序，我们需要停止当前的显示服务器。最简单的方法是使用telinit命令更改为运行级别3。执行以下linux命令后，显示服务器将停止，因此请确保在继续之前保存所有当前工作（如果有）： sudo telinit 3 之后会进入一个新的命令行会话，使用当前的用户名密码登录，然后授予驱动文件可执行权限 chmod a+x NVIDIA-Linux-x86_64-430.50.run 然后执行安装： sudo ./NVIDIA-Linux-x86_64-430.50.run --no-opengl-files 注意，–no-opengl-files参数必须加否则会循环登录，也就是loop login 参数介绍： –no-opengl-files 只安装驱动文件，不安装OpenGL文件。这个参数最重要 –no-x-check 安装驱动时不检查X服务 –no-nouveau-check 安装驱动时不检查nouveau 后面两个参数可不加。 安装驱动中注意，pre-install script failed这个提示没什么关系，之后的warning提示unable to find a suitable destination to install 32-bit compatibility libraries也没关系，都选ok，在询问是否修改x-configuration，请选择默认的no，选择yes会导致重启后无法进入系统。 ","date":"2019-09-18","objectID":"/ubuntu_cuda_cudnn/:0:3","tags":["NVI","CUDA","cuDNN"],"title":"Ubuntu上安装NVIDIA显卡驱动和CUDA和cuDNN库","uri":"/ubuntu_cuda_cudnn/"},{"categories":["机器学习"],"content":"使用nvidia-smi命令测试 英伟达系统管理接口（NVIDIA System Management Interface, 简称 nvidia-smi）是基于NVIDIA Management Library (NVML) 的命令行管理组件,旨在(intened to )帮助管理和监控NVIDIA GPU设备。 驱动安装完成后，启动电脑，之后就能用nvidia-smi命令判断驱动是否安装成功 nvidia-smi 执行这条命令将会打印出当前系统安装的NVIDIA驱动信息，如下： 若出现上图中的结果则说明英伟达驱动安装成功。 ","date":"2019-09-18","objectID":"/ubuntu_cuda_cudnn/:0:4","tags":["NVI","CUDA","cuDNN"],"title":"Ubuntu上安装NVIDIA显卡驱动和CUDA和cuDNN库","uri":"/ubuntu_cuda_cudnn/"},{"categories":["机器学习"],"content":"安装CUDA10.1 CUDA是什么？ CUDA，Compute Unified Device Architecture的简称，是由NVIDIA公司创立的基于他们公司生产的图形处理器GPUs（Graphics Processing Units,可以通俗的理解为显卡）的一个并行计算平台和编程模型。 通过CUDA，GPUs可以很方便地被用来进行通用计算（有点像在CPU中进行的数值计算等等）。在没有CUDA之前，GPUs一般只用来进行图形渲染（如通过OpenGL，DirectX）。 下载地址，选择对应版本的cuda安装包，我这里选择的是runfile类型的，不要选择使用deb版本，安装CUDA时一定使用runfile文件，这样可以进行选择不再安装驱动。 在安装界面，注意选择不安装显卡驱动（按enter键取消选择） 。之后，打开/usr/local文件夹，我们会发现多了cuda和cuda10.1这两个文件夹，如下所示： ","date":"2019-09-18","objectID":"/ubuntu_cuda_cudnn/:0:5","tags":["NVI","CUDA","cuDNN"],"title":"Ubuntu上安装NVIDIA显卡驱动和CUDA和cuDNN库","uri":"/ubuntu_cuda_cudnn/"},{"categories":["机器学习"],"content":"添加环境变量 运行sudo vim /etc/profile，末尾加上： export CUDA_HOME=/usr/local/cuda export PATH=$PATH:$CUDA_HOME/bin export LD_LIBRARY_PATH=/usr/local/cuda-10.1/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} 之后运行source /etc/profile使变量起效。 ","date":"2019-09-18","objectID":"/ubuntu_cuda_cudnn/:0:6","tags":["NVI","CUDA","cuDNN"],"title":"Ubuntu上安装NVIDIA显卡驱动和CUDA和cuDNN库","uri":"/ubuntu_cuda_cudnn/"},{"categories":["机器学习"],"content":"判断CUDA安装成功 运行一下代码 cd /usr/local/cuda/samples/1_Utilities/deviceQuery sudo make ./deviceQuery 如果输出如下类似信息，说明CUDA安装成功： 在CUDA安装之后，我们其实已经可以用PyTorch判断是否支持GPU了，进入python控制台： import torch print(torch.cuda.is_available()) ","date":"2019-09-18","objectID":"/ubuntu_cuda_cudnn/:0:7","tags":["NVI","CUDA","cuDNN"],"title":"Ubuntu上安装NVIDIA显卡驱动和CUDA和cuDNN库","uri":"/ubuntu_cuda_cudnn/"},{"categories":["机器学习"],"content":"CUDA与cuDNN的关系 cuDNN是GPU加速计算深层神经网络的库。把CUDA看作是一个工作台，上面配有很多工具，如锤子、螺丝刀等。cuDNN是基于CUDA的深度学习GPU加速库，有了它才能在GPU上完成深度学习的计算。它就相当于工作的工具，比如它就是个扳手。但是CUDA这个工作台买来的时候，并没有送扳手。想要在CUDA上运行深度神经网络，就要安装cuDNN，就像你想要拧个螺帽就要把扳手买回来。这样才能使GPU进行深度神经网络的工作，工作速度相较CPU快很多。 ","date":"2019-09-18","objectID":"/ubuntu_cuda_cudnn/:0:8","tags":["NVI","CUDA","cuDNN"],"title":"Ubuntu上安装NVIDIA显卡驱动和CUDA和cuDNN库","uri":"/ubuntu_cuda_cudnn/"},{"categories":["机器学习"],"content":"安装cuDNN 官方安装cuDNN指南 从官方安装指南可以看出，只要把cuDNN文件复制到CUDA的对应文件夹里就可以，即是所谓插入式设计，把cuDNN数据库添加CUDA里，cuDNN是CUDA的扩展计算库，不会对CUDA造成其他影响。 首先去官网下载cuDNN，需要注册一个账号才能下载。注意要选择对应版本的cuDNN Library for Linux（与CUDA 10.1对应）： 下载后进行解压： tar -zxvf cudnn-10.1-linux-x64-v7.6.2.24.tgz 进入cudnn 10.1解压之后的include目录，在命令行进行如下操作： cd cuda/include sudo cp cudnn.h /usr/local/cuda/include #复制头文件 再将进入lib64目录下的动态文件进行复制和链接： cd .. cd lib64 sudo cp libcudnn* /usr/local/cuda/lib64/ #复制动态链接库 cd /usr/local/cuda/lib64/ sudo chmod +r libcudnn.so.7.6.2 sudo ln -sf libcudnn.so.7.6.2 libcudnn.so.7 sudo ln -sf libcudnn.so.7 libcudnn.so sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn* sudo ldconfig 参考文章： https://blog.csdn.net/oTengYue/article/details/79506758 https://shomy.top/2016/12/29/gpu-tensorflow-install 简书——CUDA与cuDNN ","date":"2019-09-18","objectID":"/ubuntu_cuda_cudnn/:0:9","tags":["NVI","CUDA","cuDNN"],"title":"Ubuntu上安装NVIDIA显卡驱动和CUDA和cuDNN库","uri":"/ubuntu_cuda_cudnn/"},{"categories":["单片机"],"content":"概览 这篇文章很简单（就是一点电工知识），就是利用DHT11温湿度传感器测量温湿度值，并把结果显示在LCD1602显示器上。 ","date":"2019-08-30","objectID":"/arduino_dth11/:1:0","tags":["arduino","传感器"],"title":"Arduino使用DHT11测量温湿度","uri":"/arduino_dth11/"},{"categories":["单片机"],"content":"实验元器件列表 元器件 型号 数量 备注 主控板 arduino Uno 1 温湿度传感器 DHT11 1 液晶屏 1602 LCD 1 电阻 1K电阻 4 面包板 1 面包板条线 若个 数据线 Uno数据线 1 ","date":"2019-08-30","objectID":"/arduino_dth11/:2:0","tags":["arduino","传感器"],"title":"Arduino使用DHT11测量温湿度","uri":"/arduino_dth11/"},{"categories":["单片机"],"content":"工具和元器件介绍 ","date":"2019-08-30","objectID":"/arduino_dth11/:3:0","tags":["arduino","传感器"],"title":"Arduino使用DHT11测量温湿度","uri":"/arduino_dth11/"},{"categories":["单片机"],"content":"DHT11温湿度传感器 DHT11 传感器接线方法并不复杂，DHT11封装有4个引脚，各个引脚说明如下： Pin 名称 注释 1 VDD 供电 3-5.5 VDC 2 DATA 串行数据，单总线 3 NC 空脚 4 GND 接地，电源负极 ","date":"2019-08-30","objectID":"/arduino_dth11/:3:1","tags":["arduino","传感器"],"title":"Arduino使用DHT11测量温湿度","uri":"/arduino_dth11/"},{"categories":["单片机"],"content":"LCD1602 1602字符型液晶，是一种专门用来显示字母、数字、符号等的点阵型液晶模块，能够同时显示16x02即32个字符。 LCD1602分为两种：带背光和不带背光，带背光的要后一些，引脚多2个，为16个引脚，如下： 引脚说明 LCD1602 通常有14条引脚或16条引脚，14与16引脚的差别在于16条引脚多了背光电源线VCC(15脚)和地线GND(16脚)，其它引脚与14脚的LCD完全一样，如下： 引脚 符号 功能说明 1 VSS 一般接地 2 VDD 接电源（+5V） 3 V0 液晶显示器对比度调整端，接正电源时对比度最弱，接地电源时对比度最高（对比度过高时会产生“鬼影”，使用时可以通过一个10K的电位器调整对比度） 4 RS RS为寄存器选择，高电平1时选择数据寄存器、低电平0时选择指令寄存器 5 R/W R/W为读写信号线，高电平(1)时进行读操作，低电平(0)时进行写操作 6 E E(或EN)端为使能(enable)端，写操作时，下降沿使能；读操作时，E高电平有效 7 DB0 低4位三态、 双向数据总线 0位（最低位） 8 DB1 高4位三态、 双向数据总线 1位 9 DB2 高4位三态、 双向数据总线 2位 10 DB3 高4位三态、 双向数据总线 3位 11 DB4 高4位三态、 双向数据总线 4位 12 DB5 高4位三态、 双向数据总线 5位 13 DB6 高4位三态、 双向数据总线 6位 14 DB7 高4位三态、 双向数据总线 7位（busy flag） 15 BLA 背光电源正极 16 BLK 背光电源负极 ","date":"2019-08-30","objectID":"/arduino_dth11/:3:2","tags":["arduino","传感器"],"title":"Arduino使用DHT11测量温湿度","uri":"/arduino_dth11/"},{"categories":["单片机"],"content":"驱动LCD1602 ","date":"2019-08-30","objectID":"/arduino_dth11/:4:0","tags":["arduino","传感器"],"title":"Arduino使用DHT11测量温湿度","uri":"/arduino_dth11/"},{"categories":["单片机"],"content":"驱动方式 Arduino驱动LCD1602可以选择直接驱动，可以有4线和8线的驱动方式，不过这样还是挺占IO口的，要接的东西多了，就不够用了。所以在这里，我们介绍IIC驱动方式，在LCD1602上得焊接一块IIC转接板（如PCF8574T），只占用2个IO口就能驱动LCD1602。 IIC「Inter-Integrated Circuit 集成电路总线」是一种串行通信总线，应用于板载低速设备间的通讯。由飞利浦公司开发的这一通讯协议，其目的就是为了简化系统硬件设计，减少设备间的连线。 IIC串行总线有两根信号线，一根是双向的数字线SDA，另一根是时钟线SCL，每个IIC设备都有自己的地址，IIC总线上多个设备间通过设备地址进行区别。 上图为本篇使用的IIC转接板，直接焊接于LCD1602。可通过跳线帽设置是否开启背光，通过蓝色电位器调节对比度。IIC设备地址可通过短路A0/A1/A2修改，默认地址用下文的方法查看。 ","date":"2019-08-30","objectID":"/arduino_dth11/:4:1","tags":["arduino","传感器"],"title":"Arduino使用DHT11测量温湿度","uri":"/arduino_dth11/"},{"categories":["单片机"],"content":"接线 PCF8574T Arduino GND -\u003e GND VCC -\u003e 5V SDA -\u003e A4 SCL -\u003e A5 ","date":"2019-08-30","objectID":"/arduino_dth11/:4:2","tags":["arduino","传感器"],"title":"Arduino使用DHT11测量温湿度","uri":"/arduino_dth11/"},{"categories":["单片机"],"content":"扫描I2C地址 将以下代码拷贝到Arduino IDE，并执行。然后选择工具-\u003e串口监视器，把右下角的波特率改为115200，即可读出I2C地址: // I2C Scanner // Written by Nick Gammon // Date: 20th April 2011 #include \u003cWire.h\u003e void setup() { Serial.begin (115200); // Leonardo: wait for serial port to connect while (!Serial) { } Serial.println (); Serial.println (\"I2C scanner. Scanning ...\"); byte count = 0; Wire.begin(); for (byte i = 8; i \u003c 120; i++) { Wire.beginTransmission (i); if (Wire.endTransmission () == 0) { Serial.print (\"Found address: \"); Serial.print (i, DEC); Serial.print (\" (0x\"); Serial.print (i, HEX); Serial.println (\")\"); count++; delay (1); // maybe unneeded? } // end of good response } // end of for loop Serial.println (\"Done.\"); Serial.print (\"Found \"); Serial.print (count, DEC); Serial.println (\" device(s).\"); } // end of setup void loop() {} 可以看到默认地址是0x27（所以不能轻易相信淘宝客服的话。。。）。 ","date":"2019-08-30","objectID":"/arduino_dth11/:4:3","tags":["arduino","传感器"],"title":"Arduino使用DHT11测量温湿度","uri":"/arduino_dth11/"},{"categories":["单片机"],"content":"安装驱动库 LCD1602的驱动库都是要额外装的。 在Arduino IDE中点击「项目」—「加载库」—「管理库」，查找「LiquidCrystal_I2C」，选择最新版本进行安装。 ","date":"2019-08-30","objectID":"/arduino_dth11/:4:4","tags":["arduino","传感器"],"title":"Arduino使用DHT11测量温湿度","uri":"/arduino_dth11/"},{"categories":["单片机"],"content":"显示字符 代码挺简单的： // meng #include \u003cWire.h\u003e #include \u003cLiquidCrystal_I2C.h\u003e //引用I2C库 //设置LCD1602设备地址，这里的地址是0x3F，一般是0x20，或者0x27，具体看模块手册 LiquidCrystal_I2C lcd(0x27, 16, 2); void setup() { lcd.init(); // 初始化LCD lcd.backlight(); //设置LCD背景等亮 } void loop() { lcd.setCursor(0,0); // 设置显示指针 lcd.print(\"Pig Love Rabbit\"); // 输出字符到LCD1602上 lcd.setCursor(0,1); lcd.print(\" by MH.\"); delay(1000); lcd.setBacklight(LOW); // 关掉背光 delay(1000); delay(1000); lcd.setBacklight(HIGH); } 最终显示效果： ","date":"2019-08-30","objectID":"/arduino_dth11/:4:5","tags":["arduino","传感器"],"title":"Arduino使用DHT11测量温湿度","uri":"/arduino_dth11/"},{"categories":["单片机"],"content":"显示温湿度 ","date":"2019-08-30","objectID":"/arduino_dth11/:5:0","tags":["arduino","传感器"],"title":"Arduino使用DHT11测量温湿度","uri":"/arduino_dth11/"},{"categories":["单片机"],"content":"加载DHT的库 为了能读取DHT11的数据，我们需要引入新的库，这里我们用了这个库：DHTlib，用Arduino也可以直接搜到 ","date":"2019-08-30","objectID":"/arduino_dth11/:5:1","tags":["arduino","传感器"],"title":"Arduino使用DHT11测量温湿度","uri":"/arduino_dth11/"},{"categories":["单片机"],"content":"接线 接线蛮简单的，DHT就用到了3个脚，需要注意的是在VCC和DHT11的DATA脚之间放置一个10KΩ的上拉电阻，以使其保持高电平，以实现传感器和MCU之间的正确通信。 代码： // meng #include \u003cWire.h\u003e #include \u003cLiquidCrystal_I2C.h\u003e //引用I2C库 #include \u003cdht.h\u003e //设置LCD1602设备地址，这里的地址是0x3F，一般是0x20，或者0x27，具体看模块手册 LiquidCrystal_I2C lcd(0x27, 16, 2); #define dataPin 2 dht DHT; // Creats a DHT object void setup() { lcd.init(); // 初始化LCD lcd.backlight(); //设置LCD背景等亮 } void loop() { int readData = DHT.read11(dataPin); // 读取数据 // int readData = DHT.read22(dataPin); // DHT22/AM2302 float t = DHT.temperature; // 温度 float h = DHT.humidity; // 湿度 lcd.setCursor(0,0); // 设置显示指针 // 显示温度 lcd.print(\"Temp: \"); lcd.print(t); // Prints the temperature value from the sensor lcd.print(\" \"); lcd.print((char)223);//shows degrees character lcd.print(\"C\"); lcd.setCursor(0,1); lcd.print(\"Humi: \"); lcd.print(h); lcd.print(\" %\"); delay(3000); } 最终，我们实现了把DHT11的温湿度显示到LCD上的效果了： 参考文章： LCD 1602显示屏 ","date":"2019-08-30","objectID":"/arduino_dth11/:5:2","tags":["arduino","传感器"],"title":"Arduino使用DHT11测量温湿度","uri":"/arduino_dth11/"},{"categories":["算法"],"content":"四则运算 四则运算表达式是我们小学就接触的内容，它遵循“先乘除，后加减，从左到右，括号内先算”的法则，例如“7 + (5 - 3) * 4 + 6 / 3”，这个表达式先算5 - 3得2，再算2 * 4和6 / 3，最后计算7 + 8 +2，这个过程很简单，口算就能完成，但是如果让我们在程序里实现这个功能，该如何实现呢？我们遇到的困难在于乘除优在加减的后面，却要先运算，另外还要考虑括号，问题就复杂了。 ","date":"2019-08-19","objectID":"/stack_si_ze/:1:0","tags":["栈","四则运算"],"title":"栈应用之四则运算","uri":"/stack_si_ze/"},{"categories":["算法"],"content":"后缀表达式 波兰有位科学家也想到了这个问题，他想出了一种新的不需要括号的表达式：“后缀表达式”，它更有利于计算机计算。让我们看看它的样子：对于“7 + (5 - 3) * 4 + 6 / 3”，后缀表达式为“7 5 3 - 4 * + 6 3 / +”，叫后缀的原因在于运算符在操作数之后。我们人类喜欢看到的表达式叫“中缀表达式”（因为运算符在操作数中间），但是计算机不喜欢它。 ","date":"2019-08-19","objectID":"/stack_si_ze/:2:0","tags":["栈","四则运算"],"title":"栈应用之四则运算","uri":"/stack_si_ze/"},{"categories":["算法"],"content":"后缀表达式的方法 为了看到后缀表达式的好处，我们先看看，计算机如何利用后缀表达式计算出最终结果。 后缀表达式：7 5 3 - 4 * + 6 3 / + 规则：从左到右遍历字符串，遇到数字则进栈，遇到符号则将栈顶的两个数字出栈，进行计算，运算结果进栈，一直到最终获得结果。 初始化一个空栈，此栈用来对要运算的数字进出使用。 字符串中前三个都是数字，所以7，5，3进栈。 接下来是“-”，所以5和3出栈，5作为被减数，3作为减数，5减3得到2，并将2入栈。 接着是4入栈。 接下来是”*“，所以4和2出栈，4乘以2得8，8入栈。 下面是“+”，7和8出栈，7加8得15，15入栈。 接下来6和3数字入栈。 遇到符号“/”，所以6和3出栈，6作为被除数，3作为除数，6除3得2，2入栈。 最后遇到符号“+”，15和2出栈，15加2得17，17入栈，遍历结束，将最后结果出栈，得到17。 ","date":"2019-08-19","objectID":"/stack_si_ze/:2:1","tags":["栈","四则运算"],"title":"栈应用之四则运算","uri":"/stack_si_ze/"},{"categories":["算法"],"content":"中缀表达式转后缀表达式 可以看到利用栈就很容易计算后缀表达式的值，那么现在我们的问题就是中缀转后缀。 中缀表达式：“8 + (7 - 2 * 3 + 2) * 3 + 10 / 2” 规则：遍历字符串，遇到数字则输出，即成为后缀表达式一部分；若是操作符，则判断与栈顶符号的优先级（乘除优先级比加减优先级高，乘除优先级一样，加和减也一样），如果高于栈顶符号，则压栈，否则从栈顶开始弹出元素直到遇到遇到优先级更低的符号（或者遇到“(”，“(”只有遇到“)”才会弹出），弹出完这些符号后，把当前符号压栈。 初始化一空栈，用来对符号进出栈使用。 第一个字符是数字8，输出8，后面符号是“+”，进栈。 第三个字符是“(”，因为是左括号，所以压栈，第四个字符是7，输出，总表达式为8 7。 接着是“-”，因为栈顶是“(”，所以压栈。后面字符是2，输出，总表达式为8 7 2。 之后符号是“*”，它的优先级比栈顶“-”高，所以压栈，再之后是数字3，输出，总表达式为8 7 2 3。 接着是符号“+”，它比“*”的优先级低，所以“*”弹出栈输出，而“-”优先级和“+”一样，也要弹出栈输出，接下来碰到符号“(”，就要把“+”压栈。接着是数字2，输出，总表达式为8 7 2 3 * - 2。 接着是符号“)”，这时需要从栈顶开始依次弹出符号输出，直到遇到“(”（“(”也要弹出，只是不输出），“(”之后只剩一个“+”，所以弹出“+”输出，接下来是符号“*”，优先级比“+”高，所以压栈，总表达式为8 7 2 3 * - 2 +。 接下来是数字3，输出，紧接着是符号“+”，它比栈顶“*”优先级低，所以弹出“*”输出，而之后比较的“+”优先级一样，也弹出栈输出，最后“+”压栈，总表达式为8 7 2 3 * - 2 + 3 * +。 接着是数字10，输出，接下来是符号“/”，比符号“+”优先级高，所以压栈，总表达式为8 7 2 3 * - 2 + 3 * + 10。 接着是数字2，输出。遍历结束，依次弹出栈中元素，最后总表达式为8 7 2 3 * - 2 + 3 * + 10 2 / +。 ","date":"2019-08-19","objectID":"/stack_si_ze/:2:2","tags":["栈","四则运算"],"title":"栈应用之四则运算","uri":"/stack_si_ze/"},{"categories":["算法"],"content":"代码示例 // 预先生成运算符的tokens prepareTokens() { this.tokens = [ new Token('#', TOKEN_TYPE.ENDEXPR), new Token('(', TOKEN_TYPE.LEFTPAREN), new Token(')', TOKEN_TYPE.RIGHTPAREN), new Token('~', TOKEN_TYPE.UNARYOP, 6), // 负号 new Token('abs', TOKEN_TYPE.UNARYOP, 6), // 求绝对值 new Token('sqrt', TOKEN_TYPE.UNARYOP, 6), // 开平方根 new Token('exp', TOKEN_TYPE.UNARYOP, 6), // e的x次 new Token('ln', TOKEN_TYPE.UNARYOP, 6), // e为底数的对数 new Token('log10', TOKEN_TYPE.UNARYOP, 6), // 10为底数的对数 new Token('sin', TOKEN_TYPE.UNARYOP, 6), // 求sin x new Token('cos', TOKEN_TYPE.UNARYOP, 6), // 求cos x new Token('tan', TOKEN_TYPE.UNARYOP, 6), // 求tan x new Token('+', TOKEN_TYPE.BINARYOP, 4), // 二元+ new Token('-', TOKEN_TYPE.BINARYOP, 4), // 二元- new Token('*', TOKEN_TYPE.BINARYOP, 5), // 乘法 new Token('/', TOKEN_TYPE.BINARYOP, 5), // 除法 new Token('%', TOKEN_TYPE.BINARYOP, 5), // 除模取余 new Token('^', TOKEN_TYPE.BINARYOP, 6), // 指数运算 ] } /** * 中缀表达式转化为后缀表达式 * @return {Array} */ transform() { const postExp = [] const opStack = [] for (let i = 0; i \u003c this.infixExp.length; i++) { const pos = this.infixExp[i] const token = this.tokens[pos] switch (token.type) { case TOKEN_TYPE.OPRAND: postExp.push(pos) break; case TOKEN_TYPE.LEFTPAREN: // “(”直接入栈 opStack.push(pos) break; case TOKEN_TYPE.RIGHTPAREN: // 为“)”，出栈直到遇到运算符“(” let prePos = opStack.pop() while (prePos in this.tokens \u0026\u0026 opStack.length \u003e= 0 \u0026\u0026 this.tokens[prePos].type !== TOKEN_TYPE.LEFTPAREN) { postExp.push(prePos) prePos = opStack.pop() } break; case TOKEN_TYPE.UNARYOP: case TOKEN_TYPE.BINARYOP: let endright = 0 while (endright === 0) { if (opStack.length \u003c= 0) endright = 1 else if (this.tokens[opStack[opStack.length - 1]].type === TOKEN_TYPE.LEFTPAREN) { endright = 1 } else if (this.tokens[opStack[opStack.length - 1]].priority \u003c token.priority) { endright = 1 } else if (this.tokens[opStack[opStack.length - 1]].priority === token.priority \u0026\u0026 token.priority === MAX_PRIORITY) { endright = 1 } else { postExp.push(opStack.pop()) endright = 0 } } opStack.push(pos) break case TOKEN_TYPE.ENDEXPR: while (opStack.length \u003e= 1) { postExp.push(opStack.pop()) } break default: break } } postExp.push(0) // 添加终止符 return postExp } 中缀表达式infixExp中存的是this.tokens中的索引，完整代码Github ","date":"2019-08-19","objectID":"/stack_si_ze/:2:3","tags":["栈","四则运算"],"title":"栈应用之四则运算","uri":"/stack_si_ze/"},{"categories":["about"],"content":"一个热爱技术，很平凡的人。 ","date":"2019-07-10","objectID":"/about/:0:0","tags":[],"title":"关于我","uri":"/about/"}]