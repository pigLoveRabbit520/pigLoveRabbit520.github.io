<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Machine Learning - 分类 - pigLoveRabbit的网站</title><link>https://example.com/categories/machine-learning/</link><description>Machine Learning - 分类 - pigLoveRabbit的网站</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Tue, 08 Oct 2024 14:00:00 +0000</lastBuildDate><atom:link href="https://example.com/categories/machine-learning/" rel="self" type="application/rss+xml"/><item><title>最小二乘法和线性回归</title><link>https://example.com/least_square/</link><pubDate>Tue, 08 Oct 2024 14:00:00 +0000</pubDate><author>pigLoveRabbit</author><guid>https://example.com/least_square/</guid><description>最小二乘法 早在19世纪,勒让德就认为让&amp;quot;误差的平方和最小&amp;quot;估计出来的模型是最接近真实情形的。 按照勒让德的最佳原则,于是就</description></item></channel></rss>